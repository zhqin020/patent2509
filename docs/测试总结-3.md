# 测试日志：

🚀 车辆左转轨迹预测系统
基于历史轨迹的真正左转意图预测
============================================================
💻 使用设备: cpu
请输入要处理的最大样本数 (默认: 全部，输入正整数可缩减调试时间): 
✅ 使用真正的预测模式
   - 历史长度: 50帧 (5秒) - 增加历史长度以捕捉更多左转早期特征
   - 预测范围: 12帧 (1.2秒)
   - 利用NGSIM movement标签进行真正的预测
   - 处理全部样本（无限制）
🔄 创建数据集...
请输入NGSIM数据路径 (默认: E:\Work\zq\202509\patent2509\src\../data/peachtree_filtered_data.csv):
是否按路口和方向筛选数据？(y/n, 默认: y): 
🔍 正在分析数据中的路口信息...
正在加载数据: E:\Work\zq\202509\patent2509\src\../data/peachtree_filtered_data.csv
✅ 已加载完整数据: 873887 条记录
✅ 已加载并过滤数据: 873887/873887 条记录
包含 1545 辆车辆

📋 数据中发现的路口信息:
================================================================================
路口ID     总记录数         车辆数        方向                   机动类型
--------------------------------------------------------------------------------
0.0      681117       1180       1.0,2.0,3.0,4.0      1.0,2.0,3.0
1.0      47468        1084       1.0,2.0,3.0,4.0      1.0,2.0,3.0
2.0      50535        644        1.0,2.0,3.0,4.0      1.0,2.0,3.0
3.0      24161        627        1.0,2.0,3.0,4.0      1.0,2.0,3.0
4.0      14399        595        1.0,2.0,3.0,4.0      1.0,2.0,3.0
5.0      56207        1077       1.0,2.0,3.0,4.0      1.0,2.0,3.0
================================================================================
请输入路口ID (留空不筛选): 1
请输入入口方向 (1-东, 2-北, 3-西, 4-南, 留空不筛选): 
请输入训练轮数 epochs (默认: 50): 5
🔄 开始构建数据集...
✅ 已过滤路口 1 相关车辆数据: 47468/873887 条记录
✅ 数据准备完成: 47468 条记录, 1084 辆车
   其中左转车辆: 239 辆 (22.0%)
正在加载预处理数据: E:\Work\zq\202509\patent2509\src\../data/peachtree_filtered_data.csv   
✅ 数据加载完成: 47468 条记录
🔍 数据列名: ['vehicle_id', 'frame_id', 'total_frames', 'global_time', 'local_x', 'local_y', 'global_x', 'global_y', 'v_length', 'v_width', 'v_class', 'v_vel', 'v_acc', 'lane_id', 'o_zone', 'd_zone', 'int_id', 'section_id', 'direction', 'movement', 'preceding', 'following', 'space_headway', 'time_headway', 'location']
🔍 列名映射: {'vehicle_id': 'vehicle_id', 'frame_id': 'frame_id', 'x': 'local_x', 'y': 'local_y', 'movement': 'movement'}
🔍 开始处理 1084 辆车的轨迹数据...
🔍 最小轨迹长度要求: 5 帧
🔍 历史长度: 3, 预测长度: 2
🚗 处理车辆 2: 18 帧数据
   ✅ 从车辆 2 提取了 7 个样本
🚗 处理车辆 7: 17 帧数据
   ✅ 从车辆 7 提取了 6 个样本
🚗 处理车辆 8: 1 帧数据
   ⚠️ 跳过: 轨迹太短 (1 < 5)
🚗 处理车辆 11: 127 帧数据
   ✅ 从车辆 11 提取了 41 个样本
🚗 处理车辆 13: 20 帧数据
   ✅ 从车辆 13 提取了 5 个样本
📊 数据集构建统计:
   处理车辆总数: 1084
   跳过(轨迹太短): 9
   跳过(可用长度不足): 3
   成功构建样本: 14903
✅ 构建完成: 14903 个预测样本
✅ 数据集划分完成:
   训练集: 10432 样本
   验证集: 2235 样本
   测试集: 2236 样本

📊 各数据集左转车辆分布统计:
   训练集: 2417/10432 (23.2%) 左转样本
   验证集: 495/2235 (22.1%) 左转样本
   测试集: 507/2236 (22.7%) 左转样本
✅ 数据加载器创建完成:
   训练批次大小: 32
   验证批次大小: 32
   测试批次大小: 32
🔧 创建模型...
🎨 测试前轨迹可视化...
🎨 测试前: 抽取 5 个真实左转记录的轨迹...
Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.

✅ 真实左转轨迹样例已保存为: true_left_turn_samples.png
🚀 开始训练...
🚀 开始训练，共 5 轮
============================================================

📈 Epoch 1/5
训练 Epoch 1/5: 100%|█| 326/326 [02:08<00:00,  2.53批/s, 总损失=13.7053, 意图损失=0.3029, 
验证 Epoch 1/5: 100%|█| 70/70 [00:11<00:00,  6.31批/s, 总损失=13.9976, 意图损失=0.2885, 轨
训练损失: 211.9451 (意图: 0.2828, 轨迹: 2113.7941)
验证损失: 15.7432 (意图: 0.2734, 轨迹: 151.9628)
学习率: 0.001000
✅ 保存最佳模型

📈 Epoch 2/5
训练 Epoch 2/5: 100%|█| 326/326 [02:15<00:00,  2.41批/s, 总损失=12.5067, 意图损失=0.2732,  
验证 Epoch 2/5: 100%|█| 70/70 [00:11<00:00,  6.32批/s, 总损失=9.5744, 意图损失=0.2896, 轨  
训练损失: 14.8079 (意图: 0.2807, 轨迹: 142.4648)
验证损失: 12.7974 (意图: 0.2702, 轨迹: 122.5703)
学习率: 0.001000
✅ 保存最佳模型

📈 Epoch 3/5
训练 Epoch 3/5: 100%|█| 326/326 [02:23<00:00,  2.28批/s, 总损失=1.6960, 意图损失=0.3251,
验证 Epoch 3/5: 100%|█| 70/70 [00:11<00:00,  6.03批/s, 总损失=4.6414, 意图损失=0.2564, 轨
训练损失: 5.9395 (意图: 0.2629, 轨迹: 54.1370)
验证损失: 3.7873 (意图: 0.2385, 轨迹: 33.1029)
学习率: 0.001000
✅ 保存最佳模型

📈 Epoch 4/5
训练 Epoch 4/5: 100%|█| 326/326 [02:18<00:00,  2.36批/s, 总损失=11.1305, 意图损失=0.3325,
验证 Epoch 4/5: 100%|█| 70/70 [00:10<00:00,  6.56批/s, 总损失=4.6749, 意图损失=0.2524, 轨
训练损失: 3.6731 (意图: 0.2508, 轨迹: 31.7160)
验证损失: 3.9064 (意图: 0.2248, 轨迹: 34.5687)
学习率: 0.001000

📈 Epoch 5/5
训练 Epoch 5/5: 100%|█| 326/326 [02:13<00:00,  2.44批/s, 总损失=1.1635, 意图损失=0.1900,  
验证 Epoch 5/5: 100%|██████████████████████████████████| 70/70 [00:10<00:00,  6.40批/s, 总损失=4.4663, 意图损失=0.2533, 轨迹损失=39.5960]
训练损失: 3.4908 (意图: 0.2458, 轨迹: 29.9922)
验证损失: 3.1270 (意图: 0.2290, 轨迹: 26.6899)
学习率: 0.001000
✅ 保存最佳模型
============================================================
🎯 训练完成！
📊 开始评估模型...
📈 开始评估模型性能...
评估进度: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:10<00:00,  6.81批/s] 
✅ 模型评估完成，开始计算性能指标...
============================================================
                        模型评估结果
============================================================
意图识别准确率: 0.7733
意图识别精确率: 0.0000
意图识别召回率: 0.0000
意图识别F1分数: 0.0000
意图识别ROC-AUC: 0.7806
----------------------------------------
轨迹预测ADE: 3.5508 m
轨迹预测FDE: 3.7118 m
============================================================
🎉 训练和评估完成！

 

### 1\. GEMINI 测试结果分析与解释

-----

您的模型训练过程非常健康，训练和验证损失稳步下降，表明模型正在有效地学习。然而，评估结果中的**意图识别指标**揭示了一个严重的问题。

  * **意图识别准确率 (Accuracy)**：**0.7733**。这个值看起来不错，但它具有很大的迷惑性。
  * **意图识别精确率 (Precision)、召回率 (Recall)、F1分数 (F1 Score)**：**全部为 0.0000**。这是一个非常明确的信号，意味着在测试集上，您的模型**没有成功识别出任何一个左转（正类别）样本**。它对所有样本的预测结果都是“非左转”。

**为什么会出现这种矛盾？**

这是**类别不平衡**问题在作祟。您的数据集中，左转样本只占了大约 22-23%，这远少于非左转样本。

当模型在训练时，它会发现一个简单的“捷径”来最小化损失：**只要总是预测“非左转”这个多数类别，就能轻松获得接近 77% 的高准确率**。这样做虽然损失值会下降，但模型完全失去了对少数类别（左转）的预测能力，导致召回率和精确率都为零。

**ROC-AUC** 值为 **0.7806**，这再次印证了模型确实学到了一些东西。这个指标衡量的是模型在不同分类阈值下的性能，表明模型对于“左转”和“非左转”样本的**区分能力**是存在的。但是，由于默认的分类阈值（通常是0.5）不适合，模型在实际预测时并没有利用这种区分能力。

### 2\. 代码修改与优化建议

-----

核心目标是修复**类别不平衡**问题，并确保模型能够正确地对左转样本进行分类。以下是具体的修改方案。

#### 方案一：调整损失函数（最有效）

这是解决问题的根本方法。我们需要在损失函数中增加对少数类别（左转）的惩罚权重，迫使模型更关注左转样本的预测。

**修改文件**: `代码实现框架.py`
**修改点**: `TrainingManager` 类的 `__init__` 函数。

```python
# =============================
# 训练管理器
# =============================
class TrainingManager:
    """
    负责模型的训练、验证和保存
    """
    def __init__(self, model, train_loader, val_loader, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # --- 修改点1：计算类别权重 ---
        # 统计训练集中左转和非左转样本数量
        num_pos = sum(1 for _, _, _, label in self.train_loader.dataset if label == 1)
        num_neg = len(self.train_loader.dataset) - num_pos
        
        # 计算权重，给少数类别（左转）更高的权重
        # pos_weight = 负样本数 / 正样本数
        pos_weight = torch.tensor(num_neg / num_pos, dtype=torch.float32).to(self.device)
        print(f"📊 计算类别权重: 左转样本数={num_pos}, 非左转样本数={num_neg}, 左转样本权重={pos_weight.item():.2f}")

        # --- 修改点2：使用带有权重的损失函数 ---
        # nn.BCEWithLogitsLoss 将 Sigmoid 和 BCE 合并，更稳定
        # 并使用 pos_weight 参数来处理类别不平衡
        self.criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
        
        self.optimizer = optim.Adam(model.parameters(), lr=1e-3)
        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=5, factor=0.5, verbose=True)
        self.best_val_loss = float('inf')
        self.patience_counter = 0

    ... # 类的其他部分不变
```

**修改原因**：

  * `pos_weight` 会在计算损失时，对左转样本的损失给予更大的乘法因子（在本例中约为 `77% / 23% ≈ 3.35` 倍）。
  * 这会迫使模型不能再“偷懒”地只预测非左转样本，因为它错误预测左转样本的代价变得非常高。
  * `BCEWithLogitsLoss` 在数值上比分开使用 `Sigmoid` 和 `BCELoss` 更稳定。

#### 方案二：优化评估指标和预测阈值

即使模型训练好了，如果预测阈值不合适，仍然可能无法正确分类。我们需要在评估阶段，计算一个更好的阈值或至少展示**混淆矩阵**来理解模型的预测行为。

**修改文件**: `代码实现框架.py`
**修改点**: `TrainingManager` 类的 `evaluate` 函数。

```python
# =============================
# 训练管理器
# =============================
class TrainingManager:
    ... # 类的其他部分不变
    
    def evaluate(self, data_loader, is_test=False):
        self.model.eval()
        total_loss = 0.0
        intent_preds = []
        intent_labels = []

        with torch.no_grad():
            for batch_idx, data in enumerate(tqdm(data_loader, desc=f"评估进度")):
                # ... (保持原有代码不变)
                
                # --- 修改点3：保存原始 logits 和标签 ---
                intent_preds.extend(intent_pred.cpu().numpy())
                intent_labels.extend(intent_label.cpu().numpy())
                
                # ... (保持原有代码不变)

        # --------------------------------------------------------------------------------
        # 计算性能指标
        # --------------------------------------------------------------------------------
        # --- 修改点4：在评估时，将模型输出的 logits 转换为概率 ---
        intent_preds_tensor = torch.tensor(intent_preds)
        intent_probs = torch.sigmoid(intent_preds_tensor) # 转换为概率
        intent_labels_tensor = torch.tensor(intent_labels)

        # 使用默认阈值 0.5 进行预测
        intent_pred_classes = (intent_probs > 0.5).long().numpy()

        # --- 修改点5：增加一个自适应阈值的建议 ---
        # 我们可以根据验证集性能选择最佳阈值，但这里只展示计算方法
        # 也可以使用 ROC-AUC 曲线的 Youden's J statistic 来寻找最佳阈值
        
        # 计算各种指标
        accuracy = accuracy_score(intent_labels, intent_pred_classes)
        precision = precision_score(intent_labels, intent_pred_classes, zero_division=0)
        recall = recall_score(intent_labels, intent_pred_classes, zero_division=0)
        f1 = f1_score(intent_labels, intent_pred_classes, zero_division=0)
        roc_auc = roc_auc_score(intent_labels, intent_probs)

        # --- 修改点6：打印混淆矩阵 ---
        cm = confusion_matrix(intent_labels, intent_pred_classes)
        print("\n--- 混淆矩阵 (Confusion Matrix) ---")
        print(cm)
        print("其中: [TP, FP], [FN, TN] -> [真实左转预测正确, 真实非左转预测错误]")
        print("     [真实左转预测错误, 真实非左转预测正确]")
        
        # ... (保持原有代码不变，打印其他指标)
        return total_loss / len(data_loader), ...
```

**修改原因**：

  * 在 `evaluate` 函数中，我们现在保存了模型的原始输出（`intent_preds`），而不是直接使用阈值后的结果。
  * 在计算指标时，我们先对原始输出应用 `sigmoid` 函数，得到概率，这才是正确的步骤。
  * 最重要的是，我们**增加了混淆矩阵的打印**。这将直接告诉您模型究竟在哪些样本上预测错误，能够直观地确认模型是否只预测了“非左转”。

#### 方案三：完善 `LeftTurnPredictor`

如果上述修改后效果仍不理想，可以微调模型架构。

  * **增加网络宽度**：在 `LeftTurnPredictor` 的 `__init__` 中，将 LSTM 的 `hidden_size` 和融合层的 `Linear` 层维度适当增加，例如从 `64` 增加到 `128`。
  * **增加网络深度**：增加 LSTM 的 `num_layers`，从 `2` 增加到 `3` 或 `4`。

-----

**执行步骤**

1.  首先应用**方案一**的修改，这是最关键的一步。
2.  再次运行训练，观察训练和验证损失。
3.  如果训练成功，查看评估结果。此时，精确率、召回率和 F1 分数应该不再为零。如果它们仍然很低，请检查混淆矩阵，它会告诉您模型究竟犯了哪些错误。


-----

# CHATGTP 分析和改进建议

我看完了你最新的运行日志，这次的结果变化很大，和之前相比有明显的优缺点：

---

## 测试结果分析

1. **意图识别**

   * 准确率: **0.7733**
   * 精确率: **0.0000**
   * 召回率: **0.0000**
   * F1: **0.0000**
   * ROC-AUC: **0.7806**

   说明：

   * 模型几乎 **完全没有预测任何“左转”样本**（否则精确率/召回率不会都是 0）。
   * 但 ROC-AUC=0.78，说明模型其实能区分正负类，只是**决策阈值选取有问题**（阈值可能太高 → 所有样本都被判为非左转）。

   👉 本质不是模型学不到，而是 **输出的概率分布和阈值设定不匹配**。

2. **轨迹预测**

   * ADE: **3.55m**
   * FDE: **3.71m**

   说明：

   * 轨迹预测的精度非常好（从之前的 20m 降到 \~3.7m）。
   * 说明历史长度拉长到 5s + 数据处理后，轨迹预测部分显著改善。

3. **整体表现**

   * 模型偏向 “轨迹预测任务”，意图识别完全失效。
   * 可能原因：

     * 联合损失权重失衡 → 轨迹 MSE 太大，主导了训练，导致分类任务被淹没。
     * Focal Loss 设置的 `alpha/gamma` 不合适，正类几乎被忽略。
     * 分类阈值固定为 0.5，不适应当前概率分布。

---

## 修改建议

### 1. 调整联合损失权重

当前代码用了：

```python
total_batch_loss = 2.0 * intent_loss + 0.1 * traj_loss
```

但日志里轨迹损失数值远大于意图损失（几十 vs 0.2），实际效果还是被轨迹损失支配。

👉 建议修改为：

```python
total_batch_loss = 10.0 * intent_loss + 0.1 * traj_loss
```

甚至可以先完全关闭轨迹预测（只训练分类器），确保意图识别能学到东西。

---

### 2. 调整 Focal Loss 参数

目前你设的是：

```python
self.intent_loss_fn = FocalLoss(alpha=2.0, gamma=2.0)
```

建议尝试：

* `alpha=5.0` 或更高 → 提升正类（左转）的权重。
* `gamma=1.0` → 降低对易分类样本的惩罚，避免模型完全不学左转。

---

### 3. 分类阈值优化

目前推理阶段默认用 `p>0.5` 判定为左转。
可以：

* 输出概率后，**计算 PR 曲线**，选择最优阈值（而不是固定 0.5）。
* 或者根据 ROC-AUC≈0.78，直接把阈值调低（例如 0.3），可能立刻能恢复到几十%的召回率。

---

### 4. 分阶段训练

* **第一阶段**：只训练意图识别（让分类器能达到 F1≈0.6 以上）。
* **第二阶段**：再联合轨迹预测。
  这样避免意图任务被大损失掩盖。

---

### 5. 数据层面

* 左转样本比例 22% → 仍然不算极端不平衡，但比之前 10% 好。
* 可以再做 **过采样** 或 **SMOTE 增强** 左转样本，进一步提高召回率。

---

## 总结

* 轨迹预测效果显著提升 (ADE≈3.5m, FDE≈3.7m 👍)。
* 意图识别完全失效（精确率/召回率=0），但 ROC-AUC=0.78 → 说明模型有潜力，只是阈值和损失设计不对。

👉 关键改进方向：

1. 提高意图损失权重（10 倍以上）。
2. 调整 Focal Loss 参数（α=5, γ=1）。
3. 使用动态阈值，而不是固定 0.5。
4. 先单独训练分类器，再做多任务。

---
 