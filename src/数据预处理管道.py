#!/usr/bin/env python3
"""
æ•°æ®é¢„å¤„ç†ç®¡é“ - ä¸ºæ·±åº¦å­¦ä¹ æ¡†æ¶å‡†å¤‡é«˜è´¨é‡å·¦è½¬æ•°æ®
"""

import os
import sys
import pandas as pd
import numpy as np
from å·¦è½¬æ•°æ®åˆ†æè„šæœ¬ import LeftTurnAnalyzer

class DataPreprocessingPipeline:
    """æ•°æ®é¢„å¤„ç†ç®¡é“"""
    
    def __init__(self, raw_data_path, output_dir='processed_data'):
        self.raw_data_path = raw_data_path
        self.output_dir = output_dir
        self.analyzer = None
        
    def run_preprocessing(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹"""
        print("=" * 60)
        print("æ•°æ®é¢„å¤„ç†ç®¡é“å¯åŠ¨")
        print("=" * 60)
        
        # 1. åˆ›å»ºå·¦è½¬åˆ†æå™¨
        print("1. åˆå§‹åŒ–å·¦è½¬åˆ†æå™¨...")
        self.analyzer = LeftTurnAnalyzer(self.raw_data_path)
        
        # 2. åŠ è½½å’Œåˆ†ææ•°æ®
        print("2. åŠ è½½åŸå§‹æ•°æ®...")
        if not self.analyzer.load_data():
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return False
        
        # 3. è¯†åˆ«å·¦è½¬è½¦è¾†
        print("3. è¯†åˆ«å·¦è½¬è½¦è¾†ï¼ˆåº”ç”¨ç©ºé—´çº¦æŸå’Œç²¾ç¡®åˆ†ç±»ï¼‰...")
        if not self.analyzer.identify_left_turn_vehicles():
            print("âŒ å·¦è½¬è¯†åˆ«å¤±è´¥")
            return False
        
        # 4. å¯¼å‡ºé¢„å¤„ç†æ•°æ®
        print("4. å¯¼å‡ºé¢„å¤„ç†æ•°æ®...")
        if not self.export_for_deep_learning():
            print("âŒ æ•°æ®å¯¼å‡ºå¤±è´¥")
            return False
        
        print("\n" + "=" * 60)
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        return True
    
    def export_for_deep_learning(self):
        """å¯¼å‡ºé€‚åˆæ·±åº¦å­¦ä¹ çš„æ•°æ®æ ¼å¼"""
        if self.analyzer.left_turn_data is None or len(self.analyzer.left_turn_data) == 0:
            print("æ²¡æœ‰å·¦è½¬æ•°æ®å¯å¯¼å‡º")
            return False
        
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # å¯¼å‡ºå®Œæ•´çš„å·¦è½¬æ•°æ®
        export_path = os.path.join(self.output_dir, 'processed_left_turn_data.csv')
        
        # æ·»åŠ è´¨é‡æ ‡è®°å’Œç‰¹å¾
        export_data = self.analyzer.left_turn_data.copy()
        
        # ä¸ºæ¯ä¸ªè½¦è¾†æ·»åŠ è´¨é‡è¯„ä¼°å’Œç‰¹å¾
        vehicle_features = {}
        for vehicle_id in export_data['vehicle_id'].unique():
            vehicle_data = export_data[export_data['vehicle_id'] == vehicle_id]
            
            # è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡
            trajectory_length = len(vehicle_data)
            x_coords = vehicle_data['local_x'].values
            y_coords = vehicle_data['local_y'].values
            
            if len(x_coords) < 2:
                continue
            
            # è®¡ç®—è½¨è¿¹å¹³æ»‘åº¦
            dx = np.diff(x_coords)
            dy = np.diff(y_coords)
            distances = np.sqrt(dx**2 + dy**2)
            smoothness = np.std(distances) if len(distances) > 0 else 0
            
            # è®¡ç®—æ€»èˆªå‘è§’å˜åŒ–
            total_heading_change = self.analyzer.calculate_total_heading_change(vehicle_data)
            
            # è®¡ç®—ç©ºé—´è·¨åº¦
            x_range = x_coords.max() - x_coords.min()
            y_range = y_coords.max() - y_coords.min()
            spatial_span = max(x_range, y_range)
            
            # è®¡ç®—é€Ÿåº¦ç‰¹å¾
            if len(distances) > 0:
                avg_speed = np.mean(distances) * 10  # å‡è®¾10Hzé‡‡æ ·ç‡
                max_speed = np.max(distances) * 10
            else:
                avg_speed = max_speed = 0
            
            # è®¡ç®—åŠ é€Ÿåº¦ç‰¹å¾
            if len(distances) > 1:
                accelerations = np.diff(distances) * 100  # å‡è®¾10Hzé‡‡æ ·ç‡
                avg_acceleration = np.mean(accelerations)
                max_acceleration = np.max(np.abs(accelerations))
            else:
                avg_acceleration = max_acceleration = 0
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºé«˜è´¨é‡æ•°æ®
            is_high_quality = (
                trajectory_length >= 50 and 
                smoothness < 10 and 
                60 <= abs(total_heading_change) <= 120 and
                spatial_span < 200 and
                avg_speed > 0.5  # æœ€å°é€Ÿåº¦é˜ˆå€¼
            )
            
            vehicle_features[vehicle_id] = {
                'trajectory_length': trajectory_length,
                'smoothness': smoothness,
                'total_heading_change': abs(total_heading_change),
                'spatial_span': spatial_span,
                'avg_speed': avg_speed,
                'max_speed': max_speed,
                'avg_acceleration': avg_acceleration,
                'max_acceleration': max_acceleration,
                'is_high_quality': is_high_quality
            }
        
        # æ·»åŠ ç‰¹å¾åˆ°å¯¼å‡ºæ•°æ®
        for feature_name in ['trajectory_length', 'smoothness', 'total_heading_change', 
                           'spatial_span', 'avg_speed', 'max_speed', 'avg_acceleration', 
                           'max_acceleration', 'is_high_quality']:
            export_data[feature_name] = export_data['vehicle_id'].map(
                lambda x: vehicle_features.get(x, {}).get(feature_name, 0)
            )
        
        # æ·»åŠ åºåˆ—æ ‡è®°ï¼ˆç”¨äºæ·±åº¦å­¦ä¹ çš„åºåˆ—åˆ’åˆ†ï¼‰
        export_data = export_data.sort_values(['vehicle_id', 'frame_id'])
        export_data['sequence_id'] = export_data['vehicle_id']
        export_data['time_step'] = export_data.groupby('vehicle_id').cumcount()
        
        # ä¿å­˜æ•°æ®
        export_data.to_csv(export_path, index=False)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_vehicles = len(export_data['vehicle_id'].unique())
        high_quality_vehicles = len([v for v in vehicle_features.values() if v['is_high_quality']])
        total_points = len(export_data)
        
        print(f"\nğŸ“Š æ•°æ®å¯¼å‡ºç»Ÿè®¡:")
        print(f"   å¯¼å‡ºæ–‡ä»¶: {export_path}")
        print(f"   æ€»è½¦è¾†æ•°: {total_vehicles}")
        print(f"   é«˜è´¨é‡è½¦è¾†æ•°: {high_quality_vehicles} ({high_quality_vehicles/total_vehicles*100:.1f}%)")
        print(f"   æ€»æ•°æ®ç‚¹: {total_points}")
        
        # ä¿å­˜è´¨é‡ç»Ÿè®¡æŠ¥å‘Š
        self.save_quality_report(vehicle_features, export_path)
        
        # ä¿å­˜è®­ç»ƒé…ç½®æ–‡ä»¶
        self.save_training_config(export_path)
        
        return True
    
    def save_quality_report(self, vehicle_features, export_path):
        """ä¿å­˜æ•°æ®è´¨é‡æŠ¥å‘Š"""
        quality_report_path = os.path.join(self.output_dir, 'data_quality_report.txt')
        
        total_vehicles = len(vehicle_features)
        high_quality_vehicles = len([v for v in vehicle_features.values() if v['is_high_quality']])
        
        with open(quality_report_path, 'w', encoding='utf-8') as f:
            f.write("å·¦è½¬æ•°æ®é¢„å¤„ç†è´¨é‡æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“ˆ æ•°æ®ç»Ÿè®¡:\n")
            f.write(f"   æ€»è½¦è¾†æ•°: {total_vehicles}\n")
            f.write(f"   é«˜è´¨é‡è½¦è¾†æ•°: {high_quality_vehicles}\n")
            f.write(f"   é«˜è´¨é‡æ¯”ä¾‹: {high_quality_vehicles/total_vehicles*100:.1f}%\n\n")
            
            f.write("âœ… è´¨é‡æ ‡å‡†:\n")
            f.write("   - è½¨è¿¹é•¿åº¦ >= 50 ä¸ªç‚¹\n")
            f.write("   - è½¨è¿¹å¹³æ»‘åº¦ < 10\n")
            f.write("   - èˆªå‘è§’å˜åŒ– 60Â°-120Â°\n")
            f.write("   - ç©ºé—´è·¨åº¦ < 200ç±³\n")
            f.write("   - å¹³å‡é€Ÿåº¦ > 0.5 m/s\n\n")
            
            f.write("ğŸ“‹ å¯¼å‡ºæ•°æ®åˆ—è¯´æ˜:\n")
            f.write("   - vehicle_id: è½¦è¾†ID\n")
            f.write("   - frame_id: å¸§ID\n")
            f.write("   - local_x, local_y: è½¦è¾†åæ ‡\n")
            f.write("   - sequence_id: åºåˆ—IDï¼ˆç­‰äºvehicle_idï¼‰\n")
            f.write("   - time_step: æ—¶é—´æ­¥ï¼ˆä»0å¼€å§‹ï¼‰\n")
            f.write("   - is_high_quality: æ˜¯å¦ä¸ºé«˜è´¨é‡æ•°æ®\n")
            f.write("   - trajectory_length: è½¨è¿¹é•¿åº¦\n")
            f.write("   - smoothness: è½¨è¿¹å¹³æ»‘åº¦\n")
            f.write("   - total_heading_change: æ€»èˆªå‘è§’å˜åŒ–\n")
            f.write("   - spatial_span: ç©ºé—´è·¨åº¦\n")
            f.write("   - avg_speed, max_speed: é€Ÿåº¦ç‰¹å¾\n")
            f.write("   - avg_acceleration, max_acceleration: åŠ é€Ÿåº¦ç‰¹å¾\n\n")
            
            f.write("ğŸ¯ ä½¿ç”¨å»ºè®®:\n")
            f.write("   1. ä¼˜å…ˆä½¿ç”¨ is_high_quality=True çš„æ•°æ®è¿›è¡Œè®­ç»ƒ\n")
            f.write("   2. å¯ä»¥æ ¹æ® trajectory_length è¿›è¡Œåºåˆ—é•¿åº¦ç­›é€‰\n")
            f.write("   3. sequence_id å’Œ time_step å¯ç”¨äºæ„å»ºæ·±åº¦å­¦ä¹ åºåˆ—\n")
            f.write("   4. å„ç§ç‰¹å¾å¯ç”¨äºæ•°æ®å¢å¼ºå’Œè´¨é‡æ§åˆ¶\n")
        
        print(f"   è´¨é‡æŠ¥å‘Š: {quality_report_path}")
    
    def save_training_config(self, export_path):
        """ä¿å­˜è®­ç»ƒé…ç½®æ–‡ä»¶"""
        config_path = os.path.join(self.output_dir, 'training_config.py')
        
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write('#!/usr/bin/env python3\n')
            f.write('"""\n')
            f.write('æ·±åº¦å­¦ä¹ è®­ç»ƒé…ç½®æ–‡ä»¶\n')
            f.write('ç”±æ•°æ®é¢„å¤„ç†ç®¡é“è‡ªåŠ¨ç”Ÿæˆ\n')
            f.write('"""\n\n')
            
            f.write('# æ•°æ®è·¯å¾„é…ç½®\n')
            f.write(f'PROCESSED_DATA_PATH = "{export_path}"\n')
            f.write(f'OUTPUT_DIR = "{self.output_dir}"\n\n')
            
            f.write('# æ¨¡å‹è®­ç»ƒå‚æ•°\n')
            f.write('SEQUENCE_LENGTH = 8  # å†å²è½¨è¿¹é•¿åº¦\n')
            f.write('PREDICTION_LENGTH = 12  # é¢„æµ‹è½¨è¿¹é•¿åº¦\n')
            f.write('BATCH_SIZE = 32\n')
            f.write('LEARNING_RATE = 0.001\n')
            f.write('NUM_EPOCHS = 100\n')
            f.write('EARLY_STOPPING_PATIENCE = 10\n\n')
            
            f.write('# æ•°æ®ç­›é€‰å‚æ•°\n')
            f.write('USE_HIGH_QUALITY_ONLY = True  # æ˜¯å¦åªä½¿ç”¨é«˜è´¨é‡æ•°æ®\n')
            f.write('MIN_TRAJECTORY_LENGTH = 50  # æœ€å°è½¨è¿¹é•¿åº¦\n')
            f.write('MAX_SPATIAL_SPAN = 200  # æœ€å¤§ç©ºé—´è·¨åº¦\n\n')
            
            f.write('# ç‰¹å¾é…ç½®\n')
            f.write('VISUAL_FEATURE_DIM = 64\n')
            f.write('MOTION_FEATURE_DIM = 40\n')
            f.write('TRAFFIC_FEATURE_DIM = 32\n')
        
        print(f"   è®­ç»ƒé…ç½®: {config_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("æ•°æ®é¢„å¤„ç†ç®¡é“")
    print("å°†åŸå§‹NGSIMæ•°æ®è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ è®­ç»ƒæ•°æ®")
    
    # è·å–è¾“å…¥å‚æ•°
    raw_data_path = input("è¯·è¾“å…¥åŸå§‹NGSIMæ•°æ®è·¯å¾„ (é»˜è®¤: ../data/peachtree_filtered_data.csv): ").strip()
    if not raw_data_path:
        raw_data_path = "../data/peachtree_filtered_data.csv"
    
    output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (é»˜è®¤: processed_data): ").strip()
    if not output_dir:
        output_dir = "processed_data"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(raw_data_path):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ {raw_data_path}")
        return
    
    # è¿è¡Œé¢„å¤„ç†ç®¡é“
    pipeline = DataPreprocessingPipeline(raw_data_path, output_dir)
    success = pipeline.run_preprocessing()
    
    if success:
        print(f"\nğŸ‰ é¢„å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   - processed_left_turn_data.csv  (è®­ç»ƒæ•°æ®)")
        print(f"   - data_quality_report.txt       (è´¨é‡æŠ¥å‘Š)")
        print(f"   - training_config.py            (è®­ç»ƒé…ç½®)")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ ä»£ç å®ç°æ¡†æ¶.py è¿›è¡Œæ¨¡å‹è®­ç»ƒ")
    else:
        print("âŒ é¢„å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main()