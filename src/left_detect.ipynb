{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253cb268",
   "metadata": {},
   "source": [
    "1、数据处理脚本py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c013d20c-7aa0-4ff5-9e07-95c8abd16b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732558f2-bf59-46f0-b0e7-f17dc9420125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: pandas>=1.2 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from seaborn) (2.3.2)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-win_amd64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.10.6-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 19.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 16.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.0-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.0 kiwisolver-1.4.9 matplotlib-3.10.6 pillow-11.3.0 pyparsing-3.2.4 seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8cba8e-46c4-4906-8df8-9f9d549117b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from scipy) (2.3.3)\n",
      "Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 7.9/38.6 MB 44.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 45.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 13.6/38.6 MB 25.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 20.2/38.6 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 27.0/38.6 MB 26.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.0/38.6 MB 26.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.6 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 14.1 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84dddbe-97ea-4425-8e72-746463453a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\work\\zq\\202509\\patent\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76649f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Work\\zq\\202509\\patent\\src\\数据处理脚本.py:50: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  self.raw_data = pd.read_csv(self.data_path, sep='\\s+', names=column_names)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'peachtree_filtered_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m数据处理脚本\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NGSIMDataProcessor\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 配置参数\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 将您代码中加载数据的那一行修改为：\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpeachtree_filtered_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 只写文件名，不要写前面的路径\u001b[39;00m\n\u001b[32m     14\u001b[39m output_dir = \u001b[33m\"\u001b[39m\u001b[33mprocessed_data\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 处理后数据保存路径\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 初始化数据处理器并加载数据\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'peachtree_filtered_data.csv'"
     ]
    }
   ],
   "source": [
    "# 导入依赖库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 加载数据处理脚本中的类/函数\n",
    "from 数据处理脚本 import NGSIMDataProcessor\n",
    "\n",
    "# 配置参数\n",
    "# 将您代码中加载数据的那一行修改为：\n",
    "data = pd.read_csv('peachtree_filtered_data.csv') # 只写文件名，不要写前面的路径\n",
    "output_dir = \"processed_data\"  # 处理后数据保存路径\n",
    "\n",
    "# 初始化数据处理器并加载数据\n",
    "processor = NGSIMDataProcessor(data_path)\n",
    "processor.load_data()\n",
    "processor.preprocess_data()  # 清洗、特征工程\n",
    "processor.identify_left_turn_vehicles()  # 识别左转车辆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94f8ee1-9afd-4d17-8bc0-f6b921eae8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录的所有文件:\n",
      "  - left.ipynb\n",
      "  - left_detect.ipynb\n",
      "  - __pycache__\n",
      "  - 代码实现框架.py\n",
      "  - 实验评估脚本.py\n",
      "  - 数据处理脚本.py\n",
      "  - 评价指标实现代码.py\n",
      "\n",
      "CSV文件:\n"
     ]
    }
   ],
   "source": [
    "# 运行这个单元格来检查文件\n",
    "import os\n",
    "\n",
    "# 查看当前目录的所有文件\n",
    "print(\"当前目录的所有文件:\")\n",
    "for file in os.listdir('.'):\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "# 特别检查CSV文件\n",
    "print(\"\\nCSV文件:\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.endswith('.csv'):\n",
    "        print(f\"  - {file} (存在: {os.path.exists(file)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b09d3a7-3d05-4c07-9a4d-87592394a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载NGSIM数据...\n",
      "数据加载完成，共 873887 条记录\n",
      "数据列: ['vehicle_id', 'frame_id', 'total_frames', 'global_time', 'local_x', 'local_y', 'global_x', 'global_y', 'v_length', 'v_width', 'v_class', 'v_vel', 'v_acc', 'lane_id', 'o_zone', 'd_zone', 'int_id', 'section_id', 'direction', 'movement', 'preceding', 'following', 'space_headway', 'time_headway', 'location']\n",
      "开始数据预处理...\n",
      "  - 数据清洗...\n",
      "    删除缺失值: 0 条\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Vehicle_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Vehicle_ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m processor = NGSIMDataProcessor(data_file_path) \n\u001b[32m     20\u001b[39m processor.load_data()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m processor.identify_left_turn_vehicles()\n\u001b[32m     23\u001b[39m processor.save_processed_data(output_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\src\\数据处理脚本.py:73\u001b[39m, in \u001b[36mNGSIMDataProcessor.preprocess_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_data = \u001b[38;5;28mself\u001b[39m.raw_data.copy()\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# 1. 数据清洗\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# 2. 特征工程\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mself\u001b[39m._feature_engineering()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\src\\数据处理脚本.py:106\u001b[39m, in \u001b[36mNGSIMDataProcessor._clean_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# 删除轨迹点过少的车辆\u001b[39;00m\n\u001b[32m    105\u001b[39m min_trajectory_length = \u001b[32m10\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m vehicle_counts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVehicle_ID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n\u001b[32m    107\u001b[39m valid_vehicles = vehicle_counts[vehicle_counts >= min_trajectory_length].index\n\u001b[32m    108\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_data = \u001b[38;5;28mself\u001b[39m.processed_data[\u001b[38;5;28mself\u001b[39m.processed_data[\u001b[33m'\u001b[39m\u001b[33mVehicle_ID\u001b[39m\u001b[33m'\u001b[39m].isin(valid_vehicles)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Work\\zq\\202509\\patent\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Vehicle_ID'"
     ]
    }
   ],
   "source": [
    "# 导入依赖库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# 加载数据处理脚本中的类/函数\n",
    "from 数据处理脚本 import NGSIMDataProcessor\n",
    "datafile = \"../data/peachtree_filtered_data.csv\"\n",
    "\n",
    "# 配置参数\n",
    "script_dir = os.getcwd()  # 在Notebook中使用getcwd()\n",
    "data_file_path = os.path.join(script_dir, datafile)\n",
    "output_dir = \"processed_data\"\n",
    "\n",
    "# 初始化并处理数据\n",
    "processor = NGSIMDataProcessor(data_file_path) \n",
    "processor.load_data()\n",
    "processor.preprocess_data()\n",
    "processor.identify_left_turn_vehicles()\n",
    "processor.save_processed_data(output_dir)\n",
    "processor.visualize_data()\n",
    "\n",
    "print(\"数据处理流程完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c488cf",
   "metadata": {},
   "source": [
    "模型训练（部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4560-d0bb-4fbd-a7ab-7a19e760c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"车辆左转轨迹预测系统（精简版）\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "# 评估需要用到的 sklearn 指标库\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    \"\"\"多模态数据集（精简版）\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, seq_len: int = 8, pred_len: int = 12):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.data = self.preprocess_data()\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"简化预处理\"\"\"\n",
    "        # 计算基础运动特征\n",
    "        self.data['velocity'] = np.sqrt(self.data['vx']**2 + self.data['vy']** 2)\n",
    "        self.data['heading'] = np.arctan2(self.data['vy'], self.data['vx'])\n",
    "        \n",
    "        # 标准化\n",
    "        num_cols = self.data.select_dtypes(include=[np.number]).columns\n",
    "        self.data[num_cols] = (self.data[num_cols] - self.data[num_cols].mean()) / self.data[num_cols].std()\n",
    "        return self.data.dropna()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取样本（简化特征提取）\"\"\"\n",
    "        history = self.data.iloc[idx:idx+self.seq_len]\n",
    "        future = self.data.iloc[idx+self.seq_len:idx+self.seq_len+self.pred_len]\n",
    "        \n",
    "        # 简化特征提取\n",
    "        motion_feat = history[['x', 'y', 'velocity', 'heading']].values.flatten()\n",
    "        visual_feat = np.random.randn(64)  # 模拟视觉特征\n",
    "        traffic_feat = np.random.randn(32)  # 模拟交通特征\n",
    "        \n",
    "        # 意图标签\n",
    "        start_h = history['heading'].iloc[-1]\n",
    "        end_h = future['heading'].iloc[-1]\n",
    "        intent = 1.0 if (end_h - start_h) > np.pi/4 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'visual': torch.FloatTensor(visual_feat),\n",
    "            'motion': torch.FloatTensor(motion_feat),\n",
    "            'traffic': torch.FloatTensor(traffic_feat),\n",
    "            'intent': torch.FloatTensor([intent]),\n",
    "            'traj': torch.FloatTensor(future[['x', 'y']].values)\n",
    "        }\n",
    "\n",
    "class FeatureEncoder(nn.Module):\n",
    "    \"\"\"通用特征编码器（合并视觉/交通编码器）\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MotionEncoder(nn.Module):\n",
    "    \"\"\"运动特征编码器\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim//8,  # 按时间步拆分\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 8, -1)  # (batch, seq_len, features)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return hidden[-1]  # 取最后一层隐藏状态\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"简化注意力融合\"\"\"\n",
    "    def __init__(self, dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(dim*3, 3)  # 学习特征权重\n",
    "    \n",
    "    def forward(self, v, m, t):\n",
    "        # 特征拼接与注意力权重计算\n",
    "        cat_feat = torch.cat([v, m, t], dim=1)\n",
    "        weights = F.softmax(self.attn(cat_feat), dim=1)\n",
    "        \n",
    "        # 加权融合\n",
    "        fused = weights[:,0:1]*v + weights[:,1:2]*m + weights[:,2:3]*t\n",
    "        return fused\n",
    "\n",
    "class LeftTurnPredictor(nn.Module):\n",
    "    \"\"\"主模型（精简版）\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 编码器\n",
    "        self.visual_enc = FeatureEncoder(64)\n",
    "        self.motion_enc = MotionEncoder(32)  # 8步×4特征\n",
    "        self.traffic_enc = FeatureEncoder(32)\n",
    "        \n",
    "        # 融合与预测\n",
    "        self.fusion = AttentionFusion()\n",
    "        self.intent_head = nn.Sequential(nn.Linear(128, 1), nn.Sigmoid())\n",
    "        self.traj_decoder = nn.LSTM(\n",
    "            input_size=129,  # 融合特征+意图\n",
    "            hidden_size=128,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.traj_head = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, visual, motion, traffic):\n",
    "        # 特征编码\n",
    "        v = self.visual_enc(visual)\n",
    "        m = self.motion_enc(motion)\n",
    "        t = self.traffic_enc(traffic)\n",
    "        \n",
    "        # 融合与预测\n",
    "        fused = self.fusion(v, m, t)\n",
    "        intent = self.intent_head(fused)\n",
    "        \n",
    "        # 轨迹解码\n",
    "        dec_input = torch.cat([fused, intent], dim=1).unsqueeze(1).repeat(1, 12, 1)\n",
    "        traj_out, _ = self.traj_decoder(dec_input)\n",
    "        traj = self.traj_head(traj_out)\n",
    "        \n",
    "        return intent, traj\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"训练管理器（精简版）\"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        self.criterion_intent = nn.BCELoss()\n",
    "        self.criterion_traj = nn.MSELoss()\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in self.train_loader:\n",
    "            # 数据准备\n",
    "            visual = batch['visual'].to(self.device)\n",
    "            motion = batch['motion'].to(self.device)\n",
    "            traffic = batch['traffic'].to(self.device)\n",
    "            intent_tgt = batch['intent'].to(self.device)\n",
    "            traj_tgt = batch['traj'].to(self.device)\n",
    "            \n",
    "            # 前向计算\n",
    "            intent_pred, traj_pred = self.model(visual, motion, traffic)\n",
    "            loss = self.criterion_intent(intent_pred, intent_tgt) + 0.5 * self.criterion_traj(traj_pred, traj_tgt)\n",
    "            \n",
    "            # 反向传播\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                visual = batch['visual'].to(self.device)\n",
    "                motion = batch['motion'].to(self.device)\n",
    "                traffic = batch['traffic'].to(self.device)\n",
    "                intent_tgt = batch['intent'].to(self.device)\n",
    "                traj_tgt = batch['traj'].to(self.device)\n",
    "                \n",
    "                intent_pred, traj_pred = self.model(visual, motion, traffic)\n",
    "                loss = self.criterion_intent(intent_pred, intent_tgt) + 0.5 * self.criterion_traj(traj_pred, traj_tgt)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "    \n",
    "    def train(self, epochs: int = 50, patience: int = 10):\n",
    "        best_loss = float('inf')\n",
    "        counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # 早停机制\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(\"早停触发\")\n",
    "                    break\n",
    "\n",
    "# -------------------------- 1. 模型评估函数：放在TrainingManager之后、main之前 --------------------------\n",
    "def evaluate_simple_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"精简版模型评估函数：计算意图分类（准确率/F1）和轨迹预测（ADE/FDE）指标\"\"\"\n",
    "    model.eval()  # 切换评估模式\n",
    "    # 存储所有批次的预测结果和真实标签\n",
    "    all_intent_pred = []\n",
    "    all_intent_true = []\n",
    "    all_traj_pred = []\n",
    "    all_traj_true = []\n",
    "    \n",
    "    with torch.no_grad():  # 禁用梯度计算，加速评估\n",
    "        for batch in test_loader:\n",
    "            # 数据移至设备\n",
    "            visual = batch['visual'].to(device)\n",
    "            motion = batch['motion'].to(device)\n",
    "            traffic = batch['traffic'].to(device)\n",
    "            intent_true = batch['intent'].to(device)\n",
    "            traj_true = batch['traj'].to(device)\n",
    "            \n",
    "            # 模型预测\n",
    "            intent_pred, traj_pred = model(visual, motion, traffic)\n",
    "            \n",
    "            # 收集结果（转CPU+numpy，方便后续计算）\n",
    "            all_intent_pred.append(intent_pred.cpu().numpy())\n",
    "            all_intent_true.append(intent_true.cpu().numpy())\n",
    "            all_traj_pred.append(traj_pred.cpu().numpy())\n",
    "            all_traj_true.append(traj_true.cpu().numpy())\n",
    "    \n",
    "    # 合并所有批次结果（从列表→numpy数组）\n",
    "    intent_pred = np.concatenate(all_intent_pred)\n",
    "    intent_true = np.concatenate(all_intent_true)\n",
    "    traj_pred = np.concatenate(all_traj_pred)\n",
    "    traj_true = np.concatenate(all_traj_true)\n",
    "    \n",
    "    # -------------------------- 计算评估指标 --------------------------\n",
    "    # 1. 意图分类指标（二分类：>0.5为左转，否则非左转）\n",
    "    intent_pred_binary = (intent_pred > 0.5).astype(int)\n",
    "    intent_true_binary = (intent_true > 0.5).astype(int)\n",
    "    intent_acc = accuracy_score(intent_true_binary, intent_pred_binary)  # 准确率\n",
    "    intent_f1 = f1_score(intent_true_binary, intent_pred_binary)        # F1分数（平衡正负样本）\n",
    "    \n",
    "    # 2. 轨迹预测指标（ADE/FDE：平均位移误差/最终位移误差）\n",
    "    # ADE：所有时间步的位移误差平均值\n",
    "    ade = np.mean(np.sqrt(np.sum((traj_pred - traj_true)**2, axis=2)))\n",
    "    # FDE：最后一个时间步的位移误差平均值\n",
    "    fde = np.mean(np.sqrt(np.sum((traj_pred[:, -1, :] - traj_true[:, -1, :])**2, axis=1)))\n",
    "    \n",
    "    # -------------------------- 打印评估结果 --------------------------\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"精简版模型评估结果（测试集）\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"左转意图识别 - 准确率: {intent_acc:.3f} | F1分数: {intent_f1:.3f}\")\n",
    "    print(f\"轨迹预测       - ADE: {ade:.3f} | FDE: {fde:.3f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 返回指标，方便后续保存（可选）\n",
    "    return {'intent_acc': intent_acc, 'intent_f1': intent_f1, 'ade': ade, 'fde': fde}\n",
    "\n",
    "# -------------------------- 2. 快速测试入口（main逻辑）：训练后调用评估 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 步骤1：生成模拟数据（精简版用CSV，无需依赖pkl）\n",
    "    dummy_data = pd.DataFrame({\n",
    "        'x': np.random.normal(0, 10, 1000),    # 模拟x坐标\n",
    "        'y': np.random.normal(0, 10, 1000),    # 模拟y坐标\n",
    "        'vx': np.random.normal(0, 5, 1000),    # 模拟x方向速度\n",
    "        'vy': np.random.normal(0, 5, 1000)     # 模拟y方向速度\n",
    "    })\n",
    "    dummy_data.to_csv('dummy_data.csv', index=False)\n",
    "    print(\"已生成模拟数据：dummy_data.csv\")\n",
    "    \n",
    "    # 步骤2：加载数据集 + 划分训练/测试集（精简版用同一数据集拆分，方便快速测试）\n",
    "    full_dataset = MultiModalDataset('dummy_data.csv')\n",
    "    # 划分比例：训练集70%，测试集30%（无需验证集，简化流程）\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, test_size]\n",
    "    )\n",
    "    \n",
    "    # 步骤3：创建数据加载器（batch_size=16，CPU友好）\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # 测试集不打乱\n",
    "    print(f\"数据加载完成：训练集{len(train_dataset)}样本，测试集{len(test_dataset)}样本\")\n",
    "    \n",
    "    # 步骤4：初始化模型和训练管理器（CPU环境）\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = LeftTurnPredictor()\n",
    "    trainer = TrainingManager(model, train_loader, val_loader=test_loader, device=device)  # 精简：用测试集当验证集\n",
    "    \n",
    "    # 步骤5：启动训练（仅10轮，快速验证）\n",
    "    print(\"\\n开始训练...\")\n",
    "    trainer.train(epochs=10, patience=5)\n",
    "    \n",
    "    # 步骤6：训练后加载最佳模型，执行评估（核心：调用上面定义的评估函数）\n",
    "    print(\"\\n开始评估最佳模型...\")\n",
    "    model.load_state_dict(torch.load('best_model.pth', map_location=device))  # 加载训练中保存的最佳模型\n",
    "    eval_results = evaluate_simple_model(model, test_loader, device=device)  # 调用评估函数\n",
    "    \n",
    "    # （可选）保存评估结果\n",
    "    np.save('simple_model_eval_results.npy', eval_results)\n",
    "    print(\"\\n评估结果已保存至：simple_model_eval_results.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f02e8-4f00-407d-95a1-9db085a4885b",
   "metadata": {},
   "source": [
    "1、导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2adbf7ee-5e19-469b-9a2b-436f265eeb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "依赖库导入成功！\n",
      "PyTorch版本: 2.8.0+cu128\n",
      "NumPy版本: 2.3.2\n",
      "是否支持CUDA: True\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统 - 第一部分：依赖库导入\n",
    "\"\"\"\n",
    "\n",
    "# 基础数值计算与数据处理库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# PyTorch数据集与数据加载库\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# 可视化库\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 类型提示库（避免语法警告）\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# 模型评估指标库\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------- 运行验证 --------------------------\n",
    "print(\"依赖库导入成功！\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"NumPy版本: {np.__version__}\")\n",
    "print(f\"是否支持CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568654f8-9b37-4df1-82c3-50fc8ec77215",
   "metadata": {},
   "source": [
    "2、数据集类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "156f2547-94cf-4650-8a28-9a4ac9c51834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集总样本数: 100\n",
      "\n",
      "特征维度验证（预期值）：\n",
      "视觉特征: torch.Size([64]) (64,)\n",
      "运动特征: torch.Size([48]) (48,)\n",
      "交通特征: torch.Size([32]) (32,)\n",
      "左转意图: torch.Size([1]) (1,)\n",
      "目标轨迹: torch.Size([12, 2]) (12,2)\n",
      "\n",
      "数据集类初始化成功！\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统 - 第二部分：数据集类\n",
    "\"\"\"\n",
    "\n",
    "# 若单独运行，需先执行第一部分的依赖导入；若已执行，可跳过\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    \"\"\"多模态轨迹数据集类（加载+特征处理）\"\"\"\n",
    "    def __init__(self, data_path: str):\n",
    "        self.data_path = data_path\n",
    "        self.sequences = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        # 方式1：加载真实数据（需确保文件存在）\n",
    "        # with open(self.data_path, 'rb') as f:\n",
    "        #     return pickle.load(f)\n",
    "        \n",
    "        # 方式2：无真实数据时，生成100个模拟样本（直接运行）\n",
    "        test_sequences = []\n",
    "        for _ in range(100):\n",
    "            test_sequences.append({\n",
    "                'history_x': np.random.randn(8),    # 8个时间步x坐标\n",
    "                'history_y': np.random.randn(8),    # 8个时间步y坐标\n",
    "                'history_velocity': np.random.randn(8),  # 速度\n",
    "                'history_acceleration': np.random.randn(8),  # 加速度\n",
    "                'history_heading': np.random.randn(8),  # 航向角\n",
    "                'history_angular_velocity': np.random.randn(8),  # 角速度\n",
    "                'lane_id': np.random.randint(1, 5),  # 车道ID（1-4）\n",
    "                'vehicle_class': np.random.randint(1, 4),  # 车辆类型（1-3）\n",
    "                'left_turn_intent': np.random.randint(0, 2),  # 左转意图（0/1）\n",
    "                'future_x': np.random.randn(12),    # 12个时间步未来x\n",
    "                'future_y': np.random.randn(12)     # 12个时间步未来y\n",
    "            })\n",
    "        return test_sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        # 运动特征：8步×6类=48维\n",
    "        motion_features = np.concatenate([\n",
    "            seq['history_x'], seq['history_y'], seq['history_velocity'],\n",
    "            seq['history_acceleration'], seq['history_heading'], seq['history_angular_velocity']\n",
    "        ])\n",
    "        # 视觉特征：64维（模拟）\n",
    "        visual_features = np.random.randn(64)\n",
    "        # 交通特征：1+1+30=32维\n",
    "        traffic_features = np.concatenate([\n",
    "            np.array([seq['lane_id']]), np.array([seq['vehicle_class']]), np.random.randn(30)\n",
    "        ])\n",
    "        return {\n",
    "            'visual_features': torch.FloatTensor(visual_features),\n",
    "            'motion_features': torch.FloatTensor(motion_features),\n",
    "            'traffic_features': torch.FloatTensor(traffic_features),\n",
    "            'left_turn_intent': torch.FloatTensor([seq['left_turn_intent']]),\n",
    "            'target_trajectory': torch.FloatTensor(np.column_stack([seq['future_x'], seq['future_y']]))\n",
    "        }\n",
    "\n",
    "# -------------------------- 运行验证 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = MultiModalDataset(data_path=\"dummy_path.pkl\")  # 模拟数据无需真实路径\n",
    "    print(f\"数据集总样本数: {len(dataset)}\")\n",
    "    \n",
    "    sample = dataset[0]\n",
    "    print(f\"\\n特征维度验证（预期值）：\")\n",
    "    print(f\"视觉特征: {sample['visual_features'].shape} (64,)\")\n",
    "    print(f\"运动特征: {sample['motion_features'].shape} (48,)\")\n",
    "    print(f\"交通特征: {sample['traffic_features'].shape} (32,)\")\n",
    "    print(f\"左转意图: {sample['left_turn_intent'].shape} (1,)\")\n",
    "    print(f\"目标轨迹: {sample['target_trajectory'].shape} (12,2)\")\n",
    "    print(\"\\n数据集类初始化成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c05958-c751-4742-aad6-fccae7d98907",
   "metadata": {},
   "source": [
    "3、模型组件（核心网络层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47a39fdf-6235-44c4-af43-b62cf8dbcf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型前向传播成功！\n",
      "意图预测维度: torch.Size([8, 1]) (预期: [8,1])\n",
      "轨迹预测维度: torch.Size([8, 12, 2]) (预期: [8,12,2])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统 - 第三部分：模型组件（核心网络）\n",
    "\"\"\"\n",
    "\n",
    "# 若单独运行，需先执行第一部分的依赖导入；若已执行，可跳过\n",
    "\n",
    "# -------------------------- 1. 特征编码器 --------------------------\n",
    "class VisualEncoder(nn.Module):\n",
    "    \"\"\"视觉特征编码器（64维→128维）\"\"\"\n",
    "    def __init__(self, input_dim: int = 64, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(0.2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class MotionEncoder(nn.Module):\n",
    "    \"\"\"运动特征编码器（48维→128维，时序LSTM）\"\"\"\n",
    "    def __init__(self, input_dim: int = 48, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim//8,  # 8时间步，每步6维\n",
    "            hidden_size=hidden_dim, num_layers=2,\n",
    "            batch_first=True, dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.reshape(batch_size, 8, 6)  # [batch, 8, 6]\n",
    "        output, _ = self.lstm(x)\n",
    "        return self.fc(output[:, -1, :])  # 取最后一步输出\n",
    "\n",
    "class TrafficEncoder(nn.Module):\n",
    "    \"\"\"交通特征编码器（32维→128维）\"\"\"\n",
    "    def __init__(self, input_dim: int = 32, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Dropout(0.2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# -------------------------- 2. 注意力融合模块（修复内存问题） --------------------------\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"多模态融合（3个128维→1个128维）\"\"\"\n",
    "    def __init__(self, feature_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(feature_dim, feature_dim)\n",
    "        self.key = nn.Linear(feature_dim, feature_dim)\n",
    "        self.value = nn.Linear(feature_dim, feature_dim)\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=feature_dim, num_heads=8, dropout=0.1\n",
    "        )\n",
    "        self.output_proj = nn.Linear(feature_dim*3, feature_dim)\n",
    "    def forward(self, visual, motion, traffic):\n",
    "        features = torch.stack([visual, motion, traffic], dim=1)  # [batch, 3, 128]\n",
    "        # 自注意力\n",
    "        Q, K, V = self.query(features), self.key(features), self.value(features)\n",
    "        attn_weights = torch.softmax(torch.matmul(Q, K.transpose(-2,-1))/np.sqrt(128), dim=-1)\n",
    "        attn_feat = torch.matmul(attn_weights, V)\n",
    "        # 跨模态注意力\n",
    "        attn_feat = attn_feat.transpose(0,1)  # [3, batch, 128]\n",
    "        cross_attn, _ = self.cross_attention(attn_feat, attn_feat, attn_feat)\n",
    "        cross_attn = cross_attn.transpose(0,1)  # [batch, 3, 128]\n",
    "        # 融合（用reshape替代view，修复内存不连续）\n",
    "        fused = cross_attn.reshape(cross_attn.size(0), -1)  # [batch, 384]\n",
    "        return self.output_proj(fused)  # [batch, 128]\n",
    "\n",
    "# -------------------------- 3. 任务头（意图分类+轨迹预测） --------------------------\n",
    "class IntentClassifier(nn.Module):\n",
    "    \"\"\"左转意图分类（128维→1维概率）\"\"\"\n",
    "    def __init__(self, input_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class TrajectoryDecoder(nn.Module):\n",
    "    \"\"\"轨迹预测（128+1维→12×2维，修复输入维度问题）\"\"\"\n",
    "    def __init__(self, input_dim: int = 129, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim, hidden_size=hidden_dim,\n",
    "            num_layers=2, batch_first=True, dropout=0.2\n",
    "        )\n",
    "        self.output_layer = nn.Linear(hidden_dim, 2)  # 每步输出x/y\n",
    "        self.init_hidden = nn.Linear(input_dim, hidden_dim*2*2)  # 初始化h/c\n",
    "    def forward(self, fused_feat, intent_prob):\n",
    "        batch_size = fused_feat.size(0)\n",
    "        # 初始输入：128（融合特征）+1（意图）=129维\n",
    "        input_feat = torch.cat([fused_feat, intent_prob], dim=1)  # [batch, 129]\n",
    "        # 初始化LSTM隐藏状态（用reshape修复内存问题）\n",
    "        init_states = self.init_hidden(input_feat)\n",
    "        h0 = init_states[:, :256].reshape(2, batch_size, 128).contiguous()  # 2层×128维\n",
    "        c0 = init_states[:, 256:].reshape(2, batch_size, 128).contiguous()\n",
    "        hidden = (h0, c0)\n",
    "        \n",
    "        # 自回归预测12步轨迹\n",
    "        outputs = []\n",
    "        decoder_input = input_feat.unsqueeze(1)  # [batch, 1, 129]\n",
    "        for _ in range(12):\n",
    "            lstm_out, hidden = self.lstm(decoder_input, hidden)\n",
    "            traj_point = self.output_layer(lstm_out)  # [batch, 1, 2]\n",
    "            outputs.append(traj_point)\n",
    "            # 下一步输入：保持129维（避免维度不匹配）\n",
    "            decoder_input = torch.cat([\n",
    "                fused_feat.unsqueeze(1), intent_prob.unsqueeze(1)\n",
    "            ], dim=2)  # [batch, 1, 129]\n",
    "        \n",
    "        return torch.cat(outputs, dim=1)  # [batch, 12, 2]\n",
    "\n",
    "# -------------------------- 4. 主模型（组装所有组件） --------------------------\n",
    "class LeftTurnPredictor(nn.Module):\n",
    "    \"\"\"端到端左转预测主模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.visual_enc = VisualEncoder()\n",
    "        self.motion_enc = MotionEncoder()\n",
    "        self.traffic_enc = TrafficEncoder()\n",
    "        self.attn_fusion = AttentionFusion()\n",
    "        self.intent_cls = IntentClassifier()\n",
    "        self.traj_dec = TrajectoryDecoder()\n",
    "    def forward(self, visual, motion, traffic):\n",
    "        # 特征编码\n",
    "        visual_feat = self.visual_enc(visual)\n",
    "        motion_feat = self.motion_enc(motion)\n",
    "        traffic_feat = self.traffic_enc(traffic)\n",
    "        # 多模态融合\n",
    "        fused_feat = self.attn_fusion(visual_feat, motion_feat, traffic_feat)\n",
    "        # 双任务预测\n",
    "        intent_prob = self.intent_cls(fused_feat)\n",
    "        trajectory = self.traj_dec(fused_feat, intent_prob)\n",
    "        return intent_prob, trajectory\n",
    "\n",
    "# -------------------------- 运行验证 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟1个batch的数据（batch_size=8）\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    visual = torch.randn(8, 64).to(device)  # [batch, 64]\n",
    "    motion = torch.randn(8, 48).to(device)  # [batch, 48]\n",
    "    traffic = torch.randn(8, 32).to(device)# [batch, 32]\n",
    "    \n",
    "    # 初始化模型并前向传播\n",
    "    model = LeftTurnPredictor().to(device)\n",
    "    intent_pred, traj_pred = model(visual, motion, traffic)\n",
    "    \n",
    "    # 验证输出维度\n",
    "    print(f\"模型前向传播成功！\")\n",
    "    print(f\"意图预测维度: {intent_pred.shape} (预期: [8,1])\")\n",
    "    print(f\"轨迹预测维度: {traj_pred.shape} (预期: [8,12,2])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6923780-2d67-4d6c-a392-26bda23991c2",
   "metadata": {},
   "source": [
    "4、训练管理器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59aa621a-f76c-4553-b655-d08428026304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练管理器初始化成功！可执行 trainer.train() 开始训练\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统 - 第四部分：训练管理器（训练+验证）\n",
    "\"\"\"\n",
    "\n",
    "# 依赖说明：需先执行第一、二、三部分（导入库、数据集、模型组件）\n",
    "# 若单独运行，需复制前三部分的核心类（如MultiModalDataset、LeftTurnPredictor）\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"训练管理器（封装训练/验证/早停/学习率调度）\"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # 优化器与损失函数\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=10, factor=0.5\n",
    "        )\n",
    "        self.intent_loss_fn = nn.BCELoss()  # 意图分类损失（二分类）\n",
    "        self.traj_loss_fn = nn.MSELoss()    # 轨迹预测损失（回归）\n",
    "        \n",
    "        # 训练历史记录（用于后续绘图）\n",
    "        self.train_history = {'loss': [], 'intent_acc': [], 'traj_rmse': []}\n",
    "        self.val_history = {'loss': [], 'intent_acc': [], 'traj_rmse': []}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"训练1个epoch，返回平均损失、意图准确率、轨迹RMSE\"\"\"\n",
    "        self.model.train()  # 切换训练模式（启用Dropout等）\n",
    "        total_loss = 0.0\n",
    "        intent_correct = 0\n",
    "        total_samples = 0\n",
    "        total_traj_rmse = 0.0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # 1. 数据移至设备（CPU/GPU）\n",
    "            visual = batch['visual_features'].to(self.device)\n",
    "            motion = batch['motion_features'].to(self.device)\n",
    "            traffic = batch['traffic_features'].to(self.device)\n",
    "            intent_target = batch['left_turn_intent'].to(self.device)\n",
    "            traj_target = batch['target_trajectory'].to(self.device)\n",
    "            batch_size = visual.size(0)\n",
    "            total_samples += batch_size\n",
    "            \n",
    "            # 2. 前向传播\n",
    "            intent_pred, traj_pred = self.model(visual, motion, traffic)\n",
    "            \n",
    "            # 3. 计算损失\n",
    "            intent_loss = self.intent_loss_fn(intent_pred, intent_target)\n",
    "            traj_loss = self.traj_loss_fn(traj_pred, traj_target)\n",
    "            total_batch_loss = intent_loss + 0.5 * traj_loss  # 联合损失（平衡两任务）\n",
    "            total_loss += total_batch_loss.item() * batch_size  # 累计总损失（按batch大小加权）\n",
    "            \n",
    "            # 4. 反向传播与参数更新\n",
    "            self.optimizer.zero_grad()  # 清空梯度\n",
    "            total_batch_loss.backward()  # 计算梯度\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # 梯度裁剪（防梯度爆炸）\n",
    "            self.optimizer.step()  # 更新参数\n",
    "            \n",
    "            # 5. 统计指标\n",
    "            # 意图准确率：预测概率>0.5视为“左转”，与真实标签对比\n",
    "            intent_pred_label = (intent_pred > 0.5).float()\n",
    "            intent_correct += (intent_pred_label == intent_target).sum().item()\n",
    "            # 轨迹RMSE：每个样本的轨迹误差均方根\n",
    "            traj_rmse = torch.sqrt(torch.mean((traj_pred - traj_target) ** 2, dim=[1,2])).mean()\n",
    "            total_traj_rmse += traj_rmse.item() * batch_size\n",
    "        \n",
    "        # 计算当前epoch的平均指标\n",
    "        avg_loss = total_loss / total_samples\n",
    "        intent_acc = intent_correct / total_samples\n",
    "        avg_traj_rmse = total_traj_rmse / total_samples\n",
    "        return avg_loss, intent_acc, avg_traj_rmse\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"验证1个epoch，逻辑与train_epoch类似，但不更新参数\"\"\"\n",
    "        self.model.eval()  # 切换验证模式（禁用Dropout等）\n",
    "        total_loss = 0.0\n",
    "        intent_correct = 0\n",
    "        total_samples = 0\n",
    "        total_traj_rmse = 0.0\n",
    "        \n",
    "        with torch.no_grad():  # 禁用梯度计算（节省内存+加速）\n",
    "            for batch in self.val_loader:\n",
    "                # 1. 数据移至设备\n",
    "                visual = batch['visual_features'].to(self.device)\n",
    "                motion = batch['motion_features'].to(self.device)\n",
    "                traffic = batch['traffic_features'].to(self.device)\n",
    "                intent_target = batch['left_turn_intent'].to(self.device)\n",
    "                traj_target = batch['target_trajectory'].to(self.device)\n",
    "                batch_size = visual.size(0)\n",
    "                total_samples += batch_size\n",
    "                \n",
    "                # 2. 前向传播\n",
    "                intent_pred, traj_pred = self.model(visual, motion, traffic)\n",
    "                \n",
    "                # 3. 计算损失\n",
    "                intent_loss = self.intent_loss_fn(intent_pred, intent_target)\n",
    "                traj_loss = self.traj_loss_fn(traj_pred, traj_target)\n",
    "                total_batch_loss = intent_loss + 0.5 * traj_loss\n",
    "                total_loss += total_batch_loss.item() * batch_size\n",
    "                \n",
    "                # 4. 统计指标\n",
    "                intent_pred_label = (intent_pred > 0.5).float()\n",
    "                intent_correct += (intent_pred_label == intent_target).sum().item()\n",
    "                traj_rmse = torch.sqrt(torch.mean((traj_pred - traj_target) ** 2, dim=[1,2])).mean()\n",
    "                total_traj_rmse += traj_rmse.item() * batch_size\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        intent_acc = intent_correct / total_samples\n",
    "        avg_traj_rmse = total_traj_rmse / total_samples\n",
    "        return avg_loss, intent_acc, avg_traj_rmse\n",
    "    \n",
    "    def train(self, epochs=100, early_stopping_patience=15):\n",
    "        \"\"\"完整训练流程（含早停机制）\"\"\"\n",
    "        best_val_loss = float('inf')  # 初始最佳验证损失设为无穷大\n",
    "        patience_counter = 0  # 早停计数器（连续多少轮验证损失未下降）\n",
    "        \n",
    "        print(f\"开始训练（设备：{self.device}）\")\n",
    "        print(f\"训练集批次数量：{len(self.train_loader)} | 验证集批次数量：{len(self.val_loader)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            # 1. 训练1轮\n",
    "            train_loss, train_intent_acc, train_traj_rmse = self.train_epoch()\n",
    "            # 2. 验证1轮\n",
    "            val_loss, val_intent_acc, val_traj_rmse = self.validate()\n",
    "            # 3. 学习率调度（根据验证损失调整）\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # 4. 记录训练历史\n",
    "            self.train_history['loss'].append(train_loss)\n",
    "            self.train_history['intent_acc'].append(train_intent_acc)\n",
    "            self.train_history['traj_rmse'].append(train_traj_rmse)\n",
    "            self.val_history['loss'].append(val_loss)\n",
    "            self.val_history['intent_acc'].append(val_intent_acc)\n",
    "            self.val_history['traj_rmse'].append(val_traj_rmse)\n",
    "            \n",
    "            # 5. 打印当前轮结果\n",
    "            print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Train Acc: {train_intent_acc:.3f} | Val Acc: {val_intent_acc:.3f} | \"\n",
    "                  f\"Train RMSE: {train_traj_rmse:.4f} | Val RMSE: {val_traj_rmse:.4f}\")\n",
    "            \n",
    "            # 6. 早停机制（验证损失连续patience轮未下降则停止）\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型（仅在验证损失下降时保存）\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "                print(f\"  → 验证损失下降，保存最佳模型（best_model.pth）\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"  → 验证损失未下降，早停计数器：{patience_counter}/{early_stopping_patience}\")\n",
    "            \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"\\n早停触发！连续{early_stopping_patience}轮验证损失未下降，停止训练\")\n",
    "                break\n",
    "        \n",
    "        print(\"\\n训练完成！\")\n",
    "        return self.train_history, self.val_history\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"绘制训练历史曲线（损失、准确率、RMSE）\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # 1. 损失曲线\n",
    "        axes[0].plot(self.train_history['loss'], label='Train Loss', linewidth=2)\n",
    "        axes[0].plot(self.val_history['loss'], label='Val Loss', linewidth=2)\n",
    "        axes[0].set_title('Training & Validation Loss', fontsize=12)\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        \n",
    "        # 2. 意图准确率曲线\n",
    "        axes[1].plot(self.train_history['intent_acc'], label='Train Acc', linewidth=2)\n",
    "        axes[1].plot(self.val_history['intent_acc'], label='Val Acc', linewidth=2)\n",
    "        axes[1].set_title('Left Turn Intent Accuracy', fontsize=12)\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        \n",
    "        # 3. 轨迹RMSE曲线\n",
    "        axes[2].plot(self.train_history['traj_rmse'], label='Train RMSE', linewidth=2)\n",
    "        axes[2].plot(self.val_history['traj_rmse'], label='Val RMSE', linewidth=2)\n",
    "        axes[2].set_title('Trajectory Prediction RMSE', fontsize=12)\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('RMSE')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')  # 保存图片\n",
    "        print(\"训练历史曲线已保存为 training_history.png\")\n",
    "\n",
    "# -------------------------- 运行验证 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 快速验证训练管理器是否能初始化（需先有数据集和模型）\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 1. 加载数据集（用第二部分的MultiModalDataset）\n",
    "    dataset = MultiModalDataset(data_path=\"dummy.pkl\")\n",
    "    # 2. 拆分训练/验证集（简单拆分10%为验证集）\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    # 3. 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "    # 4. 初始化模型\n",
    "    model = LeftTurnPredictor()\n",
    "    # 5. 初始化训练管理器\n",
    "    trainer = TrainingManager(model, train_loader, val_loader, device=device)\n",
    "    print(\"训练管理器初始化成功！可执行 trainer.train() 开始训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3de53-ab08-45bd-a30e-eba4a339fb59",
   "metadata": {},
   "source": [
    "5、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2738120-183c-4d5a-a638-61ab01062af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2506085858.py, line 205)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 205\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif __name__ == \"__main__\":--\u001b[39m\n                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统 - 第五部分：模型评估+训练执行入口\n",
    "\"\"\"\n",
    "\n",
    "# 依赖说明：必须先执行第一至四部分（确保以下类已定义）\n",
    "# - MultiModalDataset (第二部分)\n",
    "# - LeftTurnPredictor (第三部分)\n",
    "# - TrainingManager (第四部分)\n",
    "# 若单独运行，需复制前三部分的核心类和第四部分的TrainingManager\n",
    "\n",
    "# -------------------------- 模型评估函数（独立功能） --------------------------\n",
    "def evaluate_model(model, test_loader, device, save_path='eval_results.npy'):\n",
    "    \"\"\"\n",
    "    在测试集上评估模型性能（输出意图分类指标+轨迹预测指标）\n",
    "    指标说明：\n",
    "    - 意图分类：准确率、精确率、召回率、F1分数\n",
    "    - 轨迹预测：ADE（平均位移误差）、FDE（最终位移误差）\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换为验证模式（禁用Dropout）\n",
    "    # 存储所有预测结果和真实标签（转CPU+numpy，方便计算指标）\n",
    "    all_intent_pred = []  # 意图预测概率\n",
    "    all_intent_true = []  # 意图真实标签\n",
    "    all_traj_pred = []    # 轨迹预测结果\n",
    "    all_traj_true = []    # 轨迹真实标签\n",
    "    \n",
    "    with torch.no_grad():  # 禁用梯度计算（节省内存+加速）\n",
    "        for batch in test_loader:\n",
    "            # 1. 数据移至计算设备（CPU/GPU）\n",
    "            visual = batch['visual_features'].to(device)\n",
    "            motion = batch['motion_features'].to(device)\n",
    "            traffic = batch['traffic_features'].to(device)\n",
    "            intent_true = batch['left_turn_intent'].to(device)\n",
    "            traj_true = batch['target_trajectory'].to(device)\n",
    "            \n",
    "            # 2. 模型前向传播（仅预测，不更新参数）\n",
    "            intent_pred, traj_pred = model(visual, motion, traffic)\n",
    "            \n",
    "            # 3. 保存结果（展平为1维，方便后续拼接）\n",
    "            all_intent_pred.extend(intent_pred.cpu().numpy().flatten())\n",
    "            all_intent_true.extend(intent_true.cpu().numpy().flatten())\n",
    "            all_traj_pred.extend(traj_pred.cpu().numpy())\n",
    "            all_traj_true.extend(traj_true.cpu().numpy())\n",
    "    \n",
    "    # -------------------------- 1. 计算意图分类指标 --------------------------\n",
    "    # 概率转标签：预测概率>0.5视为“左转”（1），否则为“不左转”（0）\n",
    "    intent_pred_label = (np.array(all_intent_pred) > 0.5).astype(int)\n",
    "    intent_true = np.array(all_intent_true)\n",
    "    \n",
    "    # 用sklearn计算分类指标（zero_division=0避免“无正样本”时报错）\n",
    "    intent_acc = accuracy_score(intent_true, intent_pred_label)\n",
    "    intent_precision = precision_score(intent_true, intent_pred_label, zero_division=0)\n",
    "    intent_recall = recall_score(intent_true, intent_pred_label, zero_division=0)\n",
    "    intent_f1 = f1_score(intent_true, intent_pred_label, zero_division=0)\n",
    "    \n",
    "    # -------------------------- 2. 计算轨迹预测指标 --------------------------\n",
    "    traj_pred = np.array(all_traj_pred)  # 形状：[样本数, 12, 2]（12个时间步，每个步x/y）\n",
    "    traj_true = np.array(all_traj_true)  # 形状：[样本数, 12, 2]\n",
    "    \n",
    "    # ADE（平均位移误差）：所有样本、所有时间步的欧氏距离平均值\n",
    "    ade = np.mean(np.sqrt(np.sum((traj_pred - traj_true) ** 2, axis=2)))\n",
    "    # FDE（最终位移误差）：所有样本最后一个时间步的欧氏距离平均值\n",
    "    fde = np.mean(np.sqrt(np.sum((traj_pred[:, -1, :] - traj_true[:, -1, :]) ** 2, axis=1)))\n",
    "    \n",
    "    # -------------------------- 3. 输出与保存结果 --------------------------\n",
    "    # 打印评估报告\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"模型测试集评估报告\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"【左转意图分类】\")\n",
    "    print(f\"  准确率（Accuracy）: {intent_acc:.4f}\")\n",
    "    print(f\"  精确率（Precision）: {intent_precision:.4f}\")\n",
    "    print(f\"  召回率（Recall）: {intent_recall:.4f}\")\n",
    "    print(f\"  F1分数（F1-Score）: {intent_f1:.4f}\")\n",
    "    print(f\"\\n【轨迹预测】\")\n",
    "    print(f\"  平均位移误差（ADE）: {ade:.4f}\")\n",
    "    print(f\"  最终位移误差（FDE）: {fde:.4f}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 保存结果（numpy格式，可后续用np.load读取分析）\n",
    "    eval_results = {\n",
    "        'intent_accuracy': intent_acc,\n",
    "        'intent_precision': intent_precision,\n",
    "        'intent_recall': intent_recall,\n",
    "        'intent_f1': intent_f1,\n",
    "        'trajectory_ade': ade,\n",
    "        'trajectory_fde': fde\n",
    "    }\n",
    "    np.save(save_path, eval_results)\n",
    "    print(f\"\\n评估结果已保存至：{save_path}\")\n",
    "    return eval_results\n",
    "\n",
    "# -------------------------- 全流程执行入口（主函数） --------------------------\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：整合“数据加载→模型初始化→训练→评估”全流程\n",
    "    可根据需求调整参数（如batch_size、epochs等）\n",
    "    \"\"\"\n",
    "    # -------------------------- 1. 基础参数配置 --------------------------\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 自动选择设备\n",
    "    data_path = \"processed_data/trajectory_sequences.pkl\"  # 真实数据路径（无真实数据时填任意值，用模拟数据）\n",
    "    batch_size = 32  # 批次大小（GPU内存不足时可改小，如16、8）\n",
    "    epochs = 100     # 最大训练轮次\n",
    "    early_stopping_patience = 15  # 早停耐心值（连续15轮验证损失不下降则停止）\n",
    "    test_ratio = 0.1  # 测试集占比（总数据拆分：70%训练+20%验证+10%测试）\n",
    "    \n",
    "    print(f\"===== 车辆左转轨迹预测系统 - 全流程启动 =====\")\n",
    "    print(f\"设备：{device} | 批次大小：{batch_size} | 最大轮次：{epochs}\")\n",
    "    print(f\"数据路径：{data_path} | 测试集占比：{test_ratio}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # -------------------------- 2. 数据加载与拆分 --------------------------\n",
    "    print(\"\\n1. 加载数据集...\")\n",
    "    # 加载数据集（第二部分定义的MultiModalDataset，无真实数据时自动生成模拟数据）\n",
    "    dataset = MultiModalDataset(data_path=data_path)\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"总样本数：{total_samples}\")\n",
    "    \n",
    "    # 拆分训练集、验证集、测试集（按 90%训练验证 + 10%测试 拆分）\n",
    "    test_size = int(total_samples * test_ratio)\n",
    "    train_val_size = total_samples - test_size\n",
    "    train_val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # 固定随机种子，确保拆分结果可复现\n",
    "    )\n",
    "    \n",
    "    # 再拆分训练集和验证集（按 80%训练 + 20%验证 拆分train_val_dataset）\n",
    "    val_size = int(train_val_size * 0.2)\n",
    "    train_size = train_val_size - val_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        train_val_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"数据拆分完成：\")\n",
    "    print(f\"  训练集：{len(train_dataset)} 样本 | 验证集：{len(val_dataset)} 样本 | 测试集：{len(test_dataset)} 样本\")\n",
    "    \n",
    "    # 创建数据加载器（批量读取数据，支持多线程加速）\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    print(f\"数据加载器创建完成：\")\n",
    "    print(f\"  训练集批次：{len(train_loader)} | 验证集批次：{len(val_loader)} | 测试集批次：{len(test_loader)}\")\n",
    "    \n",
    "    # -------------------------- 3. 模型初始化 --------------------------\n",
    "    print(\"\\n2. 初始化模型...\")\n",
    "    model = LeftTurnPredictor()  # 第三部分定义的主模型\n",
    "    model = model.to(device)     # 移至计算设备\n",
    "    print(f\"模型结构：{model.__class__.__name__}\")\n",
    "    # 可选：打印模型参数量（了解模型复杂度）\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"总参数量：{total_params:,} | 可训练参数量：{trainable_params:,}\")\n",
    "    \n",
    "    # -------------------------- 4. 启动训练 --------------------------\n",
    "    print(\"\\n3. 启动训练...\")\n",
    "    # 初始化训练管理器（第四部分定义的TrainingManager）\n",
    "    trainer = TrainingManager(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device\n",
    "    )\n",
    "    # 开始训练（返回训练历史）\n",
    "    train_history, val_history = trainer.train(\n",
    "        epochs=epochs,\n",
    "        early_stopping_patience=early_stopping_patience\n",
    "    )\n",
    "    # 绘制训练历史曲线（保存为图片）\n",
    "    trainer.plot_training_history()\n",
    "    \n",
    "    # -------------------------- 5. 测试集评估 --------------------------\n",
    "    print(\"\\n4. 测试集评估...\")\n",
    "    # 加载训练过程中保存的“最佳模型”（避免用最后一轮可能过拟合的模型）\n",
    "    best_model_path = \"best_model.pth\"\n",
    "    if os.path.exists(best_model_path):\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        model = model.to(device)\n",
    "        print(f\"已加载最佳模型：{best_model_path}\")\n",
    "    else:\n",
    "        print(f\"警告：未找到最佳模型文件 {best_model_path}，使用最后一轮模型评估\")\n",
    "    \n",
    "    # 执行评估\n",
    "    evaluate_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        save_path=\"test_eval_results.npy\"\n",
    "    )\n",
    "    \n",
    "    # -------------------------- 6. 流程结束 --------------------------\n",
    "    print(\"\\n===== 全流程执行完成 =====\")\n",
    "    print(f\"生成文件：\")\n",
    "    print(f\"  - 最佳模型：best_model.pth\")\n",
    "    print(f\"  - 训练历史曲线：training_history.png\")\n",
    "    print(f\"  - 测试集评估结果：test_eval_results.npy\")\n",
    "\n",
    "# -------------------------- 启动全流程 ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca9f32",
   "metadata": {},
   "source": [
    "完整的模型训练脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88f43bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 455) (3823444231.py, line 455)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 455\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m停止训练\")\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 455)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "车辆左转轨迹预测系统\n",
    "基于多模态深度学习的实现框架\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "# 评估所需 sklearn 指标库\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------- 数据集类 --------------------------\n",
    "class MultiModalDataset(Dataset):\n",
    "    \"\"\"修改后的多模态数据集类，适配轨迹序列数据\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str):\n",
    "        \"\"\"\n",
    "        初始化数据集（直接加载处理好的轨迹序列）\n",
    "        Args:\n",
    "            data_path: trajectory_sequences.pkl 的路径\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.sequences = self.load_data()  # 加载序列数据\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"加载预处理生成的轨迹序列\"\"\"\n",
    "        with open(self.data_path, 'rb') as f:\n",
    "            sequences = pickle.load(f)\n",
    "        return sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"从序列中提取样本特征\"\"\"\n",
    "        seq = self.sequences[idx]\n",
    "        \n",
    "        # 运动特征：拼接历史轨迹的x、y、速度、加速度等\n",
    "        motion_features = np.concatenate([\n",
    "            seq['history_x'],\n",
    "            seq['history_y'],\n",
    "            seq['history_velocity'],\n",
    "            seq['history_acceleration'],\n",
    "            seq['history_heading'],\n",
    "            seq['history_angular_velocity']\n",
    "        ])\n",
    "        \n",
    "        # 视觉特征（简化：可根据实际需求从图像中提取，此处用随机值占位）\n",
    "        visual_features = np.random.randn(64)  # 需与VisualEncoder输入维度匹配\n",
    "        \n",
    "        # 交通环境特征（扩展车道和车辆类型特征）\n",
    "        traffic_features = np.concatenate([\n",
    "            np.array([seq['lane_id']]),\n",
    "            np.array([seq['vehicle_class']]),\n",
    "            np.random.randn(30)  # 补充随机特征至32维，与TrafficEncoder输入匹配\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'visual_features': torch.FloatTensor(visual_features),\n",
    "            'motion_features': torch.FloatTensor(motion_features),\n",
    "            'traffic_features': torch.FloatTensor(traffic_features),\n",
    "            'left_turn_intent': torch.FloatTensor([seq['left_turn_intent']]),  # 1.0表示左转\n",
    "            'target_trajectory': torch.FloatTensor(np.column_stack([seq['future_x'], seq['future_y']]))\n",
    "        }\n",
    "\n",
    "# -------------------------- 模型组件 --------------------------\n",
    "class VisualEncoder(nn.Module):\n",
    "    \"\"\"视觉特征编码器\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 64, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class MotionEncoder(nn.Module):\n",
    "    \"\"\"运动特征编码器\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, num_layers: int = 2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim // 8,  # 8个时间步\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 重塑输入为(batch_size, seq_len, feature_dim)\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = 8\n",
    "        feature_dim = x.size(1) // seq_len\n",
    "        x = x.view(batch_size, seq_len, feature_dim)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        # 使用最后一个时间步的输出\n",
    "        return self.fc(output[:, -1, :])\n",
    "\n",
    "class TrafficEncoder(nn.Module):\n",
    "    \"\"\"交通环境特征编码器\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 32, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"注意力融合模块\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # 自注意力机制\n",
    "        self.query = nn.Linear(feature_dim, feature_dim)\n",
    "        self.key = nn.Linear(feature_dim, feature_dim)\n",
    "        self.value = nn.Linear(feature_dim, feature_dim)\n",
    "        \n",
    "        # 跨模态注意力\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=feature_dim,\n",
    "            num_heads=8,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # 输出投影\n",
    "        self.output_proj = nn.Linear(feature_dim * 3, feature_dim)\n",
    "    \n",
    "    def forward(self, visual_feat, motion_feat, traffic_feat):\n",
    "        # 堆叠特征\n",
    "        features = torch.stack([visual_feat, motion_feat, traffic_feat], dim=1)\n",
    "        \n",
    "        # 自注意力\n",
    "        Q = self.query(features)\n",
    "        K = self.key(features)\n",
    "        V = self.value(features)\n",
    "        \n",
    "        attention_weights = torch.softmax(\n",
    "            torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.feature_dim), \n",
    "            dim=-1\n",
    "        )\n",
    "        attended_features = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # 跨模态注意力\n",
    "        attended_features = attended_features.transpose(0, 1)\n",
    "        cross_attended, _ = self.cross_attention(\n",
    "            attended_features, attended_features, attended_features\n",
    "        )\n",
    "        cross_attended = cross_attended.transpose(0, 1)\n",
    "        \n",
    "        # 融合特征\n",
    "        fused_features = cross_attended.view(cross_attended.size(0), -1)\n",
    "        output = self.output_proj(fused_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class IntentClassifier(nn.Module):\n",
    "    \"\"\"左转意图分类器\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 128, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class TrajectoryDecoder(nn.Module):\n",
    "    \"\"\"轨迹预测解码器\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 129, hidden_dim: int = 128, output_dim: int = 2, seq_len: int = 12):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # LSTM解码器\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # 初始隐藏状态\n",
    "        self.init_hidden = nn.Linear(input_dim, hidden_dim * 2 * 2)  # 2 layers * 2 (h,c)\n",
    "    \n",
    "    def forward(self, fused_features, intent_prob):\n",
    "        batch_size = fused_features.size(0)\n",
    "        \n",
    "        # 结合意图信息\n",
    "        input_features = torch.cat([fused_features, intent_prob], dim=1)\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        init_states = self.init_hidden(input_features)\n",
    "        h0 = init_states[:, :self.hidden_dim*2].view(2, batch_size, self.hidden_dim).contiguous()\n",
    "        c0 = init_states[:, self.hidden_dim*2:].view(2, batch_size, self.hidden_dim).contiguous()\n",
    "        \n",
    "        # 解码预测轨迹\n",
    "        outputs = []\n",
    "        hidden = (h0, c0)\n",
    "        \n",
    "        # 第一步输入\n",
    "        decoder_input = input_features.unsqueeze(1)\n",
    "        \n",
    "        for t in range(self.seq_len):\n",
    "            output, hidden = self.lstm(decoder_input, hidden)\n",
    "            trajectory_point = self.output_layer(output)\n",
    "            outputs.append(trajectory_point)\n",
    "            \n",
    "            # 下一步的输入\n",
    "            decoder_input = torch.cat([\n",
    "                fused_features.unsqueeze(1), \n",
    "                intent_prob.unsqueeze(1),\n",
    "                trajectory_point\n",
    "            ], dim=2)\n",
    "        \n",
    "        # 拼接所有输出\n",
    "        trajectory = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "class LeftTurnPredictor(nn.Module):\n",
    "    \"\"\"左转轨迹预测主模型\"\"\"\n",
    "    \n",
    "    def __init__(self, visual_dim: int = 64, motion_dim: int = 48, traffic_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 特征编码器\n",
    "        self.visual_encoder = VisualEncoder(visual_dim)\n",
    "        self.motion_encoder = MotionEncoder(motion_dim)\n",
    "        self.traffic_encoder = TrafficEncoder(traffic_dim)\n",
    "        \n",
    "        # 注意力融合\n",
    "        self.attention_fusion = AttentionFusion()\n",
    "        \n",
    "        # 意图分类器\n",
    "        self.intent_classifier = IntentClassifier()\n",
    "        \n",
    "        # 轨迹解码器\n",
    "        self.trajectory_decoder = TrajectoryDecoder()\n",
    "    \n",
    "    def forward(self, visual_feat, motion_feat, traffic_feat):\n",
    "        # 特征编码\n",
    "        visual_encoded = self.visual_encoder(visual_feat)\n",
    "        motion_encoded = self.motion_encoder(motion_feat)\n",
    "        traffic_encoded = self.traffic_encoder(traffic_feat)\n",
    "        \n",
    "        # 多模态融合\n",
    "        fused_features = self.attention_fusion(\n",
    "            visual_encoded, motion_encoded, traffic_encoded\n",
    "        )\n",
    "        \n",
    "        # 意图预测\n",
    "        intent_prob = self.intent_classifier(fused_features)\n",
    "        \n",
    "        # 轨迹预测\n",
    "        trajectory = self.trajectory_decoder(fused_features, intent_prob)\n",
    "        \n",
    "        return intent_prob, trajectory\n",
    "\n",
    "# -------------------------- 训练管理器 --------------------------\n",
    "class TrainingManager:\n",
    "    \"\"\"训练管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # 优化器\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        \n",
    "        # 学习率调度器\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=10, factor=0.5\n",
    "        )\n",
    "        \n",
    "        # 损失函数\n",
    "        self.intent_loss_fn = nn.BCELoss()\n",
    "        self.trajectory_loss_fn = nn.MSELoss()\n",
    "        \n",
    "        # 训练历史\n",
    "        self.train_history = {'loss': [], 'intent_acc': [], 'traj_error': []}\n",
    "        self.val_history = {'loss': [], 'intent_acc': [], 'traj_error': []}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        intent_correct = 0\n",
    "        total_samples = 0\n",
    "        traj_error = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            # 数据移到设备\n",
    "            visual_feat = batch['visual_features'].to(self.device)\n",
    "            motion_feat = batch['motion_features'].to(self.device)\n",
    "            traffic_feat = batch['traffic_features'].to(self.device)\n",
    "            intent_target = batch['left_turn_intent'].to(self.device)\n",
    "            traj_target = batch['target_trajectory'].to(self.device)\n",
    "            \n",
    "            # 前向传播\n",
    "            intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)\n",
    "            \n",
    "            # 计算损失\n",
    "            intent_loss = self.intent_loss_fn(intent_pred, intent_target)\n",
    "            traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)\n",
    "            \n",
    "            # 联合损失\n",
    "            total_batch_loss = intent_loss + 0.5 * traj_loss\n",
    "            \n",
    "            # 反向传播\n",
    "            self.optimizer.zero_grad()\n",
    "            total_batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            total_loss += total_batch_loss.item()\n",
    "            intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()\n",
    "            total_samples += intent_target.size(0)\n",
    "            traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        intent_acc = intent_correct / total_samples\n",
    "        avg_traj_error = traj_error / len(self.train_loader)\n",
    "        \n",
    "        return avg_loss, intent_acc, avg_traj_error\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"验证\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        intent_correct = 0\n",
    "        total_samples = 0\n",
    "        traj_error = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                # 数据移到设备\n",
    "                visual_feat = batch['visual_features'].to(self.device)\n",
    "                motion_feat = batch['motion_features'].to(self.device)\n",
    "                traffic_feat = batch['traffic_features'].to(self.device)\n",
    "                intent_target = batch['left_turn_intent'].to(self.device)\n",
    "                traj_target = batch['target_trajectory'].to(self.device)\n",
    "                \n",
    "                # 前向传播\n",
    "                intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)\n",
    "                \n",
    "                # 计算损失\n",
    "                intent_loss = self.intent_loss_fn(intent_pred, intent_target)\n",
    "                traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)\n",
    "                total_batch_loss = intent_loss + 0.5 * traj_loss\n",
    "                \n",
    "                # 统计\n",
    "                total_loss += total_batch_loss.item()\n",
    "                intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()\n",
    "                total_samples += intent_target.size(0)\n",
    "                traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        intent_acc = intent_correct / total_samples\n",
    "        avg_traj_error = traj_error / len(self.val_loader)\n",
    "        \n",
    "        return avg_loss, intent_acc, avg_traj_error\n",
    "    \n",
    "    def train(self, epochs: int = 100, early_stopping_patience: int = 15):\n",
    "        \"\"\"完整训练流程（无截断）\"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(\"开始训练...\")\n",
    "        print(f\"训练集大小: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"验证集大小: {len(self.val_loader.dataset)}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # 训练\n",
    "            train_loss, train_intent_acc, train_traj_error = self.train_epoch()\n",
    "            \n",
    "            # 验证\n",
    "            val_loss, val_intent_acc, val_traj_error = self.validate()\n",
    "            \n",
    "            # 学习率调度\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # 记录历史\n",
    "            self.train_history['loss'].append(train_loss)\n",
    "            self.train_history['intent_acc'].append(train_intent_acc)\n",
    "            self.train_history['traj_error'].append(train_traj_error)\n",
    "            \n",
    "            self.val_history['loss'].append(val_loss)\n",
    "            self.val_history['intent_acc'].append(val_intent_acc)\n",
    "            self.val_history['traj_error'].append(val_traj_error)\n",
    "            \n",
    "            # 打印进度\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Intent Acc: {val_intent_acc:.3f} | \"\n",
    "                  f\"Traj Error: {val_traj_error:.3f}\")\n",
    "            \n",
    "            # 早停检查\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"早停触发，在第 {epoch+1} 轮停止训练\")\n",
    "                停止训练\")\n",
    "                break\n",
    "        \n",
    "        print(\"训练完成！\")\n",
    "        return self.train_history, self.val_history\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"绘制训练历史\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # 损失曲线\n",
    "        axes[0].plot(self.train_history['loss'], label='Train Loss')\n",
    "        axes[0].plot(self.val_history['loss'], label='Val Loss')\n",
    "        axes[0].set_title('Training Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "        \n",
    "        # 意图识别准确率\n",
    "        axes[1].plot(self.train_history['intent_acc'], label='Train Acc')\n",
    "        axes[1].plot(self.val_history['intent_acc'], label='Val Acc')\n",
    "        axes[1].set_title('Intent Classification Accuracy')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        # 轨迹预测误差\n",
    "        axes[2].plot(self.train_history['traj_error'], label='Train Error')\n",
    "        axes[2].plot(self.val_history['traj_error'], label='Val Error')\n",
    "        axes[2].set_title('Trajectory Prediction Error')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('RMSE')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# -------------------------- 模型评估函数（新增） --------------------------\n",
    "def evaluate_model(model, test_loader, device, result_save_path='full_model_eval_results.npy'):\n",
    "    \"\"\"\n",
    "    评估模型在测试集上的性能\n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        test_loader: 测试集数据加载器\n",
    "        device: 计算设备\n",
    "        result_save_path: 评估结果保存路径\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_intent_preds = []\n",
    "    all_intent_labels = []\n",
    "    all_traj_preds = []\n",
    "    all_traj_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # 数据移到设备\n",
    "            visual_feat = batch['visual_features'].to(device)\n",
    "            motion_feat = batch['motion_features'].to(device)\n",
    "            traffic_feat = batch['traffic_features'].to(device)\n",
    "            intent_target = batch['left_turn_intent'].to(device)\n",
    "            traj_target = batch['target_trajectory'].to(device)\n",
    "            \n",
    "            # 模型预测\n",
    "            intent_pred, traj_pred = model(visual_feat, motion_feat, traffic_feat)\n",
    "            \n",
    "            # 收集结果\n",
    "            all_intent_preds.extend((intent_pred > 0.5).cpu().numpy().flatten())\n",
    "            all_intent_labels.extend(intent_target.cpu().numpy().flatten())\n",
    "            all_traj_preds.extend(traj_pred.cpu().numpy())\n",
    "            all_traj_labels.extend(traj_target.cpu().numpy())\n",
    "    \n",
    "    # 计算意图识别指标\n",
    "    intent_acc = accuracy_score(all_intent_labels, all_intent_preds)\n",
    "    intent_f1 = f1_score(all_intent_labels, all_intent_preds)\n",
    "    intent_precision = precision_score(all_intent_labels, all_intent_preds)\n",
    "    intent_recall = recall_score(all_intent_labels, all_intent_preds)\n",
    "    \n",
    "    # 计算轨迹预测指标 (ADE和FDE)\n",
    "    traj_preds_np = np.array(all_traj_preds)\n",
    "    traj_labels_np = np.array(all_traj_labels)\n",
    "    \n",
    "    # 平均位移误差 (ADE)\n",
    "    ade = np.mean(np.sqrt(np.sum((traj_preds_np - traj_labels_np) ** 2, axis=2)))\n",
    "    \n",
    "    # 最终位移误差 (FDE)\n",
    "    fde = np.mean(np.sqrt(np.sum((traj_preds_np[:, -1, :] - traj_labels_np[:, -1, :]) ** 2, axis=1)))\n",
    "    \n",
    "    # 打印评估结果\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"完整版模型评估结果（测试集）\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"左转意图识别 - 准确率: {intent_acc:.3f} | 精确率: {intent_precision:.3f} | 召回率: {intent_recall:.3f} | F1分数: {intent_f1:.3f}\")\n",
    "    print(f\"轨迹预测       - ADE: {ade:.3f} | FDE: {fde:.3f}\")\n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "    \n",
    "    # 保存评估结果\n",
    "    results = {\n",
    "        'intent_accuracy': intent_acc,\n",
    "        'intent_f1': intent_f1,\n",
    "        'intent_precision': intent_precision,\n",
    "        'intent_recall': intent_recall,\n",
    "        'ade': ade,\n",
    "        'fde': fde\n",
    "    }\n",
    "    np.save(result_save_path, results)\n",
    "    print(f\"评估结果已保存至：{result_save_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------- 训练执行代码 --------------------------\n",
    "def main():\n",
    "    # 1. 配置参数\n",
    "    data_path = \"processed_data/trajectory_sequences.pkl\"  # 轨迹序列路径\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 2. 加载数据集\n",
    "    dataset = MultiModalDataset(data_path)\n",
    "    print(f\"总样本数: {len(dataset)}\")\n",
    "    \n",
    "    # 3. 划分训练集（70%）、验证集（15%）和测试集（15%）\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    # 4. 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    print(f\"训练集样本: {len(train_dataset)} | 验证集样本: {len(val_dataset)} | 测试集样本: {len(test_dataset)}\")\n",
    "    \n",
    "    # 5. 初始化模型（运动特征维度 = 8*6=48）\n",
    "    model = LeftTurnPredictor(visual_dim=64, motion_dim=48, traffic_dim=32)\n",
    "    \n",
    "    # 6. 初始化训练管理器并启动训练\n",
    "    trainer = TrainingManager(model, train_loader, val_loader, device=device)\n",
    "    train_history, val_history = trainer.train(epochs=epochs)\n",
    "    \n",
    "    # 7. 绘制训练历史\n",
    "    trainer.plot_training_history()\n",
    "    \n",
    "    # 8. 加载最佳模型并在测试集上评估（新增）\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.to(device)\n",
    "    evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # 9. 保存训练历史\n",
    "    torch.save({\n",
    "        'train_history': train_history,\n",
    "        'val_history': val_history\n",
    "    }, 'training_history.pth')\n",
    "    print(\"训练完成，所有结果已保存\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b592b06-ddf9-4e27-bafe-ff7cbcbed19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
