#!/usr/bin/env python3
"""
è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ
åŸºäºå†å²è½¨è¿¹çš„çœŸæ­£å·¦è½¬æ„å›¾é¢„æµ‹æ¡†æ¶
é‡è¦æ›´æ–°ï¼šå®ç°åŸºäºå†å²è½¨è¿¹é¢„æµ‹æœªæ¥å·¦è½¬æ„å›¾çš„çœŸæ­£é¢„æµ‹ä»»åŠ¡
"""

import sys
import os
import time
from typing import Dict, List, Tuple, Optional
import yaml
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# å¯¼å…¥å·¦è½¬æ•°æ®åˆ†æè„šæœ¬
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from å·¦è½¬æ•°æ®åˆ†æè„šæœ¬ import LeftTurnAnalyzer


# =============================
# é…ç½®åŠ è½½å™¨
# =============================
def load_config(config_path=None):
    # å¦‚æœæ²¡æœ‰æä¾›é…ç½®è·¯å¾„ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„config.yaml
    if config_path is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(script_dir, "config.yaml")
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    return config


# =============================
# æ•°æ®ç®¡é“ç±»ï¼šç»“åˆ LeftTurnAnalyzer
# =============================
class DataPipeline:
    """æ•°æ®å¤„ç†ç®¡é“ç±»ï¼Œç”¨äºç»Ÿä¸€ç®¡ç†ä»åŸå§‹æ•°æ®åˆ°æ•°æ®é›†çš„è½¬æ¢è¿‡ç¨‹"""
    def __init__(self, raw_path):
        self.raw_path = raw_path
    
    def build_dataset(self, int_id=None, approach=None, history_length=30, prediction_horizon=12, 
                     min_trajectory_length=100, use_prediction_mode=True, max_samples=None):
        """
        ä»åŸå§‹æ•°æ®æ„å»ºæ•°æ®é›†
        
        Args:
            int_id: è·¯å£ID
            approach: å…¥å£æ–¹å‘
            history_length: å†å²è½¨è¿¹é•¿åº¦
            prediction_horizon: é¢„æµ‹æ—¶é—´èŒƒå›´
            min_trajectory_length: æœ€å°è½¨è¿¹é•¿åº¦
            use_prediction_mode: æ˜¯å¦ä½¿ç”¨é¢„æµ‹æ¨¡å¼
            max_samples: æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
        
        Returns:
            MultiModalDataset: æ„å»ºå¥½çš„æ•°æ®é›†å®ä¾‹
        """
        print("ğŸ”„ å¼€å§‹æ„å»ºæ•°æ®é›†...")
        
        # åˆå§‹åŒ–LeftTurnAnalyzeræ—¶ä¼ å…¥è·¯å£IDå’Œå…¥å£æ–¹å‘
        analyzer = LeftTurnAnalyzer(self.raw_path, intersection_id=int_id, entrance_direction=approach)
        
        # åŠ è½½æ•°æ®
        analyzer.load_data()
        
        # å¦‚æœæ˜¯æ— ç‰¹å®šè·¯å£IDçš„æƒ…å†µï¼Œç¡®ä¿selected_entranceä¸ºNoneä»¥ä¾¿ç­›é€‰æ‰€æœ‰å·¦è½¬è½¦è¾†
        if int_id is None:
            analyzer.selected_entrance = None
        
        # ç­›é€‰å·¦è½¬æ•°æ®
        success = analyzer.filter_entrance_data()
        if not success:
            # å¦‚æœç­›é€‰å¤±è´¥ä½†æ•°æ®ä¸ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·¦è½¬è½¦è¾†
            if analyzer.raw_data is not None and len(analyzer.raw_data) > 0:
                print("ğŸ” å°è¯•ç­›é€‰æ‰€æœ‰å·¦è½¬è½¦è¾†...")
                if 'movement' in analyzer.raw_data.columns:
                    left_turn_data = analyzer.raw_data[analyzer.raw_data['movement'] == 2]
                    if len(left_turn_data) > 0:
                        analyzer.raw_data = left_turn_data
                        print(f"âœ… å·²ç­›é€‰å·¦è½¬è½¦è¾†æ•°æ®: {len(analyzer.raw_data)} æ¡è®°å½•, {len(analyzer.raw_data['vehicle_id'].unique())} è¾†è½¦")
                    else:
                        raise ValueError("æ•°æ®ç­›é€‰å¤±è´¥ï¼šæœªæ‰¾åˆ°å·¦è½¬è½¦è¾†æ•°æ®")
                else:
                    raise ValueError("æ•°æ®ç­›é€‰å¤±è´¥ï¼šæ•°æ®ä¸­æ²¡æœ‰'movement'åˆ—")
            else:
                raise ValueError("æ•°æ®ç­›é€‰å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å£IDå’Œæ–¹å‘æ˜¯å¦æ­£ç¡®")
        
        # è·å–ç­›é€‰åçš„å·¦è½¬æ•°æ®
        filtered = analyzer.raw_data
        print(f"âœ… æ•°æ®ç­›é€‰å®Œæˆ: {len(filtered)} æ¡è®°å½•, {len(filtered['vehicle_id'].unique())} è¾†è½¦")
        
        # ç›´æ¥ä½¿ç”¨DataFrameåˆ›å»ºæ•°æ®é›†ï¼Œé¿å…ä¸´æ—¶æ–‡ä»¶
        dataset = MultiModalDataset(
            data=filtered,  # ç›´æ¥ä¼ é€’DataFrame
            history_length=history_length,
            prediction_horizon=prediction_horizon,
            min_trajectory_length=min_trajectory_length,
            use_prediction_mode=use_prediction_mode,
            max_samples=max_samples
        )
        
        return dataset
    
    def get_dataset_statistics(self, dataset):
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if hasattr(dataset, 'analyze_dataset'):
            return dataset.analyze_dataset()
        return {}
    
    def split_dataset(self, dataset, train_ratio=0.7, val_ratio=0.15):
        """
        å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
        
        Returns:
            tuple: (train_dataset, val_dataset, test_dataset)
        """
        dataset_size = len(dataset)
        train_size = int(train_ratio * dataset_size)
        val_size = int(val_ratio * dataset_size)
        test_size = dataset_size - train_size - val_size
        
        print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ={train_size}, éªŒè¯={val_size}, æµ‹è¯•={test_size}")
        
        train_dataset = torch.utils.data.Subset(dataset, range(train_size))
        val_dataset = torch.utils.data.Subset(dataset, range(train_size, train_size + val_size))
        test_dataset = torch.utils.data.Subset(dataset, range(train_size + val_size, dataset_size))
        
        return train_dataset, val_dataset, test_dataset
    

class MockDataset(Dataset):
    """æ¨¡æ‹Ÿæ•°æ®é›†ç±»ï¼Œç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•"""
    def __init__(self, size=1000, history_length=30):
        self.size = size
        self.history_length = history_length
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        # ç”Ÿæˆä¸å®é™…æ•°æ®ç»´åº¦ä¸€è‡´çš„æ¨¡æ‹Ÿæ•°æ®
        # visual_features: [history_length, 32]
        # motion_features: [history_length, 6]
        # traffic_features: [history_length, 4]
        # target_trajectory: [12, 2] (é¢„æµ‹12ä¸ªç‚¹çš„è½¨è¿¹)
        return {
            'visual_features': torch.randn(self.history_length, 32),
            'motion_features': torch.randn(self.history_length, 6),
            'traffic_features': torch.randn(self.history_length, 4),
            'left_turn_intent': torch.rand(1),
            'target_trajectory': torch.randn(12, 2)
        }

class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†ç±» - æ”¯æŒçœŸæ­£çš„å·¦è½¬é¢„æµ‹ä»»åŠ¡"""
    
    def __init__(self, data_path: str = None, data: pd.DataFrame = None, history_length: int = 30, prediction_horizon: int = 12, 
                 min_trajectory_length: int = 100, use_prediction_mode: bool = True, max_samples: Optional[int] = None):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ (ä¸dataå‚æ•°äºŒé€‰ä¸€)
            data: ç›´æ¥æä¾›çš„DataFrameæ•°æ®
            history_length: å†å²è½¨è¿¹é•¿åº¦ (å¸§æ•°ï¼Œé»˜è®¤30å¸§=3ç§’)
            prediction_horizon: é¢„æµ‹æ—¶é—´èŒƒå›´ (å¸§æ•°ï¼Œé»˜è®¤50å¸§=5ç§’)
            min_trajectory_length: æœ€å°è½¨è¿¹é•¿åº¦è¦æ±‚
            use_prediction_mode: æ˜¯å¦ä½¿ç”¨çœŸæ­£çš„é¢„æµ‹æ¨¡å¼
            max_samples: æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ï¼Œç”¨äºç¼©å‡æµ‹è¯•è°ƒè¯•æ—¶é—´
        """
        # å‚æ•°æ£€æŸ¥
        if data is None and data_path is None:
            raise ValueError("å¿…é¡»æä¾›data_pathæˆ–dataå‚æ•°")
            
        self.data_path = data_path
        self.history_length = history_length
        self.prediction_horizon = prediction_horizon
        self.min_trajectory_length = min_trajectory_length
        self.use_prediction_mode = use_prediction_mode
        self.max_samples = max_samples  
        
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™åŸæœ‰å‚æ•°å
        self.sequence_length = history_length
        self.prediction_length = prediction_horizon
        
        print(f"ğŸš€ åˆå§‹åŒ–æ•°æ®é›† (é¢„æµ‹æ¨¡å¼: {'å¼€å¯' if use_prediction_mode else 'å…³é—­'})")
        print(f"   å†å²é•¿åº¦: {history_length}å¸§ ({history_length*0.1:.1f}ç§’)")
        print(f"   é¢„æµ‹èŒƒå›´: {prediction_horizon}å¸§ ({prediction_horizon*0.1:.1f}ç§’)")
        
        # ä¼˜å…ˆä½¿ç”¨ç›´æ¥æä¾›çš„DataFrame
        if data is not None:
            self.raw_data = data
            print(f"âœ… ç›´æ¥åŠ è½½DataFrameæ•°æ®: {len(data)} æ¡è®°å½•, {len(data['vehicle_id'].unique())} è¾†è½¦")
        else:
            self.raw_data = self.load_data()
        
        if use_prediction_mode:
            self.samples = self._build_prediction_samples()
            print(f"âœ… æ„å»ºé¢„æµ‹æ ·æœ¬: {len(self.samples)} ä¸ª")
        else:
            # å…¼å®¹æ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            self.data = self.raw_data
        
    def load_data(self):
        """åŠ è½½é¢„å¤„ç†å¥½çš„å·¦è½¬æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½é¢„å¤„ç†æ•°æ®: {self.data_path}")
        
        # åŠ è½½ç”±æ•°æ®é¢„å¤„ç†ç®¡é“ç”Ÿæˆçš„æ•°æ®
        data = pd.read_csv(self.data_path)
        
        print(f"æ•°æ®åŠ è½½æˆåŠŸ: {len(data)} æ¡è®°å½•, {len(data['vehicle_id'].unique())} è¾†è½¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—
        required_columns = ['vehicle_id', 'frame_id', 'local_x', 'local_y']
        missing_columns = [col for col in required_columns if col not in data.columns]
        if missing_columns:
            raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        
        # å¦‚æœæœ‰è´¨é‡æ ‡è®°ï¼Œä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ•°æ®
        if 'is_high_quality' in data.columns:
            high_quality_data = data[data['is_high_quality'] == True]
            if len(high_quality_data) > 0:
                print(f"ä½¿ç”¨é«˜è´¨é‡æ•°æ®: {len(high_quality_data)} æ¡è®°å½•, {len(high_quality_data['vehicle_id'].unique())} è¾†è½¦")
                data = high_quality_data
        
        # æŒ‰è½¦è¾†IDå’Œå¸§IDæ’åº
        data = data.sort_values(['vehicle_id', 'frame_id'])
        
        return data
    
    def _build_prediction_samples(self):
        """æ„å»ºçœŸæ­£çš„é¢„æµ‹æ ·æœ¬"""
        samples = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰movementå­—æ®µ
        if 'movement' not in self.raw_data.columns:
            print("âš ï¸  æ•°æ®ä¸­æ²¡æœ‰movementå­—æ®µï¼Œæ— æ³•æ„å»ºé¢„æµ‹æ ·æœ¬")
            return []
        
        # æŒ‰è½¦è¾†åˆ†ç»„
        vehicle_groups = self.raw_data.groupby('vehicle_id')
        
        print("ğŸ”„ æ„å»ºé¢„æµ‹æ ·æœ¬...")
        valid_vehicles = 0
        total_vehicles = len(vehicle_groups)
        
        # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
        with tqdm(total=total_vehicles, desc="å¤„ç†è½¦è¾†æ•°æ®", unit="è¾†") as pbar:
            for vehicle_id, vehicle_data in vehicle_groups:
                # æŒ‰æ—¶é—´æ’åº
                vehicle_data = vehicle_data.sort_values('frame_id').reset_index(drop=True)
                
                # æ£€æŸ¥è½¨è¿¹é•¿åº¦
                if len(vehicle_data) < self.min_trajectory_length:
                    pbar.update(1)
                    continue
                    
                valid_vehicles += 1
                
                # æ»‘åŠ¨çª—å£æ„å»ºæ ·æœ¬
                total_length = self.history_length + self.prediction_horizon
                possible_windows = len(vehicle_data) - total_length + 1
                
                for i in range(possible_windows):
                    # å†å²è½¨è¿¹ (è¾“å…¥)
                    history_data = vehicle_data.iloc[i:i+self.history_length].copy()
                    
                    # æœªæ¥è½¨è¿¹ (ç”¨äºæ ‡ç­¾)
                    future_data = vehicle_data.iloc[i+self.history_length:i+total_length].copy()
                    
                    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                    if len(history_data) != self.history_length or len(future_data) != self.prediction_horizon:
                        continue
                    
                    # æå–æ ‡ç­¾ (æœªæ¥æ˜¯å¦æœ‰å·¦è½¬)
                    future_movements = future_data['movement'].values
                    has_left_turn = np.any(future_movements == 2.0)  # 2.0 = å·¦è½¬
                    
                    # é¢å¤–ä¿¡æ¯
                    sample_info = {
                        'vehicle_id': vehicle_id,
                        'start_frame': history_data['frame_id'].iloc[0],
                        'end_frame': future_data['frame_id'].iloc[-1],
                        'history_trajectory': history_data[['local_x', 'local_y']].values,
                        'future_trajectory': future_data[['local_x', 'local_y']].values,
                        'future_movements': future_movements  # ä¿ç•™åŸå§‹movementå€¼ç”¨äºéªŒè¯
                    }
                    
                    samples.append({
                        'history_data': history_data,
                        'future_data': future_data,
                        'label': int(has_left_turn),
                        'info': sample_info
                    })
                    
                    # å¦‚æœè¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ï¼Œæå‰ç»“æŸ
                    if self.max_samples and len(samples) >= self.max_samples:
                        print(f"ğŸ”„ å·²è¾¾åˆ°æœ€å¤§æ ·æœ¬æ•°é™åˆ¶ ({self.max_samples}ä¸ªæ ·æœ¬)")
                        pbar.update(total_vehicles - pbar.n)  # æ›´æ–°è¿›åº¦æ¡åˆ°100%
                        return samples[:self.max_samples]
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                pbar.set_postfix({
                    'æœ‰æ•ˆè½¦è¾†': valid_vehicles,
                    'æ ·æœ¬æ•°': len(samples)
                })
        
        print(f"âœ… æ„å»ºå®Œæˆï¼Œæœ‰æ•ˆè½¦è¾†: {valid_vehicles} è¾†, æ€»æ ·æœ¬æ•°: {len(samples)} ä¸ª")
        return samples
    
    def __len__(self):
        if self.use_prediction_mode and hasattr(self, 'samples'):
            return len(self.samples)
        else:
            return len(self.data) - self.sequence_length - self.prediction_length + 1
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬"""
        if self.use_prediction_mode and hasattr(self, 'samples'):
            # çœŸæ­£çš„é¢„æµ‹æ¨¡å¼
            return self._get_prediction_sample(idx)
        else:
            # å…¼å®¹æ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            return self._get_legacy_sample(idx)
    
    def _get_prediction_sample(self, idx):
        """è·å–é¢„æµ‹æ ·æœ¬"""
        if idx >= len(self.samples):
            idx = idx % len(self.samples)
        
        sample = self.samples[idx]
        history_data = sample['history_data']
        future_data = sample['future_data']
        label = sample['label']
        
        # æå–å¤šæ¨¡æ€ç‰¹å¾ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        visual_features = self.extract_visual_features(history_data)
        motion_features = self.extract_motion_features(history_data)
        traffic_features = self.extract_traffic_features(history_data)
        
        # ç›®æ ‡è½¨è¿¹ï¼ˆæœªæ¥è½¨è¿¹ï¼‰
        target_trajectory = future_data[['local_x', 'local_y']].values
        
        # æå–æœªæ¥movementå­—æ®µä½œä¸ºæœªæ¥å€¼
        future_movements = sample['info'].get('future_movements', np.array([]))
        
        return {
            'visual_features': torch.FloatTensor(visual_features),
            'motion_features': torch.FloatTensor(motion_features),
            'traffic_features': torch.FloatTensor(traffic_features),
            'left_turn_intent': torch.FloatTensor([float(label)]),  # çœŸæ­£çš„é¢„æµ‹æ ‡ç­¾
            'target_trajectory': torch.FloatTensor(target_trajectory),
            'future_movements': torch.FloatTensor(future_movements),  # æ·»åŠ æœªæ¥movementå­—æ®µä½œä¸ºæœªæ¥å€¼
            'sample_info': sample['info']  # é¢å¤–ä¿¡æ¯
        }
    
    def _get_legacy_sample(self, idx):
        """è·å–ä¼ ç»Ÿæ ·æœ¬ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰"""
        # è·å–è½¦è¾†åºåˆ—æ•°æ®
        vehicle_ids = self.data['vehicle_id'].unique()
        
        # ç®€åŒ–å¤„ç†ï¼šæŒ‰ç´¢å¼•è·å–è½¦è¾†æ•°æ®
        if idx < len(vehicle_ids):
            vehicle_id = vehicle_ids[idx]
            vehicle_data = self.data[self.data['vehicle_id'] == vehicle_id]
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
            if len(vehicle_data) < self.sequence_length + self.prediction_length:
                # å¦‚æœæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å¡«å……æˆ–è·³è¿‡
                vehicle_data = vehicle_data.iloc[:self.sequence_length + self.prediction_length]
            
            # å†å²è½¨è¿¹
            history = vehicle_data.iloc[:self.sequence_length]
            
            # æœªæ¥è½¨è¿¹
            future = vehicle_data.iloc[self.sequence_length:self.sequence_length + self.prediction_length]
            
            # æå–å¤šæ¨¡æ€ç‰¹å¾
            visual_features = self.extract_visual_features(history)
            motion_features = self.extract_motion_features(history)
            traffic_features = self.extract_traffic_features(history)
            
            # å·¦è½¬æ„å›¾æ ‡ç­¾ï¼ˆä»é¢„å¤„ç†æ•°æ®ä¸­è·å–ï¼‰
            left_turn_intent = self.get_left_turn_intent(vehicle_data)
        else:
            # ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¿”å›é»˜è®¤æ•°æ®
            return self._get_legacy_sample(idx % len(vehicle_ids))
        
        # ç›®æ ‡è½¨è¿¹ï¼ˆä½¿ç”¨NGSIMæ•°æ®çš„local_x, local_yåˆ—ï¼‰
        if 'local_x' in future.columns and 'local_y' in future.columns:
            target_trajectory = future[['local_x', 'local_y']].values
        else:
            # å¦‚æœæ²¡æœ‰ä½ç½®åˆ—ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            target_trajectory = np.random.randn(len(future), 2)
        
        return {
            'visual_features': torch.FloatTensor(visual_features),
            'motion_features': torch.FloatTensor(motion_features),
            'traffic_features': torch.FloatTensor(traffic_features),
            'left_turn_intent': torch.FloatTensor([left_turn_intent]),
            'target_trajectory': torch.FloatTensor(target_trajectory)
        }
    
    def extract_visual_features(self, history):
        """
        æå–è§†è§‰ç‰¹å¾ã€‚ç”±äºNGSIMæ²¡æœ‰å›¾åƒï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªæŠ½è±¡å®ç°ã€‚
        """
        # è¿™é‡Œçš„å®ç°æ˜¯æŠ½è±¡çš„ï¼Œä»£è¡¨ä¸€ä¸ªæœªæ¥å¯ä»¥é›†æˆçš„è§†è§‰æ¨¡å‹ã€‚
        # å¦‚æœæœ‰å›¾åƒæ•°æ®ï¼Œå¯ä»¥ç”¨é¢„è®­ç»ƒçš„CNNï¼ˆå¦‚ResNetï¼‰æ¥æå–ç‰¹å¾ã€‚
        # å¯¹äºNGSIMæ•°æ®ï¼Œå¯ä»¥è€ƒè™‘å°†è½¦è¾†è½¨è¿¹å’Œå‘¨å›´ç¯å¢ƒä¿¡æ¯æ …æ ¼åŒ–ä¸ºä¸€å¼ "åœ°å›¾å›¾åƒ"ï¼Œ
        # ç„¶åç”¨ä¸€ä¸ªå°çš„CNNæ¥å¤„ç†è¿™å¼ å›¾åƒã€‚
        
        # ç®€å•å ä½ç¬¦å®ç°ï¼šè¿”å›ä¸€ä¸ªç»´åº¦åˆé€‚çš„éšæœºå¼ é‡
        # å‡è®¾è§†è§‰ç‰¹å¾ç»´åº¦ä¸º32
        return torch.rand(self.history_length, 32).numpy()
    
    def extract_motion_features(self, history):
        """
        ä»è½¦è¾†è½¨è¿¹æ•°æ®ä¸­æå–è¿åŠ¨å­¦ç‰¹å¾ï¼Œå¹¶è®¡ç®—å¯¼æ•°ã€‚
        ç‰¹å¾åŒ…æ‹¬ï¼šx, y, é€Ÿåº¦, åŠ é€Ÿåº¦, èˆªå‘è§’, èˆªå‘è§’å˜åŒ–ç‡ã€‚
        """
        # æå–åŸºç¡€è¿åŠ¨å­¦ç‰¹å¾
        trajectory_data = history[['local_x', 'local_y', 'v_vel', 'v_acc']].values.astype(np.float32)

        # ç¡®ä¿æ•°æ®å¸§è¶³å¤Ÿé•¿ä»¥è®¡ç®—å¯¼æ•°
        if len(trajectory_data) < 2:
            # å¦‚æœè½¨è¿¹å¤ªçŸ­ï¼Œè¿”å›ä¸€ä¸ªå¡«å……äº†0çš„å¼ é‡
            return np.zeros((self.history_length, 6), dtype=np.float32)

        # è®¡ç®—èˆªå‘è§’ï¼ˆheading angleï¼‰ï¼Œä½¿ç”¨atan2æ¥å¤„ç†æ‰€æœ‰è±¡é™
        dx = np.diff(trajectory_data[:, 0])
        dy = np.diff(trajectory_data[:, 1])
        # ä½¿ç”¨np.arctan2è®¡ç®—èˆªå‘è§’ï¼Œå¯ä»¥å¤„ç†æ‰€æœ‰è±¡é™
        heading = np.arctan2(dy, dx)
        heading = np.insert(heading, 0, heading[0] if len(heading) > 0 else 0)  # åœ¨ç¬¬ä¸€å¸§è¡¥ä¸Šä¸€ä¸ªå€¼

        # è®¡ç®—èˆªå‘è§’å˜åŒ–ç‡ï¼ˆheading rate of changeï¼‰
        # è€ƒè™‘è§’åº¦çš„å‘¨æœŸæ€§ï¼Œä½¿ç”¨np.unwrapæ¥é¿å…è·³å˜
        unwrapped_heading = np.unwrap(heading)
        heading_rate = np.diff(unwrapped_heading)
        heading_rate = np.insert(heading_rate, 0, 0)  # ç¬¬ä¸€å¸§å˜åŒ–ç‡ä¸º0

        # å°†æ‰€æœ‰ç‰¹å¾æ‹¼æ¥èµ·æ¥
        motion_features = np.stack([
            trajectory_data[:, 0],  # local_x
            trajectory_data[:, 1],  # local_y
            trajectory_data[:, 2],  # v_vel
            trajectory_data[:, 3],  # v_acc
            heading,               # èˆªå‘è§’
            heading_rate           # èˆªå‘è§’å˜åŒ–ç‡
        ], axis=1)

        return motion_features
    
    def extract_traffic_features(self, history):
        """
        æå–äº¤é€šç¯å¢ƒç‰¹å¾ï¼Œå¦‚ä¸å‰åè½¦çš„ç›¸å¯¹è·ç¦»å’Œç›¸å¯¹é€Ÿåº¦ã€‚
        """
        # è·å–å½“å‰è½¦è¾†çš„ID
        current_vehicle_id = history['vehicle_id'].iloc[0]

        # æå–å‰åè½¦ID
        preceding_id = history['preceding'].iloc[0]
        following_id = history['following'].iloc[0]

        # é»˜è®¤ç‰¹å¾ï¼Œå¦‚æœå‰åè½¦ä¸å­˜åœ¨ï¼Œåˆ™ä¸º0
        preceding_features = np.zeros(2)
        following_features = np.zeros(2)

        # æŸ¥æ‰¾å‰è½¦å¹¶è®¡ç®—ç›¸å¯¹ç‰¹å¾
        if preceding_id > 0:
            preceding_vehicle_df = self.raw_data[self.raw_data['vehicle_id'] == preceding_id]
            if not preceding_vehicle_df.empty:
                # æ‰¾åˆ°åŒä¸€å¸§çš„å‰è½¦æ•°æ®
                current_frame = history['frame_id'].iloc[0]
                preceding_frame_df = preceding_vehicle_df[preceding_vehicle_df['frame_id'] == current_frame]
                if not preceding_frame_df.empty:
                    preceding_pos = preceding_frame_df['local_y'].iloc[0]
                    preceding_vel = preceding_frame_df['v_vel'].iloc[0]
                    
                    # ç›¸å¯¹ä½ç½®å’Œç›¸å¯¹é€Ÿåº¦
                    relative_y = preceding_pos - history['local_y'].iloc[0]
                    relative_v = preceding_vel - history['v_vel'].iloc[0]
                    preceding_features = np.array([relative_y, relative_v], dtype=np.float32)

        # æŸ¥æ‰¾åè½¦å¹¶è®¡ç®—ç›¸å¯¹ç‰¹å¾
        if following_id > 0:
            following_vehicle_df = self.raw_data[self.raw_data['vehicle_id'] == following_id]
            if not following_vehicle_df.empty:
                # æ‰¾åˆ°åŒä¸€å¸§çš„åè½¦æ•°æ®
                current_frame = history['frame_id'].iloc[0]
                following_frame_df = following_vehicle_df[following_vehicle_df['frame_id'] == current_frame]
                if not following_frame_df.empty:
                    following_pos = following_frame_df['local_y'].iloc[0]
                    following_vel = following_frame_df['v_vel'].iloc[0]

                    # ç›¸å¯¹ä½ç½®å’Œç›¸å¯¹é€Ÿåº¦
                    relative_y = following_pos - history['local_y'].iloc[0]
                    relative_v = following_vel - history['v_vel'].iloc[0]
                    following_features = np.array([relative_y, relative_v], dtype=np.float32)

        # å°†æ‰€æœ‰äº¤é€šç‰¹å¾æ‹¼æ¥èµ·æ¥
        traffic_features = np.concatenate([preceding_features, following_features])
        
        # æ‰©å±•ä¸ºæ—¶é—´åºåˆ—æ ¼å¼
        traffic_features = np.tile(traffic_features, (self.history_length, 1))
        
        return traffic_features
    
    def get_left_turn_intent(self, vehicle_data):
        """ä»æ•°æ®ä¸­è·å–å·¦è½¬æ„å›¾æ ‡ç­¾"""
        # ä¼˜å…ˆä½¿ç”¨é¢„å¤„ç†æ•°æ®çš„è´¨é‡æ ‡è®°
        if 'is_high_quality' in vehicle_data.columns:
            return 1.0 if vehicle_data['is_high_quality'].iloc[0] else 0.0
        # å…¶æ¬¡ä½¿ç”¨NGSIMåŸå§‹movementæ ‡ç­¾
        elif 'movement' in vehicle_data.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¦è½¬æ ‡ç­¾
            has_left_turn = np.any(vehicle_data['movement'] == 2.0)
            return 1.0 if has_left_turn else 0.0
        else:
            # å…¼å®¹æ€§å¤„ç†ï¼šé»˜è®¤ä¸ºå·¦è½¬æ•°æ®
            return 1.0
    
    def analyze_dataset(self):
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if self.use_prediction_mode and hasattr(self, 'samples'):
            print(f"ğŸ“Š é¢„æµ‹æ•°æ®é›†åˆ†æ:")
            print(f"   æ€»æ ·æœ¬æ•°: {len(self.samples):,}")
            
            # ä½¿ç”¨è¿›åº¦æ¡è¿›è¡Œæ•°æ®åˆ†æ
            with tqdm(total=4, desc="åˆ†æè¿›åº¦", unit="é¡¹") as pbar:
                # æ ‡ç­¾åˆ†å¸ƒ
                labels = [sample['label'] for sample in self.samples]
                left_turn_count = sum(labels)
                non_left_turn_count = len(labels) - left_turn_count
                
                print(f"   å·¦è½¬æ ·æœ¬: {left_turn_count:,} ({left_turn_count/len(labels)*100:.1f}%)")
                print(f"   éå·¦è½¬æ ·æœ¬: {non_left_turn_count:,} ({non_left_turn_count/len(labels)*100:.1f}%)")
                pbar.update(1)
                
                # è½¦è¾†åˆ†å¸ƒ
                vehicle_ids = [sample['info']['vehicle_id'] for sample in self.samples]
                unique_vehicles = len(set(vehicle_ids))
                print(f"   æ¶‰åŠè½¦è¾†æ•°: {unique_vehicles:,}")
                print(f"   å¹³å‡æ¯è½¦æ ·æœ¬æ•°: {len(self.samples)/unique_vehicles:.1f}")
                pbar.update(1)
                
                # æ—¶é—´è·¨åº¦åˆ†æ
                if len(self.samples) > 0:
                    sample_info = self.samples[0]['info']
                    time_span = sample_info['end_frame'] - sample_info['start_frame']
                    print(f"   æ ·æœ¬æ—¶é—´è·¨åº¦: {time_span}å¸§ ({time_span*0.1:.1f}ç§’)")
                pbar.update(1)
                
                # ä½ç½®èŒƒå›´åˆ†æ
                if len(self.samples) > 0:
                    all_positions = []
                    for sample in self.samples[:1000]:  # åªåˆ†æå‰1000ä¸ªæ ·æœ¬ä»¥åŠ é€Ÿ
                        all_positions.extend(sample['info']['history_trajectory'])
                        all_positions.extend(sample['info']['future_trajectory'])
                    
                    if all_positions:
                        positions_array = np.array(all_positions)
                        min_x, min_y = np.min(positions_array, axis=0)
                        max_x, max_y = np.max(positions_array, axis=0)
                        print(f"   è½¨è¿¹ç©ºé—´èŒƒå›´: x[{min_x:.1f}, {max_x:.1f}], y[{min_y:.1f}, {max_y:.1f}]")
                pbar.update(1)
        else:
            print(f"ğŸ“Š ä¼ ç»Ÿæ•°æ®é›†åˆ†æ:")
            print(f"   æ•°æ®è®°å½•æ•°: {len(self.data):,}")
            
            with tqdm(total=2, desc="åˆ†æè¿›åº¦", unit="é¡¹") as pbar:
                # è½¦è¾†ç»Ÿè®¡
                print(f"   è½¦è¾†æ•°: {len(self.data['vehicle_id'].unique()):,}")
                pbar.update(1)
                
                # ç§»åŠ¨ç±»å‹ç»Ÿè®¡
                if 'movement' in self.data.columns:
                    movement_counts = self.data['movement'].value_counts()
                    print(f"   Movementåˆ†å¸ƒ:")
                    for movement, count in movement_counts.items():
                        movement_name = {1.0: 'ç›´è¡Œ', 2.0: 'å·¦è½¬', 3.0: 'å³è½¬'}.get(movement, f'å…¶ä»–({movement})')
                        print(f"     {movement_name}: {count:,} ({count/len(self.data)*100:.1f}%)")
                pbar.update(1)

class VisualEncoder(nn.Module):
    """è§†è§‰ç‰¹å¾ç¼–ç å™¨"""
    
    def __init__(self, input_dim: int = 32, hidden_dim: int = 128):
        super().__init__()
        # è§†è§‰ç‰¹å¾æ˜¯åºåˆ—å½¢å¼ [batch_size, history_length, input_dim]
        # ä½¿ç”¨LSTMå¤„ç†åºåˆ—ç‰¹å¾
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.dropout = nn.Dropout(0.2)
        
        # è¾“å‡ºå±‚
        self.out_layer = nn.Linear(hidden_dim, hidden_dim)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        # x: [batch_size, history_length, input_dim]
        # ä½¿ç”¨LSTMå¤„ç†åºåˆ—ç‰¹å¾
        lstm_out, _ = self.lstm(x)
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_out = lstm_out[:, -1, :]
        last_out = self.dropout(last_out)
        
        # é€šè¿‡è¾“å‡ºå±‚
        out = self.out_layer(last_out)
        out = self.relu(out)
        
        return out

class MotionEncoder(nn.Module):
    """è¿åŠ¨ç‰¹å¾ç¼–ç å™¨ - å¤„ç†åºåˆ—å½¢å¼çš„è¿åŠ¨å­¦ç‰¹å¾"""
    
    def __init__(self, num_features: int = 6, hidden_dim: int = 128, num_layers: int = 2):
        super().__init__()
        # ç›´æ¥ä½¿ç”¨è¿åŠ¨å­¦ç‰¹å¾çš„æ•°é‡ä½œä¸ºè¾“å…¥ç»´åº¦
        # å‡è®¾è¾“å…¥æ˜¯ [batch_size, history_length, num_features] æ ¼å¼
        self.lstm = nn.LSTM(
            input_size=num_features,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_dim, hidden_dim)
    
    def forward(self, x):
        # x: [batch_size, history_length, num_features]
        # LSTMç›´æ¥å¤„ç†åºåˆ—ç‰¹å¾
        output, (hidden, cell) = self.lstm(x)
        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        return self.fc(output[:, -1, :])

class TrafficEncoder(nn.Module):
    """äº¤é€šç¯å¢ƒç‰¹å¾ç¼–ç å™¨ - å¤„ç†åºåˆ—å½¢å¼çš„äº¤é€šç¯å¢ƒç‰¹å¾"""
    
    def __init__(self, num_features: int = 4, hidden_dim: int = 128):
        super().__init__()
        # äº¤é€šç¯å¢ƒç‰¹å¾æ˜¯åºåˆ—å½¢å¼ [batch_size, history_length, num_features]
        # ä½¿ç”¨LSTMå¤„ç†åºåˆ—ç‰¹å¾
        self.lstm = nn.LSTM(num_features, hidden_dim, batch_first=True)
        self.dropout = nn.Dropout(0.2)
        
        # è¾“å‡ºå±‚
        self.out_layer = nn.Linear(hidden_dim, hidden_dim)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        # x: [batch_size, history_length, num_features]
        # ä½¿ç”¨LSTMå¤„ç†åºåˆ—ç‰¹å¾
        lstm_out, _ = self.lstm(x)
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_out = lstm_out[:, -1, :]
        last_out = self.dropout(last_out)
        
        # é€šè¿‡è¾“å‡ºå±‚
        out = self.out_layer(last_out)
        out = self.relu(out)
        
        return out

class AttentionFusion(nn.Module):
    """æ³¨æ„åŠ›èåˆæ¨¡å—"""
    
    def __init__(self, feature_dim: int = 128):
        super().__init__()
        self.feature_dim = feature_dim
        
        # è‡ªæ³¨æ„åŠ›æœºåˆ¶
        self.query = nn.Linear(feature_dim, feature_dim)
        self.key = nn.Linear(feature_dim, feature_dim)
        self.value = nn.Linear(feature_dim, feature_dim)
        
        # è·¨æ¨¡æ€æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=8,
            dropout=0.1
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(feature_dim * 3, feature_dim)
    
    def forward(self, visual_feat, motion_feat, traffic_feat):
        # å †å ç‰¹å¾
        features = torch.stack([visual_feat, motion_feat, traffic_feat], dim=1)
        
        # è‡ªæ³¨æ„åŠ›
        Q = self.query(features)
        K = self.key(features)
        V = self.value(features)
        
        attention_weights = torch.softmax(
            torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.feature_dim), 
            dim=-1
        )
        attended_features = torch.matmul(attention_weights, V)
        
        # è·¨æ¨¡æ€æ³¨æ„åŠ›
        attended_features = attended_features.transpose(0, 1)
        cross_attended, _ = self.cross_attention(
            attended_features, attended_features, attended_features
        )
        cross_attended = cross_attended.transpose(0, 1)
        
        # èåˆç‰¹å¾
        fused_features = cross_attended.contiguous().view(cross_attended.size(0), -1)
        output = self.output_proj(fused_features)
        
        return output

class IntentClassifier(nn.Module):
    """å·¦è½¬æ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self, input_dim: int = 128, hidden_dim: int = 64):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.classifier(x)

class TrajectoryDecoder(nn.Module):
    """è½¨è¿¹é¢„æµ‹è§£ç å™¨"""
    
    def __init__(self, input_dim: int = 129, hidden_dim: int = 128, output_dim: int = 2, seq_len: int = 12):
        super().__init__()
        self.seq_len = seq_len
        self.hidden_dim = hidden_dim
        
        # LSTMè§£ç å™¨
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.2
        )
        
        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(hidden_dim, output_dim)
        
        # åˆå§‹éšè—çŠ¶æ€
        self.init_hidden = nn.Linear(input_dim, hidden_dim * 2 * 2)  # 2 layers * 2 (h,c)
    
    def forward(self, fused_features, intent_prob):
        batch_size = fused_features.size(0)
        
        # ç»“åˆæ„å›¾ä¿¡æ¯
        input_features = torch.cat([fused_features, intent_prob], dim=1)
        
        # åˆå§‹åŒ–éšè—çŠ¶æ€
        init_states = self.init_hidden(input_features)
        h0 = init_states[:, :self.hidden_dim*2].reshape(2, batch_size, self.hidden_dim)
        c0 = init_states[:, self.hidden_dim*2:].reshape(2, batch_size, self.hidden_dim)
        
        # è§£ç é¢„æµ‹è½¨è¿¹
        outputs = []
        hidden = (h0, c0)
        
        # ç¬¬ä¸€æ­¥è¾“å…¥ - ä½¿ç”¨å›ºå®šçš„è¾“å…¥ç‰¹å¾
        decoder_input = input_features.unsqueeze(1)  # [batch, 1, input_dim]
        
        for t in range(self.seq_len):
            output, hidden = self.lstm(decoder_input, hidden)
            trajectory_point = self.output_layer(output)
            outputs.append(trajectory_point)
            
            # ä¿æŒè¾“å…¥ç»´åº¦ä¸€è‡´ï¼Œä¸æ·»åŠ trajectory_point
            # ä½¿ç”¨ç›¸åŒçš„input_featuresä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥
            decoder_input = input_features.unsqueeze(1)
        
        # æ‹¼æ¥æ‰€æœ‰è¾“å‡º
        trajectory = torch.cat(outputs, dim=1)
        
        return trajectory

class LeftTurnPredictor(nn.Module):
    """
    å·¦è½¬é¢„æµ‹æ¨¡å‹ï¼Œé‡‡ç”¨å¤šæ¨¡æ€èåˆæ¶æ„
    æ•´åˆäº†è§†è§‰ã€è¿åŠ¨å’Œäº¤é€šç¯å¢ƒç‰¹å¾è¿›è¡Œå·¦è½¬æ„å›¾é¢„æµ‹å’Œè½¨è¿¹é¢„æµ‹
    """

    def __init__(self, history_horizon: int = 50, num_motion_features: int = 6, 
                 num_traffic_features: int = 4, num_visual_features: int = 32, prediction_horizon: int = 12):
        super().__init__()
        
        # è¿åŠ¨å­¦ç‰¹å¾ç¼–ç å™¨ï¼ˆä½¿ç”¨LSTMï¼‰
        self.motion_encoder = MotionEncoder(num_features=num_motion_features)
        
        # äº¤é€šç¯å¢ƒç‰¹å¾ç¼–ç å™¨
        self.traffic_encoder = TrafficEncoder(num_features=num_traffic_features)
        
        # è§†è§‰ç‰¹å¾ç¼–ç å™¨
        self.visual_encoder = VisualEncoder(input_dim=num_visual_features)

        # æ³¨æ„åŠ›èåˆæ¨¡å—
        self.attention_fusion = AttentionFusion()

        # æ„å›¾åˆ†ç±»å™¨
        self.intent_classifier = IntentClassifier()

        # è½¨è¿¹è§£ç å™¨ - ä½¿ç”¨åŠ¨æ€é¢„æµ‹é•¿åº¦
        self.trajectory_decoder = TrajectoryDecoder(seq_len=prediction_horizon)

    def forward(self, visual_feat, motion_feat, traffic_feat):
        # ç‰¹å¾ç¼–ç 
        # æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯åºåˆ—å½¢å¼ [batch_size, history_length, feature_dim]
        visual_encoded = self.visual_encoder(visual_feat)
        motion_encoded = self.motion_encoder(motion_feat)
        traffic_encoded = self.traffic_encoder(traffic_feat)
        
        # å¤šæ¨¡æ€èåˆ
        fused_features = self.attention_fusion(
            visual_encoded, motion_encoded, traffic_encoded
        )
        
        # æ„å›¾é¢„æµ‹
        intent_prob = self.intent_classifier(fused_features)
        
        # è½¨è¿¹é¢„æµ‹
        trajectory = self.trajectory_decoder(fused_features, intent_prob)
        
        return intent_prob, trajectory

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self, model, train_loader, val_loader, device='cuda'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', patience=10, factor=0.5
        )
        
        # æŸå¤±å‡½æ•°
        self.intent_loss_fn = nn.BCELoss()
        self.trajectory_loss_fn = nn.MSELoss()
        
        # è®­ç»ƒå†å²
        self.train_history = {'loss': [], 'intent_acc': [], 'traj_error': []}
        self.val_history = {'loss': [], 'intent_acc': [], 'traj_error': []}
    
    def train_epoch(self, epoch_num=None, total_epochs=None):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        intent_correct = 0
        total_samples = 0
        traj_error = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        desc = f"Epoch {epoch_num}/{total_epochs} [Train]" if epoch_num and total_epochs else "Training"
        pbar = tqdm(self.train_loader, desc=desc, leave=False)
        
        batch_losses = []
        batch_start_time = time.time()
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            visual_feat = batch['visual_features'].to(self.device)
            motion_feat = batch['motion_features'].to(self.device)
            traffic_feat = batch['traffic_features'].to(self.device)
            intent_target = batch['left_turn_intent'].to(self.device)
            traj_target = batch['target_trajectory'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)
            
            # è®¡ç®—æŸå¤±
            intent_loss = self.intent_loss_fn(intent_pred, intent_target)
            traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)
            
            # è”åˆæŸå¤±
            total_batch_loss = intent_loss + 0.5 * traj_loss
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            total_batch_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç»Ÿè®¡
            batch_loss = total_batch_loss.item()
            total_loss += batch_loss
            batch_losses.append(batch_loss)
            intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()
            total_samples += intent_target.size(0)
            traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()
            
            # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
            if batch_idx % 5 == 0:  # æ¯5ä¸ªbatchæ›´æ–°ä¸€æ¬¡
                current_avg_loss = np.mean(batch_losses[-10:]) if len(batch_losses) >= 10 else np.mean(batch_losses)
                current_intent_acc = intent_correct / total_samples if total_samples > 0 else 0
                
                # è®¡ç®—å¤„ç†é€Ÿåº¦
                elapsed_time = time.time() - batch_start_time
                samples_per_sec = total_samples / elapsed_time if elapsed_time > 0 else 0
                
                pbar.set_postfix({
                    'Loss': f'{current_avg_loss:.4f}',
                    'IntentAcc': f'{current_intent_acc:.3f}',
                    'Speed': f'{samples_per_sec:.1f}samples/s'
                })
        
        pbar.close()
        
        avg_loss = total_loss / len(self.train_loader)
        intent_acc = intent_correct / total_samples
        avg_traj_error = traj_error / len(self.train_loader)
        
        return avg_loss, intent_acc, avg_traj_error
    
    def validate(self, epoch_num=None, total_epochs=None):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        intent_correct = 0
        total_samples = 0
        traj_error = 0
        
        # åˆ›å»ºéªŒè¯è¿›åº¦æ¡
        desc = f"Epoch {epoch_num}/{total_epochs} [Valid]" if epoch_num and total_epochs else "Validating"
        pbar = tqdm(self.val_loader, desc=desc, leave=False)
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(pbar):
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                visual_feat = batch['visual_features'].to(self.device)
                motion_feat = batch['motion_features'].to(self.device)
                traffic_feat = batch['traffic_features'].to(self.device)
                intent_target = batch['left_turn_intent'].to(self.device)
                traj_target = batch['target_trajectory'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)
                
                # è®¡ç®—æŸå¤±
                intent_loss = self.intent_loss_fn(intent_pred, intent_target)
                traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)
                total_batch_loss = intent_loss + 0.5 * traj_loss
                
                # ç»Ÿè®¡
                total_loss += total_batch_loss.item()
                intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()
                total_samples += intent_target.size(0)
                traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                if batch_idx % 3 == 0:  # éªŒè¯æ—¶æ›´é¢‘ç¹æ›´æ–°
                    current_avg_loss = total_loss / (batch_idx + 1)
                    current_intent_acc = intent_correct / total_samples if total_samples > 0 else 0
                    
                    pbar.set_postfix({
                        'Loss': f'{current_avg_loss:.4f}',
                        'IntentAcc': f'{current_intent_acc:.3f}'
                    })
        
        pbar.close()
        
        avg_loss = total_loss / len(self.val_loader)
        intent_acc = intent_correct / total_samples
        avg_traj_error = traj_error / len(self.val_loader)
        
        return avg_loss, intent_acc, avg_traj_error
    
    def train(self, epochs: int = 50, early_stopping_patience: int = 15):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        best_val_loss = float('inf')
        patience_counter = 0
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(self.train_loader.dataset):,}")
        print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(self.val_loader.dataset):,}")
        print(f"ğŸ¯ ç›®æ ‡è½®æ•°: {epochs}")
        print(f"â° æ—©åœè€å¿ƒ: {early_stopping_patience}")
        print(f"ğŸ’» è®¾å¤‡: {self.device}")
        print("=" * 80)
        
        # æ€»ä½“è¿›åº¦æ¡
        epoch_pbar = tqdm(range(epochs), desc="Overall Progress", position=0)
        
        training_start_time = time.time()
        
        for epoch in epoch_pbar:
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_intent_acc, train_traj_error = self.train_epoch(epoch+1, epochs)
            
            # éªŒè¯
            val_loss, val_intent_acc, val_traj_error = self.validate(epoch+1, epochs)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            old_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_loss)
            new_lr = self.optimizer.param_groups[0]['lr']
            
            # è®°å½•å†å²
            self.train_history['loss'].append(train_loss)
            self.train_history['intent_acc'].append(train_intent_acc)
            self.train_history['traj_error'].append(train_traj_error)
            
            self.val_history['loss'].append(val_loss)
            self.val_history['intent_acc'].append(val_intent_acc)
            self.val_history['traj_error'].append(val_traj_error)
            
            # è®¡ç®—æ—¶é—´ç»Ÿè®¡
            epoch_time = time.time() - epoch_start_time
            total_elapsed = time.time() - training_start_time
            avg_epoch_time = total_elapsed / (epoch + 1)
            eta = avg_epoch_time * (epochs - epoch - 1)
            
            # æ—©åœæ£€æŸ¥å’Œæ¨¡å‹ä¿å­˜
            improvement = ""
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_model.pth')
                improvement = "ğŸ’¾ [BEST]"
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    improvement = "â¹ï¸ [EARLY STOP]"
            
            # å­¦ä¹ ç‡å˜åŒ–æç¤º
            lr_info = f"ğŸ“‰ LR: {old_lr:.2e}" if new_lr == old_lr else f"ğŸ“‰ LR: {old_lr:.2e}â†’{new_lr:.2e}"
            
            # æ›´æ–°æ€»ä½“è¿›åº¦æ¡
            epoch_pbar.set_postfix({
                'Train_Loss': f'{train_loss:.4f}',
                'Val_Loss': f'{val_loss:.4f}',
                'Val_Acc': f'{val_intent_acc:.3f}',
                'Patience': f'{patience_counter}/{early_stopping_patience}',
                'ETA': f'{eta/60:.1f}min'
            })
            
            # è¯¦ç»†ä¿¡æ¯è¾“å‡º
            epoch_info = f"ğŸ“ˆ Epoch {epoch+1:3d}/{epochs} | " + \
                        f"â±ï¸ {epoch_time:.1f}s | " + \
                        f"ğŸ”„ Train: {train_loss:.4f} | " + \
                        f"âœ… Valid: {val_loss:.4f} | " + \
                        f"ğŸ¯ Acc: {val_intent_acc:.3f} | " + \
                        f"ğŸ“ TrajErr: {val_traj_error:.3f}"
            print(epoch_info)
            
            detail_info = f"    {lr_info} | " + \
                         f"â³ ETA: {eta/60:.1f}min | " + \
                         f"ğŸ• Total: {total_elapsed/60:.1f}min | " + \
                         f"{improvement}"
            print(detail_info)
            
            if patience_counter >= early_stopping_patience:
                print(f"â¹ï¸ æ—©åœè§¦å‘ï¼åœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break
        
        epoch_pbar.close()
        
        total_training_time = time.time() - training_start_time
        print("" + "=" * 80)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
        print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: best_model.pth")
        print("=" * 80)
        
        return self.train_history, self.val_history
    
    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # æŸå¤±æ›²çº¿
        axes[0].plot(self.train_history['loss'], label='Train Loss')
        axes[0].plot(self.val_history['loss'], label='Val Loss')
        axes[0].set_title('Training Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True)
        
        # æ„å›¾è¯†åˆ«å‡†ç¡®ç‡
        axes[1].plot(self.train_history['intent_acc'], label='Train Acc')
        axes[1].plot(self.val_history['intent_acc'], label='Val Acc')
        axes[1].set_title('Intent Classification Accuracy')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Accuracy')
        axes[1].legend()
        axes[1].grid(True)
        
        # è½¨è¿¹é¢„æµ‹è¯¯å·®
        axes[2].plot(self.train_history['traj_error'], label='Train Error')
        axes[2].plot(self.val_history['traj_error'], label='Val Error')
        axes[2].set_title('Trajectory Prediction Error')
        axes[2].set_xlabel('Epoch')
        axes[2].set_ylabel('RMSE')
        axes[2].legend()
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

def evaluate_model(model, test_loader, device='cuda'):
    """æ¨¡å‹è¯„ä¼°"""
    model.eval()
    
    all_intent_preds = []
    all_intent_targets = []
    all_traj_preds = []
    all_traj_targets = []
    all_future_movements = []  # å­˜å‚¨future_movementsç”¨äºä¸çœŸå®å·¦è½¬æ•°æ®éªŒè¯
    
    print("ğŸ“ˆ å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºè¯„ä¼°è¿›åº¦
    with torch.no_grad():
        with tqdm(total=len(test_loader), desc="è¯„ä¼°è¿›åº¦", unit="æ‰¹") as pbar:
            for batch_idx, batch in enumerate(test_loader):
                visual_feat = batch['visual_features'].to(device)
                motion_feat = batch['motion_features'].to(device)
                traffic_feat = batch['traffic_features'].to(device)
                intent_target = batch['left_turn_intent'].to(device)
                traj_target = batch['target_trajectory'].to(device)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«future_movementså­—æ®µï¼ˆç”¨äºä¸çœŸå®å·¦è½¬æ•°æ®éªŒè¯ï¼‰
                if 'future_movements' in batch:
                    all_future_movements.extend(batch['future_movements'])
                
                intent_pred, traj_pred = model(visual_feat, motion_feat, traffic_feat)
                
                all_intent_preds.append(intent_pred.cpu().numpy())
                all_intent_targets.append(intent_target.cpu().numpy())
                all_traj_preds.append(traj_pred.cpu().numpy())
                all_traj_targets.append(traj_target.cpu().numpy())
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                
                # å®šæœŸæ˜¾ç¤ºå½“å‰è¿›åº¦çš„ç»Ÿè®¡ä¿¡æ¯
                if batch_idx % 10 == 0 or batch_idx == len(test_loader) - 1:
                    # è®¡ç®—å½“å‰çš„ç®€å•ç»Ÿè®¡
                    current_samples = (batch_idx + 1) * len(batch['visual_features'])
                    pbar.set_postfix({
                        'å·²å¤„ç†æ ·æœ¬': current_samples
                    })
    
    print("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼Œå¼€å§‹è®¡ç®—æ€§èƒ½æŒ‡æ ‡...")
    
    # åˆå¹¶ç»“æœ
    intent_preds = np.concatenate(all_intent_preds)
    intent_targets = np.concatenate(all_intent_targets)
    traj_preds = np.concatenate(all_traj_preds)
    traj_targets = np.concatenate(all_traj_targets)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    # æ„å›¾è¯†åˆ«æŒ‡æ ‡
    intent_binary_preds = (intent_preds > 0.5).astype(int)
    intent_binary_targets = (intent_targets > 0.5).astype(int)
    
    intent_accuracy = accuracy_score(intent_binary_targets, intent_binary_preds)
    intent_precision = precision_score(intent_binary_targets, intent_binary_preds)
    intent_recall = recall_score(intent_binary_targets, intent_binary_preds)
    intent_f1 = f1_score(intent_binary_targets, intent_binary_preds)
    
    # è½¨è¿¹é¢„æµ‹æŒ‡æ ‡
    # ADE (Average Displacement Error)
    ade = np.mean(np.sqrt(np.sum((traj_preds - traj_targets) ** 2, axis=2)))
    
    # FDE (Final Displacement Error)
    fde = np.mean(np.sqrt(np.sum((traj_preds[:, -1, :] - traj_targets[:, -1, :]) ** 2, axis=1)))
    
    # æ‰“å°è¯„ä¼°ç»“æœ
    print("============================================================")
    print("                        æ¨¡å‹è¯„ä¼°ç»“æœ")
    print("============================================================")
    print(f"æ„å›¾è¯†åˆ«å‡†ç¡®ç‡: {intent_accuracy:.4f}")
    print(f"æ„å›¾è¯†åˆ«ç²¾ç¡®ç‡: {intent_precision:.4f}")
    print(f"æ„å›¾è¯†åˆ«å¬å›ç‡: {intent_recall:.4f}")
    print(f"æ„å›¾è¯†åˆ«F1åˆ†æ•°: {intent_f1:.4f}")
    print("-" * 40)
    print(f"è½¨è¿¹é¢„æµ‹ADE: {ade:.4f} m")
    print(f"è½¨è¿¹é¢„æµ‹FDE: {fde:.4f} m")
    print("=" * 60)
    
    # å‡†å¤‡è¿”å›ç»“æœ
    results = {
        'intent_accuracy': intent_accuracy,
        'intent_precision': intent_precision,
        'intent_recall': intent_recall,
        'intent_f1': intent_f1,
        'trajectory_ade': ade,
        'trajectory_fde': fde
    }
    
    # å¦‚æœå­˜åœ¨future_movementsæ•°æ®ï¼Œè¿›è¡Œä¸çœŸå®å·¦è½¬æ•°æ®çš„éªŒè¯åˆ†æ
    if all_future_movements:
        # åŸºäºfuture_movementsç¡®å®šçœŸæ­£çš„å·¦è½¬è½¦è¾†
        true_left_turns = [1 if any(m == 'L' for m in movements) else 0 for movements in all_future_movements]
        
        # è®¡ç®—åŸºäºçœŸå®å·¦è½¬æ ‡ç­¾çš„å‡†ç¡®ç‡
        true_left_accuracy = accuracy_score(true_left_turns, intent_binary_preds[:len(true_left_turns)])
        true_left_precision = precision_score(true_left_turns, intent_binary_preds[:len(true_left_turns)], zero_division=0)
        true_left_recall = recall_score(true_left_turns, intent_binary_preds[:len(true_left_turns)], zero_division=0)
        true_left_f1 = f1_score(true_left_turns, intent_binary_preds[:len(true_left_turns)], zero_division=0)
        
        # æ‰“å°åŸºäºçœŸå®å·¦è½¬æ•°æ®çš„éªŒè¯ç»“æœ
        print("ğŸ“Š åŸºäºçœŸå®å·¦è½¬æ•°æ®çš„éªŒè¯ç»“æœ (ä¸å·¦è½¬æ•°æ®åˆ†æè„šæœ¬å¯¹æ¯”):")
        print(f"   - çœŸæ­£å·¦è½¬è½¦è¾†æ•°: {sum(true_left_turns)}/{len(true_left_turns)}")
        print(f"   - é¢„æµ‹å‡†ç¡®ç‡: {true_left_accuracy:.4f}")
        print(f"   - ç²¾ç¡®ç‡: {true_left_precision:.4f}")
        print(f"   - å¬å›ç‡: {true_left_recall:.4f}")
        print(f"   - F1åˆ†æ•°: {true_left_f1:.4f}")
        print("=" * 60)
        
        # å°†éªŒè¯ç»“æœæ·»åŠ åˆ°è¿”å›å­—å…¸
        results.update({
            'true_left_turns_count': sum(true_left_turns),
            'true_left_turns_total': len(true_left_turns),
            'true_left_accuracy': true_left_accuracy,
            'true_left_precision': true_left_precision,
            'true_left_recall': true_left_recall,
            'true_left_f1': true_left_f1
        })
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ")
    print("åŸºäºå†å²è½¨è¿¹çš„çœŸæ­£å·¦è½¬æ„å›¾é¢„æµ‹")
    print("=" * 60)
    data_dir = os.path.join(os.path.dirname(__file__), "../data")

    # åŠ è½½é…ç½® (ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼Œè‡ªåŠ¨å®šä½åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•çš„config.yaml)
    config = load_config()

    raw_csv_file =  config.get("raw_csv_file", "peachtree_filtered_data.csv")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    
    # é€‰æ‹©é¢„æµ‹æ¨¡å¼
    print("ğŸ¯ é€‰æ‹©é¢„æµ‹æ¨¡å¼:")
    print("1. çœŸæ­£çš„é¢„æµ‹æ¨¡å¼ (æ¨è) - åŸºäºå†å²è½¨è¿¹é¢„æµ‹æœªæ¥å·¦è½¬æ„å›¾")
    print("2. ä¼ ç»Ÿæ¨¡å¼ - å¤šæ¨¡æ€ç‰¹å¾èåˆ")
    
    mode_choice = input("è¯·é€‰æ‹©æ¨¡å¼ (1/2, é»˜è®¤: 1): ").strip()
    use_prediction_mode = mode_choice != '2'
    
    # æ·»åŠ å…¨å±€æ ·æœ¬æ•°é™åˆ¶å‚æ•°
    max_samples_input = input("è¯·è¾“å…¥è¦å¤„ç†çš„æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: å…¨éƒ¨ï¼Œè¾“å…¥æ­£æ•´æ•°å¯ç¼©å‡è°ƒè¯•æ—¶é—´): ").strip()

    max_samples = config.get("max_samples", -1)
    max_samples = int(max_samples_input) if max_samples_input and max_samples_input.isdigit() and int(max_samples_input)>0 else max_samples
    
    if use_prediction_mode:
        print("âœ… ä½¿ç”¨çœŸæ­£çš„é¢„æµ‹æ¨¡å¼")
        print("   - å†å²é•¿åº¦: 30å¸§ (3ç§’)")
        print("   - é¢„æµ‹èŒƒå›´: 50å¸§ (5ç§’)")
        print("   - åˆ©ç”¨NGSIM movementæ ‡ç­¾è¿›è¡ŒçœŸæ­£çš„é¢„æµ‹")
        if max_samples>0:
            print(f"   - é™åˆ¶æœ€å¤§æ ·æœ¬æ•°: {max_samples}")
    else:
        print("âœ… ä½¿ç”¨ä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å¼")
        if max_samples>0:
            print(f"   - é™åˆ¶æœ€å¤§æ ·æœ¬æ•°: {max_samples}")
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ”„ åˆ›å»ºæ•°æ®é›†...")
    try:
        # è·å–æ•°æ®è·¯å¾„
        raw_csv_file_fullpath = f"{data_dir}/{raw_csv_file}"
        data_path_input = input(f"è¯·è¾“å…¥NGSIMæ•°æ®è·¯å¾„ (é»˜è®¤: {raw_csv_file_fullpath}): ").strip()
        data_path_fullpath = data_path_input if data_path_input else raw_csv_file_fullpath
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
        if not os.path.exists(data_path_fullpath):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path_fullpath}")
            print("ğŸ’¡ è¯·ç¡®ä¿NGSIMæ•°æ®æ–‡ä»¶å­˜åœ¨")
            return
            
        # åˆ›å»ºDataPipelineå®ä¾‹
        data_pipeline = DataPipeline(data_path_fullpath)
        
        # è·å–è·¯å£å’Œæ–¹å‘ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        int_id = config.get("int_id", 1)
        approach = config.get("approach", "northbound")
        
        if use_prediction_mode:
            # é¢„æµ‹æ¨¡å¼ä¸‹å¯ä»¥é€‰æ‹©ç‰¹å®šè·¯å£å’Œæ–¹å‘
            filter_input = input("æ˜¯å¦æŒ‰è·¯å£å’Œæ–¹å‘ç­›é€‰æ•°æ®ï¼Ÿ(y/n, é»˜è®¤: y): ").strip().lower()
            filter_input = 'y' if not filter_input else 'n'
            if filter_input == 'y':
                try:
                    # å…ˆä½¿ç”¨LeftTurnAnalyzerå‘ç°å¹¶æ˜¾ç¤ºæ•°æ®ä¸­çš„è·¯å£
                    print("ğŸ” æ­£åœ¨åˆ†ææ•°æ®ä¸­çš„è·¯å£ä¿¡æ¯...")
                    analyzer = LeftTurnAnalyzer(data_path_fullpath)
                    analyzer.load_data()
                    intersections = analyzer.discover_intersections()
                    
                    if intersections:
                        print("\nğŸ“‹ æ•°æ®ä¸­å‘ç°çš„è·¯å£ä¿¡æ¯ï¼š")
                        print("=" * 80)
                        print(f"{'è·¯å£ID':<8} {'æ€»è®°å½•æ•°':<12} {'è½¦è¾†æ•°':<10} {'æ–¹å‘':<20} {'æœºåŠ¨ç±»å‹':<15}")
                        print("-" * 80)
                        
                        for int_id_available, info in sorted(intersections.items()):
                            # è½¬æ¢æ–¹å‘ä¸ºåç§°
                            direction_names = []
                            for direction in info['directions'][:4]:  # æœ€å¤šæ˜¾ç¤º4ä¸ªæ–¹å‘
                                if direction in analyzer.direction_names:
                                    direction_names.append(f"{direction}({analyzer.direction_names[direction].split(' ')[0]})")
                                else:
                                    direction_names.append(str(direction))
                            directions_str = ','.join(direction_names)
                            
                            # è½¬æ¢æœºåŠ¨ç±»å‹ä¸ºåç§°
                            movement_names = []
                            for movement in info['movements'][:4]:  # æœ€å¤šæ˜¾ç¤º4ä¸ªæœºåŠ¨ç±»å‹
                                if movement in analyzer.movement_names:
                                    movement_names.append(f"{movement}({analyzer.movement_names[movement].split(' ')[0]})")
                                else:
                                    movement_names.append(str(movement))
                            movements_str = ','.join(movement_names)
                            
                            print(f"{int_id_available:<8} {info['total_records']:<12} {info['total_vehicles']:<10} {directions_str:<20} {movements_str:<15}")
                        print("=" * 80)
                    else:
                        print("âš ï¸ æœªèƒ½åœ¨æ•°æ®ä¸­å‘ç°è·¯å£ä¿¡æ¯")
                    
                    # ç„¶åè®©ç”¨æˆ·é€‰æ‹©è·¯å£ID
                    int_id_input = input("è¯·è¾“å…¥è·¯å£ID (ç•™ç©ºä¸ç­›é€‰): ").strip()
                    int_id = int(int_id_input) if int_id_input else None
                    
                    if int_id is not None:
                        # åˆ†æè¯¥è·¯å£çš„å¯ç”¨å…¥å£æ–¹å‘
                        try:
                            entrance_analyzer = LeftTurnAnalyzer(data_path_fullpath)
                            entrance_analyzer.load_data()
                            entrance_analyzer.intersection_id = int_id
                            entrance_stats = entrance_analyzer.analyze_intersection_entrances()
                            
                            if entrance_stats:
                                print(f"\nâœ… è·¯å£ {int_id} çš„å¯ç”¨å…¥å£æ–¹å‘ä¿¡æ¯ï¼š")
                                print("=" * 70)
                                print(f"{'æ–¹å‘ç¼–å·':<10} {'æ–¹å‘åç§°':<10} {'æ€»è½¦è¾†':<10} {'å·¦è½¬è½¦è¾†':<10} {'å·¦è½¬æ¯”ä¾‹':<10}")
                                print("-" * 70)
                                
                                for stats in entrance_stats.values():
                                    print(f"{stats['direction']:<10} {stats['direction_name']:<10} {stats['total_vehicles']:<10} {stats['left_turn_vehicles']:<10} {stats['left_turn_ratio']:.1f}%")
                                print("=" * 70)
                        except Exception as e:
                            print(f"âš ï¸ åˆ†æå…¥å£æ–¹å‘æ—¶å‡ºé”™: {e}")
                        
                        approach_input = input("è¯·è¾“å…¥å…¥å£æ–¹å‘ (1-ä¸œ, 2-åŒ—, 3-è¥¿, 4-å—, ç•™ç©ºä¸ç­›é€‰): ").strip()
                        approach = int(approach_input) if approach_input and approach_input.isdigit() else None
                except ValueError:
                    print("âš ï¸ æ— æ•ˆçš„è·¯å£IDæˆ–æ–¹å‘ï¼Œå°†ä½¿ç”¨æ‰€æœ‰æ•°æ®")
        else:
            # ä¼ ç»Ÿæ¨¡å¼ä¸‹éœ€è¦è·¯å£å’Œæ–¹å‘ä¿¡æ¯
            try:
                int_id_input = input("è¯·è¾“å…¥è·¯å£ID (é»˜è®¤: 1): ").strip()
                int_id = int(int_id_input) if int_id_input else 1
                
                # è·å–å…¥å£æ–¹å‘
                print("è¯·é€‰æ‹©å…¥å£æ–¹å‘:")
                print("1 - ä¸œå‘")
                print("2 - åŒ—å‘")
                print("3 - è¥¿å‘")
                print("4 - å—å‘")
                entrance_direction_input = input("è¯·é€‰æ‹©å…¥å£æ–¹å‘ (é»˜è®¤: 1): ").strip()
                approach = int(entrance_direction_input) if entrance_direction_input else 1
            except Exception as e:
                print(f"âŒ è·å–è·¯å£å’Œæ–¹å‘ä¿¡æ¯å¤±è´¥: {e}")
                print("ğŸ’¡ å°†ä½¿ç”¨é»˜è®¤å€¼")
                int_id = 1
                approach = 1
        
        # ä½¿ç”¨DataPipelineæ„å»ºæ•°æ®é›†
        history_length = config.get("history_length", 30)
        prediction_horizon = config.get("prediction_horizon", 12)  # ä¿®æ”¹ä¸º12ä»¥åŒ¹é…æ¨¡å‹è¾“å‡º

        epochs = config.get("epochs", 50)
        epochs_input = input("è¯·è¾“å…¥è®­ç»ƒè½®æ•° epochs (é»˜è®¤: epochs=50): ").strip()
        epochs = int(epochs_input) if epochs_input else epochs

        full_dataset = data_pipeline.build_dataset(
            int_id=int_id,
            approach=approach,
            history_length=history_length if use_prediction_mode else 8,
            prediction_horizon=prediction_horizon if use_prediction_mode else 12,
            min_trajectory_length=100 if use_prediction_mode else 20,
            use_prediction_mode=use_prediction_mode,
            max_samples=max_samples
        )
        
        # åˆ†ææ•°æ®é›†
        data_pipeline.get_dataset_statistics(full_dataset)
        
        # ä½¿ç”¨DataPipelineè¿›è¡Œæ•°æ®é›†åˆ’åˆ†
        train_dataset, val_dataset, test_dataset = data_pipeline.split_dataset(full_dataset)
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        # ä½¿ç”¨ä¸é…ç½®ä¸€è‡´çš„history_length
        train_dataset = MockDataset(800, history_length=history_length)
        val_dataset = MockDataset(200, history_length=history_length)
        test_dataset = MockDataset(200, history_length=history_length)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # åˆ›å»ºæ¨¡å‹ - ä¼ å…¥é¢„æµ‹é•¿åº¦å‚æ•°
    print("åˆ›å»ºæ¨¡å‹...")
    model = LeftTurnPredictor(prediction_horizon=prediction_horizon)
    
    # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
    trainer = TrainingManager(model, train_loader, val_loader, device)
    
    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒ...")
    train_history, val_history = trainer.train(epochs=epochs)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    trainer.plot_training_history()
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load('best_model.pth'))
    
    # è¯„ä¼°æ¨¡å‹
    print("è¯„ä¼°æ¨¡å‹...")
    results = evaluate_model(model, test_loader, device)
    
    print("è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()