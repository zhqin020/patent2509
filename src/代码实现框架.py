#!/usr/bin/env python3
"""
è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ
åŸºäºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ çš„å®ç°æ¡†æ¶
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import cv2
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
import time
from tqdm import tqdm

class MockDataset(Dataset):
    """æ¨¡æ‹Ÿæ•°æ®é›†ç±»ï¼Œç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•"""
    def __init__(self, size=1000):
        self.size = size
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        return {
            'visual_features': torch.randn(64),
            'motion_features': torch.randn(40),
            'traffic_features': torch.randn(32),
            'left_turn_intent': torch.rand(1),
            'target_trajectory': torch.randn(12, 2)
        }

class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†ç±»"""
    
    def __init__(self, data_path: str, sequence_length: int = 8, prediction_length: int = 12):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            sequence_length: å†å²è½¨è¿¹é•¿åº¦
            prediction_length: é¢„æµ‹è½¨è¿¹é•¿åº¦
        """
        self.data_path = data_path
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.data = self.load_data()
        
    def load_data(self):
        """åŠ è½½é¢„å¤„ç†å¥½çš„å·¦è½¬æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½é¢„å¤„ç†æ•°æ®: {self.data_path}")
        
        # åŠ è½½ç”±æ•°æ®é¢„å¤„ç†ç®¡é“ç”Ÿæˆçš„æ•°æ®
        data = pd.read_csv(self.data_path)
        
        print(f"æ•°æ®åŠ è½½æˆåŠŸ: {len(data)} æ¡è®°å½•, {len(data['vehicle_id'].unique())} è¾†è½¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—
        required_columns = ['vehicle_id', 'frame_id', 'local_x', 'local_y']
        missing_columns = [col for col in required_columns if col not in data.columns]
        if missing_columns:
            raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        
        # å¦‚æœæœ‰è´¨é‡æ ‡è®°ï¼Œä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ•°æ®
        if 'is_high_quality' in data.columns:
            high_quality_data = data[data['is_high_quality'] == True]
            if len(high_quality_data) > 0:
                print(f"ä½¿ç”¨é«˜è´¨é‡æ•°æ®: {len(high_quality_data)} æ¡è®°å½•, {len(high_quality_data['vehicle_id'].unique())} è¾†è½¦")
                data = high_quality_data
        
        # æŒ‰è½¦è¾†IDå’Œå¸§IDæ’åº
        data = data.sort_values(['vehicle_id', 'frame_id'])
        
        return data
    
    def preprocess_data(self, data):
        """æ•°æ®é¢„å¤„ç†"""
        # è½¨è¿¹å¹³æ»‘
        data = self.smooth_trajectories(data)
        
        # ç‰¹å¾å·¥ç¨‹
        data = self.extract_features(data)
        
        # æ ‡å‡†åŒ–
        data = self.normalize_features(data)
        
        return data
    
    def smooth_trajectories(self, data):
        """è½¨è¿¹å¹³æ»‘å¤„ç†"""
        # ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢æˆ–ç§»åŠ¨å¹³å‡è¿›è¡Œè½¨è¿¹å¹³æ»‘
        return data
    
    def extract_features(self, data):
        """ç‰¹å¾æå–"""
        # åŸºäºNGSIMæ•°æ®æ ¼å¼è®¡ç®—ç‰¹å¾ï¼ˆä½¿ç”¨å°å†™åˆ—åï¼‰
        if 'v_vel' in data.columns:
            data['velocity'] = data['v_vel']
        else:
            data['velocity'] = 0
            
        if 'v_acc' in data.columns:
            data['acceleration'] = data['v_acc']
        else:
            data['acceleration'] = data['velocity'].diff().fillna(0)
            
        # è®¡ç®—èˆªå‘è§’ï¼ˆåŸºäºä½ç½®å˜åŒ–ï¼‰
        if 'local_x' in data.columns and 'local_y' in data.columns:
            data['dx'] = data['local_x'].diff().fillna(0)
            data['dy'] = data['local_y'].diff().fillna(0)
            data['heading'] = np.arctan2(data['dy'], data['dx'])
        else:
            data['heading'] = 0
        
        return data
    
    def normalize_features(self, data):
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        # Z-scoreæ ‡å‡†åŒ–
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        data[numeric_columns] = (data[numeric_columns] - data[numeric_columns].mean()) / data[numeric_columns].std()
        
        return data
    
    def __len__(self):
        return len(self.data) - self.sequence_length - self.prediction_length + 1
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬"""
        # è·å–è½¦è¾†åºåˆ—æ•°æ®
        vehicle_ids = self.data['vehicle_id'].unique()
        
        # ç®€åŒ–å¤„ç†ï¼šæŒ‰ç´¢å¼•è·å–è½¦è¾†æ•°æ®
        if idx < len(vehicle_ids):
            vehicle_id = vehicle_ids[idx]
            vehicle_data = self.data[self.data['vehicle_id'] == vehicle_id]
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
            if len(vehicle_data) < self.sequence_length + self.prediction_length:
                # å¦‚æœæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å¡«å……æˆ–è·³è¿‡
                vehicle_data = vehicle_data.iloc[:self.sequence_length + self.prediction_length]
            
            # å†å²è½¨è¿¹
            history = vehicle_data.iloc[:self.sequence_length]
            
            # æœªæ¥è½¨è¿¹
            future = vehicle_data.iloc[self.sequence_length:self.sequence_length + self.prediction_length]
            
            # æå–å¤šæ¨¡æ€ç‰¹å¾
            visual_features = self.extract_visual_features(history)
            motion_features = self.extract_motion_features(history)
            traffic_features = self.extract_traffic_features(history)
            
            # å·¦è½¬æ„å›¾æ ‡ç­¾ï¼ˆä»é¢„å¤„ç†æ•°æ®ä¸­è·å–ï¼‰
            left_turn_intent = self.get_left_turn_intent(vehicle_data)
        else:
            # ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¿”å›é»˜è®¤æ•°æ®
            return self.__getitem__(idx % len(vehicle_ids))
        
        # ç›®æ ‡è½¨è¿¹ï¼ˆä½¿ç”¨NGSIMæ•°æ®çš„local_x, local_yåˆ—ï¼‰
        if 'local_x' in future.columns and 'local_y' in future.columns:
            target_trajectory = future[['local_x', 'local_y']].values
        else:
            # å¦‚æœæ²¡æœ‰ä½ç½®åˆ—ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            target_trajectory = np.random.randn(len(future), 2)
        
        return {
            'visual_features': torch.FloatTensor(visual_features),
            'motion_features': torch.FloatTensor(motion_features),
            'traffic_features': torch.FloatTensor(traffic_features),
            'left_turn_intent': torch.FloatTensor([left_turn_intent]),
            'target_trajectory': torch.FloatTensor(target_trajectory)
        }
    
    def extract_visual_features(self, history):
        """æå–è§†è§‰ç‰¹å¾"""
        # è¿™é‡Œåº”è¯¥ä»è§†é¢‘å¸§ä¸­æå–è§†è§‰ç‰¹å¾
        # ç®€åŒ–å®ç°ï¼Œè¿”å›éšæœºç‰¹å¾
        return np.random.randn(64)
    
    def extract_motion_features(self, history):
        """æå–è¿åŠ¨ç‰¹å¾"""
        features = []
        # ä½¿ç”¨NGSIMæ•°æ®çš„å®é™…åˆ—åï¼ˆå°å†™ï¼‰
        for col in ['local_x', 'local_y', 'v_vel', 'v_acc']:
            if col in history.columns:
                features.extend(history[col].values)
            else:
                # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œå¡«å……é›¶å€¼
                features.extend([0.0] * len(history))
        
        # æ·»åŠ è®¡ç®—çš„èˆªå‘è§’ç‰¹å¾
        if 'local_x' in history.columns and 'local_y' in history.columns:
            dx = history['local_x'].diff().fillna(0)
            dy = history['local_y'].diff().fillna(0)
            headings = np.arctan2(dy, dx)
            features.extend(headings.values)
        else:
            features.extend([0.0] * len(history))
        
        # ç¡®ä¿è¿”å›å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡
        if len(features) == 0:
            features = [0.0] * 40  # é»˜è®¤40ç»´ç‰¹å¾
        elif len(features) < 40:
            features.extend([0.0] * (40 - len(features)))
        elif len(features) > 40:
            features = features[:40]
            
        return np.array(features)
    
    def extract_traffic_features(self, history):
        """æå–äº¤é€šç¯å¢ƒç‰¹å¾"""
        features = []
        # ä½¿ç”¨NGSIMæ•°æ®çš„å®é™…åˆ—åï¼ˆå°å†™ï¼‰
        for col in ['lane_id', 'preceding', 'following', 'space_headway', 'time_headway']:
            if col in history.columns:
                features.extend(history[col].values)
            else:
                # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œå¡«å……é›¶å€¼
                features.extend([0.0] * len(history))
        
        # ç¡®ä¿è¿”å›å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡
        if len(features) == 0:
            features = [0.0] * 32  # é»˜è®¤32ç»´ç‰¹å¾
        elif len(features) < 32:
            features.extend([0.0] * (32 - len(features)))
        elif len(features) > 32:
            features = features[:32]
            
        return np.array(features)
    
    def get_left_turn_intent(self, vehicle_data):
        """ä»é¢„å¤„ç†æ•°æ®ä¸­è·å–å·¦è½¬æ„å›¾æ ‡ç­¾"""
        # ç›´æ¥ä»é¢„å¤„ç†æ•°æ®ä¸­è¯»å–is_high_qualityæ ‡è®°
        # é¢„å¤„ç†ç®¡é“å·²ç»å®Œæˆäº†ç²¾ç¡®çš„å·¦è½¬è¯†åˆ«
        if 'is_high_quality' in vehicle_data.columns:
            return 1.0 if vehicle_data['is_high_quality'].iloc[0] else 0.0
        else:
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ²¡æœ‰è´¨é‡æ ‡è®°ï¼Œé»˜è®¤ä¸ºå·¦è½¬æ•°æ®
            return 1.0

class VisualEncoder(nn.Module):
    """è§†è§‰ç‰¹å¾ç¼–ç å™¨"""
    
    def __init__(self, input_dim: int = 64, hidden_dim: int = 128):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
    
    def forward(self, x):
        return self.encoder(x)

class MotionEncoder(nn.Module):
    """è¿åŠ¨ç‰¹å¾ç¼–ç å™¨"""
    
    def __init__(self, input_dim: int, hidden_dim: int = 128, num_layers: int = 2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_dim // 8,  # å‡è®¾æœ‰8ä¸ªæ—¶é—´æ­¥
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_dim, hidden_dim)
    
    def forward(self, x):
        # é‡å¡‘è¾“å…¥ä¸º(batch_size, seq_len, feature_dim)
        batch_size = x.size(0)
        seq_len = 8
        feature_dim = x.size(1) // seq_len
        x = x.view(batch_size, seq_len, feature_dim)
        
        output, (hidden, cell) = self.lstm(x)
        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        return self.fc(output[:, -1, :])

class TrafficEncoder(nn.Module):
    """äº¤é€šç¯å¢ƒç‰¹å¾ç¼–ç å™¨"""
    
    def __init__(self, input_dim: int = 32, hidden_dim: int = 128):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
    
    def forward(self, x):
        return self.encoder(x)

class AttentionFusion(nn.Module):
    """æ³¨æ„åŠ›èåˆæ¨¡å—"""
    
    def __init__(self, feature_dim: int = 128):
        super().__init__()
        self.feature_dim = feature_dim
        
        # è‡ªæ³¨æ„åŠ›æœºåˆ¶
        self.query = nn.Linear(feature_dim, feature_dim)
        self.key = nn.Linear(feature_dim, feature_dim)
        self.value = nn.Linear(feature_dim, feature_dim)
        
        # è·¨æ¨¡æ€æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=8,
            dropout=0.1
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(feature_dim * 3, feature_dim)
    
    def forward(self, visual_feat, motion_feat, traffic_feat):
        # å †å ç‰¹å¾
        features = torch.stack([visual_feat, motion_feat, traffic_feat], dim=1)
        
        # è‡ªæ³¨æ„åŠ›
        Q = self.query(features)
        K = self.key(features)
        V = self.value(features)
        
        attention_weights = torch.softmax(
            torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.feature_dim), 
            dim=-1
        )
        attended_features = torch.matmul(attention_weights, V)
        
        # è·¨æ¨¡æ€æ³¨æ„åŠ›
        attended_features = attended_features.transpose(0, 1)
        cross_attended, _ = self.cross_attention(
            attended_features, attended_features, attended_features
        )
        cross_attended = cross_attended.transpose(0, 1)
        
        # èåˆç‰¹å¾
        fused_features = cross_attended.contiguous().view(cross_attended.size(0), -1)
        output = self.output_proj(fused_features)
        
        return output

class IntentClassifier(nn.Module):
    """å·¦è½¬æ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self, input_dim: int = 128, hidden_dim: int = 64):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.classifier(x)

class TrajectoryDecoder(nn.Module):
    """è½¨è¿¹é¢„æµ‹è§£ç å™¨"""
    
    def __init__(self, input_dim: int = 129, hidden_dim: int = 128, output_dim: int = 2, seq_len: int = 12):
        super().__init__()
        self.seq_len = seq_len
        self.hidden_dim = hidden_dim
        
        # LSTMè§£ç å™¨
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            dropout=0.2
        )
        
        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(hidden_dim, output_dim)
        
        # åˆå§‹éšè—çŠ¶æ€
        self.init_hidden = nn.Linear(input_dim, hidden_dim * 2 * 2)  # 2 layers * 2 (h,c)
    
    def forward(self, fused_features, intent_prob):
        batch_size = fused_features.size(0)
        
        # ç»“åˆæ„å›¾ä¿¡æ¯
        input_features = torch.cat([fused_features, intent_prob], dim=1)
        
        # åˆå§‹åŒ–éšè—çŠ¶æ€
        init_states = self.init_hidden(input_features)
        h0 = init_states[:, :self.hidden_dim*2].reshape(2, batch_size, self.hidden_dim)
        c0 = init_states[:, self.hidden_dim*2:].reshape(2, batch_size, self.hidden_dim)
        
        # è§£ç é¢„æµ‹è½¨è¿¹
        outputs = []
        hidden = (h0, c0)
        
        # ç¬¬ä¸€æ­¥è¾“å…¥ - ä½¿ç”¨å›ºå®šçš„è¾“å…¥ç‰¹å¾
        decoder_input = input_features.unsqueeze(1)  # [batch, 1, input_dim]
        
        for t in range(self.seq_len):
            output, hidden = self.lstm(decoder_input, hidden)
            trajectory_point = self.output_layer(output)
            outputs.append(trajectory_point)
            
            # ä¿æŒè¾“å…¥ç»´åº¦ä¸€è‡´ï¼Œä¸æ·»åŠ trajectory_point
            # ä½¿ç”¨ç›¸åŒçš„input_featuresä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥
            decoder_input = input_features.unsqueeze(1)
        
        # æ‹¼æ¥æ‰€æœ‰è¾“å‡º
        trajectory = torch.cat(outputs, dim=1)
        
        return trajectory

class LeftTurnPredictor(nn.Module):
    """å·¦è½¬è½¨è¿¹é¢„æµ‹ä¸»æ¨¡å‹"""
    
    def __init__(self, visual_dim: int = 64, motion_dim: int = 40, traffic_dim: int = 32):
        super().__init__()
        
        # ç‰¹å¾ç¼–ç å™¨
        self.visual_encoder = VisualEncoder(visual_dim)
        self.motion_encoder = MotionEncoder(motion_dim)
        self.traffic_encoder = TrafficEncoder(traffic_dim)
        
        # æ³¨æ„åŠ›èåˆ
        self.attention_fusion = AttentionFusion()
        
        # æ„å›¾åˆ†ç±»å™¨
        self.intent_classifier = IntentClassifier()
        
        # è½¨è¿¹è§£ç å™¨
        self.trajectory_decoder = TrajectoryDecoder()
    
    def forward(self, visual_feat, motion_feat, traffic_feat):
        # ç‰¹å¾ç¼–ç 
        visual_encoded = self.visual_encoder(visual_feat)
        motion_encoded = self.motion_encoder(motion_feat)
        traffic_encoded = self.traffic_encoder(traffic_feat)
        
        # å¤šæ¨¡æ€èåˆ
        fused_features = self.attention_fusion(
            visual_encoded, motion_encoded, traffic_encoded
        )
        
        # æ„å›¾é¢„æµ‹
        intent_prob = self.intent_classifier(fused_features)
        
        # è½¨è¿¹é¢„æµ‹
        trajectory = self.trajectory_decoder(fused_features, intent_prob)
        
        return intent_prob, trajectory

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self, model, train_loader, val_loader, device='cuda'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', patience=10, factor=0.5
        )
        
        # æŸå¤±å‡½æ•°
        self.intent_loss_fn = nn.BCELoss()
        self.trajectory_loss_fn = nn.MSELoss()
        
        # è®­ç»ƒå†å²
        self.train_history = {'loss': [], 'intent_acc': [], 'traj_error': []}
        self.val_history = {'loss': [], 'intent_acc': [], 'traj_error': []}
    
    def train_epoch(self, epoch_num=None, total_epochs=None):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        intent_correct = 0
        total_samples = 0
        traj_error = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        desc = f"Epoch {epoch_num}/{total_epochs} [Train]" if epoch_num and total_epochs else "Training"
        pbar = tqdm(self.train_loader, desc=desc, leave=False)
        
        batch_losses = []
        batch_start_time = time.time()
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            visual_feat = batch['visual_features'].to(self.device)
            motion_feat = batch['motion_features'].to(self.device)
            traffic_feat = batch['traffic_features'].to(self.device)
            intent_target = batch['left_turn_intent'].to(self.device)
            traj_target = batch['target_trajectory'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)
            
            # è®¡ç®—æŸå¤±
            intent_loss = self.intent_loss_fn(intent_pred, intent_target)
            traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)
            
            # è”åˆæŸå¤±
            total_batch_loss = intent_loss + 0.5 * traj_loss
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            total_batch_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç»Ÿè®¡
            batch_loss = total_batch_loss.item()
            total_loss += batch_loss
            batch_losses.append(batch_loss)
            intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()
            total_samples += intent_target.size(0)
            traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()
            
            # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
            if batch_idx % 5 == 0:  # æ¯5ä¸ªbatchæ›´æ–°ä¸€æ¬¡
                current_avg_loss = np.mean(batch_losses[-10:]) if len(batch_losses) >= 10 else np.mean(batch_losses)
                current_intent_acc = intent_correct / total_samples if total_samples > 0 else 0
                
                # è®¡ç®—å¤„ç†é€Ÿåº¦
                elapsed_time = time.time() - batch_start_time
                samples_per_sec = total_samples / elapsed_time if elapsed_time > 0 else 0
                
                pbar.set_postfix({
                    'Loss': f'{current_avg_loss:.4f}',
                    'IntentAcc': f'{current_intent_acc:.3f}',
                    'Speed': f'{samples_per_sec:.1f}samples/s'
                })
        
        pbar.close()
        
        avg_loss = total_loss / len(self.train_loader)
        intent_acc = intent_correct / total_samples
        avg_traj_error = traj_error / len(self.train_loader)
        
        return avg_loss, intent_acc, avg_traj_error
    
    def validate(self, epoch_num=None, total_epochs=None):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        intent_correct = 0
        total_samples = 0
        traj_error = 0
        
        # åˆ›å»ºéªŒè¯è¿›åº¦æ¡
        desc = f"Epoch {epoch_num}/{total_epochs} [Valid]" if epoch_num and total_epochs else "Validating"
        pbar = tqdm(self.val_loader, desc=desc, leave=False)
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(pbar):
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                visual_feat = batch['visual_features'].to(self.device)
                motion_feat = batch['motion_features'].to(self.device)
                traffic_feat = batch['traffic_features'].to(self.device)
                intent_target = batch['left_turn_intent'].to(self.device)
                traj_target = batch['target_trajectory'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                intent_pred, traj_pred = self.model(visual_feat, motion_feat, traffic_feat)
                
                # è®¡ç®—æŸå¤±
                intent_loss = self.intent_loss_fn(intent_pred, intent_target)
                traj_loss = self.trajectory_loss_fn(traj_pred, traj_target)
                total_batch_loss = intent_loss + 0.5 * traj_loss
                
                # ç»Ÿè®¡
                total_loss += total_batch_loss.item()
                intent_correct += ((intent_pred > 0.5) == (intent_target > 0.5)).sum().item()
                total_samples += intent_target.size(0)
                traj_error += torch.sqrt(torch.mean((traj_pred - traj_target) ** 2)).item()
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                if batch_idx % 3 == 0:  # éªŒè¯æ—¶æ›´é¢‘ç¹æ›´æ–°
                    current_avg_loss = total_loss / (batch_idx + 1)
                    current_intent_acc = intent_correct / total_samples if total_samples > 0 else 0
                    
                    pbar.set_postfix({
                        'Loss': f'{current_avg_loss:.4f}',
                        'IntentAcc': f'{current_intent_acc:.3f}'
                    })
        
        pbar.close()
        
        avg_loss = total_loss / len(self.val_loader)
        intent_acc = intent_correct / total_samples
        avg_traj_error = traj_error / len(self.val_loader)
        
        return avg_loss, intent_acc, avg_traj_error
    
    def train(self, epochs: int = 100, early_stopping_patience: int = 15):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        best_val_loss = float('inf')
        patience_counter = 0
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(self.train_loader.dataset):,}")
        print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(self.val_loader.dataset):,}")
        print(f"ğŸ¯ ç›®æ ‡è½®æ•°: {epochs}")
        print(f"â° æ—©åœè€å¿ƒ: {early_stopping_patience}")
        print(f"ğŸ’» è®¾å¤‡: {self.device}")
        print("=" * 80)
        
        # æ€»ä½“è¿›åº¦æ¡
        epoch_pbar = tqdm(range(epochs), desc="Overall Progress", position=0)
        
        training_start_time = time.time()
        
        for epoch in epoch_pbar:
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_intent_acc, train_traj_error = self.train_epoch(epoch+1, epochs)
            
            # éªŒè¯
            val_loss, val_intent_acc, val_traj_error = self.validate(epoch+1, epochs)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            old_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_loss)
            new_lr = self.optimizer.param_groups[0]['lr']
            
            # è®°å½•å†å²
            self.train_history['loss'].append(train_loss)
            self.train_history['intent_acc'].append(train_intent_acc)
            self.train_history['traj_error'].append(train_traj_error)
            
            self.val_history['loss'].append(val_loss)
            self.val_history['intent_acc'].append(val_intent_acc)
            self.val_history['traj_error'].append(val_traj_error)
            
            # è®¡ç®—æ—¶é—´ç»Ÿè®¡
            epoch_time = time.time() - epoch_start_time
            total_elapsed = time.time() - training_start_time
            avg_epoch_time = total_elapsed / (epoch + 1)
            eta = avg_epoch_time * (epochs - epoch - 1)
            
            # æ—©åœæ£€æŸ¥å’Œæ¨¡å‹ä¿å­˜
            improvement = ""
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_model.pth')
                improvement = "ğŸ’¾ [BEST]"
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    improvement = "â¹ï¸ [EARLY STOP]"
            
            # å­¦ä¹ ç‡å˜åŒ–æç¤º
            lr_info = f"ğŸ“‰ LR: {old_lr:.2e}" if new_lr == old_lr else f"ğŸ“‰ LR: {old_lr:.2e}â†’{new_lr:.2e}"
            
            # æ›´æ–°æ€»ä½“è¿›åº¦æ¡
            epoch_pbar.set_postfix({
                'Train_Loss': f'{train_loss:.4f}',
                'Val_Loss': f'{val_loss:.4f}',
                'Val_Acc': f'{val_intent_acc:.3f}',
                'Patience': f'{patience_counter}/{early_stopping_patience}',
                'ETA': f'{eta/60:.1f}min'
            })
            
            # è¯¦ç»†ä¿¡æ¯è¾“å‡º
            epoch_info = f"ğŸ“ˆ Epoch {epoch+1:3d}/{epochs} | " + \
                        f"â±ï¸ {epoch_time:.1f}s | " + \
                        f"ğŸ”„ Train: {train_loss:.4f} | " + \
                        f"âœ… Valid: {val_loss:.4f} | " + \
                        f"ğŸ¯ Acc: {val_intent_acc:.3f} | " + \
                        f"ğŸ“ TrajErr: {val_traj_error:.3f}"
            print(epoch_info)
            
            detail_info = f"    {lr_info} | " + \
                         f"â³ ETA: {eta/60:.1f}min | " + \
                         f"ğŸ• Total: {total_elapsed/60:.1f}min | " + \
                         f"{improvement}"
            print(detail_info)
            
            if patience_counter >= early_stopping_patience:
                print(f"â¹ï¸ æ—©åœè§¦å‘ï¼åœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break
        
        epoch_pbar.close()
        
        total_training_time = time.time() - training_start_time
        print("" + "=" * 80)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
        print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: best_model.pth")
        print("=" * 80)
        
        return self.train_history, self.val_history
    
    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # æŸå¤±æ›²çº¿
        axes[0].plot(self.train_history['loss'], label='Train Loss')
        axes[0].plot(self.val_history['loss'], label='Val Loss')
        axes[0].set_title('Training Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True)
        
        # æ„å›¾è¯†åˆ«å‡†ç¡®ç‡
        axes[1].plot(self.train_history['intent_acc'], label='Train Acc')
        axes[1].plot(self.val_history['intent_acc'], label='Val Acc')
        axes[1].set_title('Intent Classification Accuracy')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Accuracy')
        axes[1].legend()
        axes[1].grid(True)
        
        # è½¨è¿¹é¢„æµ‹è¯¯å·®
        axes[2].plot(self.train_history['traj_error'], label='Train Error')
        axes[2].plot(self.val_history['traj_error'], label='Val Error')
        axes[2].set_title('Trajectory Prediction Error')
        axes[2].set_xlabel('Epoch')
        axes[2].set_ylabel('RMSE')
        axes[2].legend()
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

def evaluate_model(model, test_loader, device='cuda'):
    """æ¨¡å‹è¯„ä¼°"""
    model.eval()
    
    all_intent_preds = []
    all_intent_targets = []
    all_traj_preds = []
    all_traj_targets = []
    
    with torch.no_grad():
        for batch in test_loader:
            visual_feat = batch['visual_features'].to(device)
            motion_feat = batch['motion_features'].to(device)
            traffic_feat = batch['traffic_features'].to(device)
            intent_target = batch['left_turn_intent'].to(device)
            traj_target = batch['target_trajectory'].to(device)
            
            intent_pred, traj_pred = model(visual_feat, motion_feat, traffic_feat)
            
            all_intent_preds.append(intent_pred.cpu().numpy())
            all_intent_targets.append(intent_target.cpu().numpy())
            all_traj_preds.append(traj_pred.cpu().numpy())
            all_traj_targets.append(traj_target.cpu().numpy())
    
    # åˆå¹¶ç»“æœ
    intent_preds = np.concatenate(all_intent_preds)
    intent_targets = np.concatenate(all_intent_targets)
    traj_preds = np.concatenate(all_traj_preds)
    traj_targets = np.concatenate(all_traj_targets)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    # æ„å›¾è¯†åˆ«æŒ‡æ ‡
    intent_binary_preds = (intent_preds > 0.5).astype(int)
    intent_binary_targets = (intent_targets > 0.5).astype(int)
    
    intent_accuracy = accuracy_score(intent_binary_targets, intent_binary_preds)
    intent_precision = precision_score(intent_binary_targets, intent_binary_preds)
    intent_recall = recall_score(intent_binary_targets, intent_binary_preds)
    intent_f1 = f1_score(intent_binary_targets, intent_binary_preds)
    
    # è½¨è¿¹é¢„æµ‹æŒ‡æ ‡
    # ADE (Average Displacement Error)
    ade = np.mean(np.sqrt(np.sum((traj_preds - traj_targets) ** 2, axis=2)))
    
    # FDE (Final Displacement Error)
    fde = np.mean(np.sqrt(np.sum((traj_preds[:, -1, :] - traj_targets[:, -1, :]) ** 2, axis=1)))
    
    print("=" * 60)
    print("æ¨¡å‹è¯„ä¼°ç»“æœ")
    print("=" * 60)
    print(f"æ„å›¾è¯†åˆ«å‡†ç¡®ç‡: {intent_accuracy:.4f}")
    print(f"æ„å›¾è¯†åˆ«ç²¾ç¡®ç‡: {intent_precision:.4f}")
    print(f"æ„å›¾è¯†åˆ«å¬å›ç‡: {intent_recall:.4f}")
    print(f"æ„å›¾è¯†åˆ«F1åˆ†æ•°: {intent_f1:.4f}")
    print("-" * 40)
    print(f"è½¨è¿¹é¢„æµ‹ADE: {ade:.4f} m")
    print(f"è½¨è¿¹é¢„æµ‹FDE: {fde:.4f} m")
    print("=" * 60)
    
    return {
        'intent_accuracy': intent_accuracy,
        'intent_precision': intent_precision,
        'intent_recall': intent_recall,
        'intent_f1': intent_f1,
        'trajectory_ade': ade,
        'trajectory_fde': fde
    }

def main():
    """ä¸»å‡½æ•°"""
    print("è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ")
    print("åŸºäºå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ ")
    print("=" * 50)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–é¢„å¤„ç†æ•°æ®è·¯å¾„
    processed_data_path = input("è¯·è¾“å…¥é¢„å¤„ç†æ•°æ®è·¯å¾„ (é»˜è®¤: processed_data/processed_left_turn_data.csv): ").strip()
    if not processed_data_path:
        processed_data_path = "processed_data/processed_left_turn_data.csv"
    
    # æ£€æŸ¥é¢„å¤„ç†æ•°æ®æ˜¯å¦å­˜åœ¨
    import os
    if not os.path.exists(processed_data_path):
        print(f"âŒ é¢„å¤„ç†æ•°æ®ä¸å­˜åœ¨: {processed_data_path}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ æ•°æ®é¢„å¤„ç†ç®¡é“.py ç”Ÿæˆé¢„å¤„ç†æ•°æ®")
        print("   æˆ–è€…ä½¿ç”¨åŸå§‹æ•°æ®è·¯å¾„ï¼ˆä¸æ¨èï¼Œå› ä¸ºæ²¡æœ‰ç²¾ç¡®çš„å·¦è½¬è¯†åˆ«ï¼‰")
        
        use_raw = input("æ˜¯å¦ä½¿ç”¨åŸå§‹æ•°æ®ï¼Ÿ(y/N): ").strip().lower()
        if use_raw == 'y':
            processed_data_path = '../data/peachtree_filtered_data.csv'
            print("âš ï¸  è­¦å‘Š: ä½¿ç”¨åŸå§‹æ•°æ®å¯èƒ½åŒ…å«éå·¦è½¬è½¦è¾†")
        else:
            print("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ç®¡é“")
            return
    
    # åˆ›å»ºæ•°æ®é›†
    print("åˆ›å»ºæ•°æ®é›†...")
    try:
        # ä½¿ç”¨é¢„å¤„ç†å¥½çš„é«˜è´¨é‡å·¦è½¬æ•°æ®
        full_dataset = MultiModalDataset(data_path=processed_data_path)
        
        # æ•°æ®é›†åˆ’åˆ†
        dataset_size = len(full_dataset)
        train_size = int(0.7 * dataset_size)
        val_size = int(0.15 * dataset_size)
        test_size = dataset_size - train_size - val_size
        
        print(f"æ•°æ®é›†å¤§å°: è®­ç»ƒ={train_size}, éªŒè¯={val_size}, æµ‹è¯•={test_size}")
        
        # ç®€å•åˆ’åˆ†ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„åˆ’åˆ†ç­–ç•¥ï¼‰
        train_dataset = torch.utils.data.Subset(full_dataset, range(train_size))
        val_dataset = torch.utils.data.Subset(full_dataset, range(train_size, train_size + val_size))
        test_dataset = torch.utils.data.Subset(full_dataset, range(train_size + val_size, dataset_size))
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        train_dataset = MockDataset(800)
        val_dataset = MockDataset(200)
        test_dataset = MockDataset(200)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = LeftTurnPredictor()
    
    # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
    trainer = TrainingManager(model, train_loader, val_loader, device)
    
    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒ...")
    train_history, val_history = trainer.train(epochs=50)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    trainer.plot_training_history()
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load('best_model.pth'))
    
    # è¯„ä¼°æ¨¡å‹
    print("è¯„ä¼°æ¨¡å‹...")
    results = evaluate_model(model, test_loader, device)
    
    print("è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()