#!/usr/bin/env python3
"""
è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹è¯„ä»·æŒ‡æ ‡å®ç°
åŒ…å«å®Œæ•´çš„è¯„ä»·æ–¹æ³•å’Œå¯è§†åŒ–åŠŸèƒ½
ä¸“é—¨é’ˆå¯¹è·¯å£1è¿›è¡Œå·¦è½¬é¢„æµ‹è¯„ä»·
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import precision_recall_curve
import pandas as pd
from typing import Dict, List, Tuple, Optional
import time
import os
import warnings
warnings.filterwarnings('ignore')

class TrajectoryEvaluator:
    """
    è½¨è¿¹é¢„æµ‹è¯„ä»·å™¨
    """
    
    def __init__(self, prediction_length: int = 12, time_step: float = 0.4):
        """
        åˆå§‹åŒ–è¯„ä»·å™¨
        
        Args:
            prediction_length: é¢„æµ‹æ—¶é•¿ï¼ˆå¸§æ•°ï¼‰
            time_step: æ—¶é—´æ­¥é•¿ï¼ˆç§’ï¼‰
        """
        self.prediction_length = prediction_length
        self.time_step = time_step
        self.evaluation_results = {}
        
    def calculate_ade(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—å¹³å‡ä½ç§»è¯¯å·® (Average Displacement Error)
        
        Args:
            predictions: é¢„æµ‹è½¨è¿¹ [N, T, 2]
            ground_truth: çœŸå®è½¨è¿¹ [N, T, 2]
            
        Returns:
            ADEå€¼ (ç±³)
        """
        if predictions.shape != ground_truth.shape:
            raise ValueError("é¢„æµ‹è½¨è¿¹å’ŒçœŸå®è½¨è¿¹çš„å½¢çŠ¶å¿…é¡»ç›¸åŒ")
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„ä½ç§»è¯¯å·®
        displacement_errors = np.sqrt(np.sum((predictions - ground_truth) ** 2, axis=2))
        
        # è®¡ç®—å¹³å‡ä½ç§»è¯¯å·®
        ade = np.mean(displacement_errors)
        
        return float(ade)
    
    def calculate_fde(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—æœ€ç»ˆä½ç§»è¯¯å·® (Final Displacement Error)
        
        Args:
            predictions: é¢„æµ‹è½¨è¿¹ [N, T, 2]
            ground_truth: çœŸå®è½¨è¿¹ [N, T, 2]
            
        Returns:
            FDEå€¼ (ç±³)
        """
        if predictions.shape != ground_truth.shape:
            raise ValueError("é¢„æµ‹è½¨è¿¹å’ŒçœŸå®è½¨è¿¹çš„å½¢çŠ¶å¿…é¡»ç›¸åŒ")
        
        # è®¡ç®—æœ€ç»ˆæ—¶é—´æ­¥çš„ä½ç§»è¯¯å·®
        final_displacement_errors = np.sqrt(np.sum((predictions[:, -1, :] - ground_truth[:, -1, :]) ** 2, axis=1))
        
        # è®¡ç®—å¹³å‡æœ€ç»ˆä½ç§»è¯¯å·®
        fde = np.mean(final_displacement_errors)
        
        return float(fde)
    
    def calculate_rmse(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—å‡æ–¹æ ¹è¯¯å·® (Root Mean Square Error)
        """
        mse = np.mean((predictions - ground_truth) ** 2)
        rmse = np.sqrt(mse)
        return float(rmse)
    
    def calculate_mae(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·® (Mean Absolute Error)
        """
        mae = np.mean(np.abs(predictions - ground_truth))
        return float(mae)
    
    def calculate_heading_error(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—èˆªå‘è§’è¯¯å·®
        """
        # è®¡ç®—é€Ÿåº¦å‘é‡
        pred_velocities = np.diff(predictions, axis=1)
        gt_velocities = np.diff(ground_truth, axis=1)
        
        # è®¡ç®—èˆªå‘è§’
        pred_headings = np.arctan2(pred_velocities[:, :, 1], pred_velocities[:, :, 0])
        gt_headings = np.arctan2(gt_velocities[:, :, 1], gt_velocities[:, :, 0])
        
        # è®¡ç®—è§’åº¦å·®å¼‚
        heading_diff = np.abs(pred_headings - gt_headings)
        heading_diff = np.minimum(heading_diff, 2 * np.pi - heading_diff)  # å¤„ç†è§’åº¦ç¯ç»•
        
        # è½¬æ¢ä¸ºåº¦æ•°å¹¶è®¡ç®—å¹³å‡å€¼
        heading_error = np.mean(np.degrees(heading_diff))
        
        return float(heading_error)
    
    def calculate_velocity_error(self, predictions: np.ndarray, ground_truth: np.ndarray) -> float:
        """
        è®¡ç®—é€Ÿåº¦è¯¯å·®
        """
        # è®¡ç®—é€Ÿåº¦
        pred_velocities = np.sqrt(np.sum(np.diff(predictions, axis=1) ** 2, axis=2)) / self.time_step
        gt_velocities = np.sqrt(np.sum(np.diff(ground_truth, axis=1) ** 2, axis=2)) / self.time_step
        
        # è®¡ç®—é€Ÿåº¦è¯¯å·®
        velocity_error = np.mean(np.abs(pred_velocities - gt_velocities))
        
        return float(velocity_error)
    
    def evaluate_trajectory_accuracy(self, predictions: np.ndarray, ground_truth: np.ndarray) -> Dict:
        """
        è¯„ä»·è½¨è¿¹é¢„æµ‹ç²¾åº¦
        """
        results = {
            'ade': self.calculate_ade(predictions, ground_truth),
            'fde': self.calculate_fde(predictions, ground_truth),
            'rmse': self.calculate_rmse(predictions, ground_truth),
            'mae': self.calculate_mae(predictions, ground_truth),
            'heading_error': self.calculate_heading_error(predictions, ground_truth),
            'velocity_error': self.calculate_velocity_error(predictions, ground_truth)
        }
        
        return results
    
    def evaluate_intent_classification(self, intent_predictions: np.ndarray,
                                     intent_ground_truth: np.ndarray) -> Dict:
        """
        è¯„ä»·æ„å›¾åˆ†ç±»æ€§èƒ½
        """
        # å°†è¿ç»­é¢„æµ‹è½¬æ¢ä¸ºäºŒåˆ†ç±»
        intent_pred_binary = (intent_predictions > 0.5).astype(int)
        intent_gt_binary = intent_ground_truth.astype(int)
        
        # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        accuracy = accuracy_score(intent_gt_binary, intent_pred_binary)
        precision = precision_score(intent_gt_binary, intent_pred_binary, zero_division=0)
        recall = recall_score(intent_gt_binary, intent_pred_binary, zero_division=0)
        f1 = f1_score(intent_gt_binary, intent_pred_binary, zero_division=0)
        
        # è®¡ç®—ROC AUC
        try:
            fpr, tpr, _ = roc_curve(intent_gt_binary, intent_predictions)
            roc_auc = auc(fpr, tpr)
        except:
            roc_auc = 0.5
        
        # è®¡ç®—PR AUC
        try:
            precision_curve, recall_curve, _ = precision_recall_curve(intent_gt_binary, intent_predictions)
            pr_auc = auc(recall_curve, precision_curve)
        except:
            pr_auc = 0.5
        
        results = {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1_score': float(f1),
            'roc_auc': float(roc_auc),
            'pr_auc': float(pr_auc),
            'confusion_matrix': confusion_matrix(intent_gt_binary, intent_pred_binary).tolist()
        }
        
        return results
    
    def evaluate_temporal_consistency(self, predictions: np.ndarray) -> Dict:
        """
        è¯„ä»·æ—¶é—´ä¸€è‡´æ€§
        """
        # è®¡ç®—ç›¸é‚»æ—¶é—´æ­¥çš„é€Ÿåº¦å˜åŒ–
        velocities = np.diff(predictions, axis=1)
        accelerations = np.diff(velocities, axis=1)
        
        # è®¡ç®—åŠ é€Ÿåº¦çš„æ ‡å‡†å·®ä½œä¸ºå¹³æ»‘åº¦æŒ‡æ ‡
        smoothness = np.mean(np.std(accelerations, axis=1))
        
        # è®¡ç®—è½¨è¿¹çš„æ€»å˜åŒ–é‡
        total_variation = np.mean(np.sum(np.abs(np.diff(predictions, axis=1)), axis=(1, 2)))
        
        results = {
            'smoothness': float(smoothness),
            'total_variation': float(total_variation)
        }
        
        return results
    
    def evaluate_physical_constraints(self, trajectories: np.ndarray) -> Dict:
        """
        è¯„ä»·ç‰©ç†çº¦æŸæ»¡è¶³æƒ…å†µ
        """
        # è®¡ç®—é€Ÿåº¦
        velocities = np.sqrt(np.sum(np.diff(trajectories, axis=1) ** 2, axis=2)) / self.time_step
        
        # è®¡ç®—åŠ é€Ÿåº¦
        accelerations = np.diff(velocities, axis=1) / self.time_step
        
        # å®šä¹‰çº¦æŸ
        MAX_VELOCITY = 30.0  # m/s (çº¦108 km/h)
        MAX_ACCELERATION = 5.0  # m/sÂ²
        
        # æ£€æŸ¥è¿åæƒ…å†µ
        velocity_violations = np.sum(velocities > MAX_VELOCITY)
        acceleration_violations = np.sum(np.abs(accelerations) > MAX_ACCELERATION)
        
        total_points = velocities.size
        total_acc_points = accelerations.size
        
        results = {
            'max_velocity': float(np.max(velocities)),
            'velocity_violation_rate': float(velocity_violations / total_points),
            'max_acceleration': float(np.max(np.abs(accelerations))),
            'acceleration_violation_rate': float(acceleration_violations / total_acc_points)
        }
        
        return results
    
    def analyze_temporal_patterns(self, predictions: np.ndarray, ground_truth: np.ndarray) -> Dict:
        """
        åˆ†ææ—¶é—´æ¨¡å¼
        """
        timestep_errors = []
        
        for t in range(predictions.shape[1]):
            error = np.mean(np.sqrt(np.sum((predictions[:, t, :] - ground_truth[:, t, :]) ** 2, axis=1)))
            timestep_errors.append(float(error))
        
        results = {
            'timestep_errors': timestep_errors,
            'error_growth_rate': float((timestep_errors[-1] - timestep_errors[0]) / len(timestep_errors))
        }
        
        return results
    
    def comprehensive_evaluation(self, predictions: np.ndarray, ground_truth: np.ndarray,
                               intent_predictions: np.ndarray, intent_ground_truth: np.ndarray) -> Dict:
        """
        ç»¼åˆè¯„ä»·
        """
        print("æ‰§è¡Œç»¼åˆè¯„ä»·...")
        
        results = {}
        
        # è½¨è¿¹ç²¾åº¦è¯„ä»·
        results['trajectory_accuracy'] = self.evaluate_trajectory_accuracy(predictions, ground_truth)
        
        # æ„å›¾åˆ†ç±»è¯„ä»·
        results['intent_classification'] = self.evaluate_intent_classification(intent_predictions, intent_ground_truth)
        
        # æ—¶é—´ä¸€è‡´æ€§è¯„ä»·
        results['temporal_consistency'] = self.evaluate_temporal_consistency(predictions)
        
        # ç‰©ç†çº¦æŸè¯„ä»·
        results['physical_constraints'] = self.evaluate_physical_constraints(predictions)
        
        # æ—¶é—´æ¨¡å¼åˆ†æ
        results['temporal_analysis'] = self.analyze_temporal_patterns(predictions, ground_truth)
        
        return results

def load_intersection_data(intersection_id: int = 1, data_path: str = None) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    åŠ è½½æŒ‡å®šè·¯å£çš„NGSIMæ•°æ®
    
    Args:
        intersection_id: è·¯å£IDï¼Œé»˜è®¤ä¸º1
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        filtered_data: è¿‡æ»¤åçš„æ•°æ®
        left_turn_data: å·¦è½¬æ•°æ®
    """
    # æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    if data_path is None:
        data_paths = [
            "../data/peachtree_filtered_data.csv",
            "data/peachtree_filtered_data.csv", 
            "../data/peachtree_trajectory.csv",
            "data/peachtree_trajectory.csv"
        ]
    else:
        data_paths = [data_path]
    
    # å°è¯•åŠ è½½æ•°æ®
    data = None
    for path in data_paths:
        try:
            if os.path.exists(path):
                print(f"ğŸ“ åŠ è½½æ•°æ®æ–‡ä»¶: {path}")
                data = pd.read_csv(path)
                print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(data)} æ¡è®°å½•")
                break
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            continue
    
    if data is None:
        raise FileNotFoundError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„NGSIMæ•°æ®æ–‡ä»¶")
    
    # è¿‡æ»¤æŒ‡å®šè·¯å£çš„æ•°æ®
    if 'int_id' in data.columns:
        filtered_data = data[data['int_id'] == intersection_id].copy()
        print(f"ğŸ” è¿‡æ»¤è·¯å£ {intersection_id} çš„æ•°æ®: {len(filtered_data)} æ¡è®°å½•")
        print(f"åŒ…å« {len(filtered_data['vehicle_id'].unique())} è¾†è½¦è¾†")
    else:
        print("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰int_idåˆ—ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®")
        filtered_data = data.copy()
    
    # æå–å·¦è½¬æ•°æ® (movement=2)
    if 'movement' in filtered_data.columns:
        left_turn_data = filtered_data[filtered_data['movement'] == 2].copy()
        print(f"ğŸš— æ‰¾åˆ°å·¦è½¬è½¦è¾†: {len(left_turn_data['vehicle_id'].unique())} è¾†")
    else:
        print("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰movementåˆ—ï¼Œæ— æ³•è¯†åˆ«å·¦è½¬è½¦è¾†")
        left_turn_data = pd.DataFrame()
    
    return filtered_data, left_turn_data

def create_sample_data(num_samples: int = 100, prediction_length: int = 12) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•
    
    Returns:
        predictions, ground_truth, intent_predictions, intent_ground_truth
    """
    np.random.seed(42)
    
    # ç”Ÿæˆè½¨è¿¹æ•°æ®
    predictions = np.random.randn(num_samples, prediction_length, 2) * 0.5
    ground_truth = predictions + np.random.randn(num_samples, prediction_length, 2) * 0.3
    
    # ç”Ÿæˆæ„å›¾æ•°æ®
    intent_ground_truth = np.random.binomial(1, 0.3, num_samples).astype(float)
    intent_predictions = intent_ground_truth + np.random.randn(num_samples) * 0.2
    intent_predictions = np.clip(intent_predictions, 0, 1)
    
    return predictions, ground_truth, intent_predictions, intent_ground_truth

def prepare_intersection_evaluation_data(intersection_id: int = 1, data_path: str = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ä¸ºæŒ‡å®šè·¯å£å‡†å¤‡è¯„ä»·æ•°æ®
    
    Args:
        intersection_id: è·¯å£IDï¼Œé»˜è®¤ä¸º1
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        predictions, ground_truth, intent_predictions, intent_ground_truth
    """
    try:
        # åŠ è½½è·¯å£æ•°æ®
        filtered_data, left_turn_data = load_intersection_data(intersection_id, data_path)
        
        if len(filtered_data) == 0:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è·¯å£æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return create_sample_data()
        
        # ä»çœŸå®æ•°æ®æ„å»ºè¯„ä»·æ•°æ®é›†
        vehicle_ids = filtered_data['vehicle_id'].unique()
        predictions_list = []
        ground_truth_list = []
        intent_predictions_list = []
        intent_ground_truth_list = []
        
        print(f"ğŸ”„ å¤„ç†è·¯å£ {intersection_id} çš„ {len(vehicle_ids)} è¾†è½¦è¾†...")
        
        for vehicle_id in vehicle_ids[:100]:  # é™åˆ¶å¤„ç†æ•°é‡ä»¥æé«˜æ€§èƒ½
            vehicle_data = filtered_data[filtered_data['vehicle_id'] == vehicle_id].sort_values('frame_id')
            
            if len(vehicle_data) < 24:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
                continue
            
            # æ„å»ºè½¨è¿¹æ•°æ® (ä½¿ç”¨å‰12å¸§ä½œä¸ºground truthï¼Œå12å¸§ä½œä¸ºprediction)
            mid_point = len(vehicle_data) // 2
            if mid_point >= 12:
                gt_trajectory = vehicle_data.iloc[:12][['local_x', 'local_y']].values
                pred_trajectory = vehicle_data.iloc[mid_point:mid_point+12][['local_x', 'local_y']].values
                
                if len(pred_trajectory) == 12:
                    ground_truth_list.append(gt_trajectory)
                    predictions_list.append(pred_trajectory)
                    
                    # æ„å›¾æ ‡ç­¾ (æ˜¯å¦ä¸ºå·¦è½¬)
                    is_left_turn = 1.0 if vehicle_id in left_turn_data['vehicle_id'].values else 0.0
                    intent_ground_truth_list.append(is_left_turn)
                    
                    # æ¨¡æ‹Ÿé¢„æµ‹æ„å›¾ (æ·»åŠ ä¸€äº›å™ªå£°)
                    intent_pred = is_left_turn + np.random.normal(0, 0.1)
                    intent_pred = np.clip(intent_pred, 0, 1)
                    intent_predictions_list.append(intent_pred)
        
        if len(predictions_list) == 0:
            print("âš ï¸ æ— æ³•ä»çœŸå®æ•°æ®æ„å»ºè¯„ä»·é›†ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return create_sample_data()
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        predictions = np.array(predictions_list)
        ground_truth = np.array(ground_truth_list)
        intent_predictions = np.array(intent_predictions_list)
        intent_ground_truth = np.array(intent_ground_truth_list)
        
        print(f"âœ… æˆåŠŸæ„å»ºè¯„ä»·æ•°æ®é›†:")
        print(f"   è½¨è¿¹æ ·æœ¬æ•°: {len(predictions)}")
        print(f"   å·¦è½¬è½¦è¾†æ•°: {int(np.sum(intent_ground_truth))}")
        print(f"   éå·¦è½¬è½¦è¾†æ•°: {int(len(intent_ground_truth) - np.sum(intent_ground_truth))}")
        
        return predictions, ground_truth, intent_predictions, intent_ground_truth
        
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
        print("ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º")
        return create_sample_data()

def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºè¯„ä»·ç³»ç»Ÿçš„ä½¿ç”¨
    """
    print("è½¦è¾†å·¦è½¬è½¨è¿¹é¢„æµ‹è¯„ä»·ç³»ç»Ÿæ¼”ç¤º - è·¯å£1ä¸“é¡¹åˆ†æ")
    print("=" * 60)
    
    # åŠ è½½è·¯å£1çš„çœŸå®æ•°æ®è¿›è¡Œè¯„ä»·
    print("ğŸ¯ æœ¬é˜¶æ®µä»…å¯¹è·¯å£1è¿›è¡Œå·¦è½¬é¢„æµ‹è¯„ä»·")
    print("å¦‚æœæ¨¡å‹é¢„æµ‹æ­£å¸¸ï¼Œå°†æ³›åŒ–åˆ°æ‰€æœ‰è·¯å£")
    print("-" * 60)
    
    # åˆ›å»ºè·¯å£1çš„è¯„ä»·æ•°æ®
    predictions, ground_truth, intent_predictions, intent_ground_truth = prepare_intersection_evaluation_data(
        intersection_id=1
    )
    
    # åˆ›å»ºè¯„ä»·å™¨
    evaluator = TrajectoryEvaluator()
    
    # æ‰§è¡Œç»¼åˆè¯„ä»·
    print("æ‰§è¡Œç»¼åˆè¯„ä»·...")
    results = evaluator.comprehensive_evaluation(
        predictions, ground_truth, intent_predictions, intent_ground_truth
    )
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š è·¯å£1å·¦è½¬é¢„æµ‹è¯„ä»·ç»“æœ")
    print("="*60)
    
    print("\nè½¨è¿¹é¢„æµ‹ç²¾åº¦:")
    traj_acc = results['trajectory_accuracy']
    print(f"  ADE: {traj_acc['ade']:.4f} m")
    print(f"  FDE: {traj_acc['fde']:.4f} m")
    print(f"  RMSE: {traj_acc['rmse']:.4f} m")
    print(f"  èˆªå‘è§’è¯¯å·®: {traj_acc['heading_error']:.2f}Â°")
    print(f"  é€Ÿåº¦è¯¯å·®: {traj_acc['velocity_error']:.4f} m/s")
    
    print("\næ„å›¾åˆ†ç±»æ€§èƒ½:")
    intent_class = results['intent_classification']
    print(f"  å‡†ç¡®ç‡: {intent_class['accuracy']:.4f}")
    print(f"  ç²¾ç¡®ç‡: {intent_class['precision']:.4f}")
    print(f"  å¬å›ç‡: {intent_class['recall']:.4f}")
    print(f"  F1åˆ†æ•°: {intent_class['f1_score']:.4f}")
    print(f"  ROC AUC: {intent_class['roc_auc']:.4f}")
    
    print("\nç‰©ç†çº¦æŸæ£€æŸ¥:")
    phys_const = results['physical_constraints']
    print(f"  æœ€å¤§é€Ÿåº¦: {phys_const['max_velocity']:.2f} m/s")
    print(f"  é€Ÿåº¦è¿åç‡: {phys_const['velocity_violation_rate']:.2%}")
    print(f"  æœ€å¤§åŠ é€Ÿåº¦: {phys_const['max_acceleration']:.2f} m/sÂ²")
    print(f"  åŠ é€Ÿåº¦è¿åç‡: {phys_const['acceleration_violation_rate']:.2%}")
    
    print("\n" + "="*60)
    print("ğŸ‰ è·¯å£1å·¦è½¬é¢„æµ‹è¯„ä»·å®Œæˆï¼")
    print("å¦‚æœç»“æœæ»¡æ„ï¼Œå¯ä»¥å°†æ¨¡å‹æ³›åŒ–åˆ°å…¶ä»–è·¯å£")
    print("="*60)

if __name__ == "__main__":
    main()